---
layout: post
title: 05-8 B√†i T·∫≠p Th·ª±c H√†nh - C√°c B√†i To√°n Chu·∫©n
chapter: '05'
order: 9
owner: GitHub Copilot
lang: vi
categories:
- chapter05
lesson_type: required
---

# B√†i T·∫≠p Th·ª±c H√†nh - C√°c B√†i To√°n Chu·∫©n (Canonical Problems)

C√°c b√†i t·∫≠p ƒë∆∞·ª£c tham kh·∫£o t·ª´ Boyd & Vandenberghe (2004), Ben-Tal & Nemirovski (2001).

---

## üìù **Ph·∫ßn I: Linear Programming (LP)**

### **B√†i t·∫≠p 1: B√†i to√°n Dinh d∆∞·ª°ng (Diet Problem)**

M·ªôt ng∆∞·ªùi c·∫ßn l·∫≠p k·∫ø ho·∫°ch dinh d∆∞·ª°ng v·ªõi 3 lo·∫°i th·ª±c ph·∫©m:
- Th·ª±c ph·∫©m 1: 2 ƒë∆°n v·ªã protein, 1 ƒë∆°n v·ªã carbs, gi√° 3 USD
- Th·ª±c ph·∫©m 2: 1 ƒë∆°n v·ªã protein, 2 ƒë∆°n v·ªã carbs, gi√° 2 USD  
- Th·ª±c ph·∫©m 3: 1 ƒë∆°n v·ªã protein, 1 ƒë∆°n v·ªã carbs, gi√° 1.5 USD

Y√™u c·∫ßu t·ªëi thi·ªÉu: 5 ƒë∆°n v·ªã protein, 6 ƒë∆°n v·ªã carbs m·ªói ng√†y.

**Y√™u c·∫ßu:**  
a) Vi·∫øt b√†i to√°n LP ƒë·ªÉ minimize chi ph√≠  
b) T√¨m nghi·ªám t·ªëi ∆∞u  
c) Gi·∫£i th√≠ch √Ω nghƒ©a dual variables (shadow prices)

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**a) Formulation:**

Bi·∫øn: $$x_i$$ = l∆∞·ª£ng th·ª±c ph·∫©m $$i$$ ($$i = 1,2,3$$)

$$
\begin{align}
\min_{x} \quad & 3x_1 + 2x_2 + 1.5x_3 \\
\text{s.t.} \quad & 2x_1 + x_2 + x_3 \geq 5 \quad \text{(protein)} \\
& x_1 + 2x_2 + x_3 \geq 6 \quad \text{(carbs)} \\
& x_1, x_2, x_3 \geq 0
\end{align}
$$

**D·∫°ng chu·∫©n (min v·ªõi $$\leq$$):**

$$
\begin{align}
\min_{x} \quad & 3x_1 + 2x_2 + 1.5x_3 \\
\text{s.t.} \quad & -2x_1 - x_2 - x_3 \leq -5 \\
& -x_1 - 2x_2 - x_3 \leq -6 \\
& x_1, x_2, x_3 \geq 0
\end{align}
$$

---

**b) Gi·∫£i b·∫±ng ph∆∞∆°ng ph√°p ƒë·ªì th·ªã (2 bi·∫øn ch√≠nh):**

Gi·∫£ s·ª≠ $$x_3 = 0$$ (th·ª≠ nghi·ªám):

$$
\begin{cases}
2x_1 + x_2 \geq 5 \\
x_1 + 2x_2 \geq 6
\end{cases}
$$

Giao ƒëi·ªÉm: Gi·∫£i h·ªá $$2x_1 + x_2 = 5$$, $$x_1 + 2x_2 = 6$$:

T·ª´ (1): $$x_2 = 5 - 2x_1$$. Th·∫ø v√†o (2):

$$x_1 + 2(5 - 2x_1) = 6 \Rightarrow x_1 + 10 - 4x_1 = 6 \Rightarrow -3x_1 = -4 \Rightarrow x_1 = \frac{4}{3}$$

$$x_2 = 5 - 2 \cdot \frac{4}{3} = \frac{7}{3}$$

Chi ph√≠: $$3 \cdot \frac{4}{3} + 2 \cdot \frac{7}{3} = 4 + \frac{14}{3} = \frac{26}{3} \approx 8.67$$

**Th·ª≠ c√°c ƒëi·ªÉm kh√°c:**

- ƒêi·ªÉm $$(0, 3)$$: Protein = $$3 < 5$$ ‚úó
- ƒêi·ªÉm $$(2.5, 0)$$: Carbs = $$2.5 < 6$$ ‚úó

**Nghi·ªám t·ªëi ∆∞u:** $$x^* = (\frac{4}{3}, \frac{7}{3}, 0)$$, chi ph√≠ = $$\frac{26}{3} \approx 8.67$$ USD

---

**c) Dual variables (Shadow prices):**

Dual problem:

$$
\max_{\lambda} \quad 5\lambda_1 + 6\lambda_2 \quad \text{s.t.} \quad A^T\lambda \leq c, \, \lambda \geq 0
$$

V·ªõi $$\lambda^* = (\frac{2}{3}, \frac{4}{3})$$ (t·ª´ complementary slackness):

**√ù nghƒ©a:**
- $$\lambda_1^* = \frac{2}{3}$$: TƒÉng y√™u c·∫ßu protein 1 ƒë∆°n v·ªã ‚Üí chi ph√≠ tƒÉng $$\frac{2}{3}$$ USD
- $$\lambda_2^* = \frac{4}{3}$$: TƒÉng y√™u c·∫ßu carbs 1 ƒë∆°n v·ªã ‚Üí chi ph√≠ tƒÉng $$\frac{4}{3}$$ USD

Carbs "ƒë·∫Øt" h∆°n protein trong b·ªëi c·∫£nh n√†y!

</details>

---

## üìù **Ph·∫ßn II: Quadratic Programming (QP)**

### **B√†i t·∫≠p 2: Portfolio Optimization**

ƒê·∫ßu t∆∞ v√†o 2 t√†i s·∫£n v·ªõi:
- L·ª£i nhu·∫≠n k·ª≥ v·ªçng: $$\mu = (0.12, 0.10)^T$$
- Ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai: $$\Sigma = \begin{bmatrix} 0.04 & 0.01 \\ 0.01 & 0.09 \end{bmatrix}$$

**Y√™u c·∫ßu:**  
a) Vi·∫øt b√†i to√°n minimize risk v·ªõi target return $$r = 0.11$$  
b) T√¨m portfolio t·ªëi ∆∞u  
c) V·∫Ω efficient frontier

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**a) Formulation:**

$$
\begin{align}
\min_{x} \quad & \frac{1}{2} x^T \Sigma x \\
\text{s.t.} \quad & \mu^T x = r \\
& \mathbf{1}^T x = 1 \\
& x \geq 0
\end{align}
$$

V·ªõi $$r = 0.11$$:

$$
\begin{align}
\min_{x} \quad & \frac{1}{2}(0.04x_1^2 + 0.02x_1x_2 + 0.09x_2^2) \\
\text{s.t.} \quad & 0.12x_1 + 0.10x_2 = 0.11 \\
& x_1 + x_2 = 1 \\
& x_1, x_2 \geq 0
\end{align}
$$

---

**b) Gi·∫£i b·∫±ng Lagrangian:**

T·ª´ $$x_1 + x_2 = 1$$ v√† $$0.12x_1 + 0.10x_2 = 0.11$$:

$$0.12x_1 + 0.10(1-x_1) = 0.11 \Rightarrow 0.02x_1 = 0.01 \Rightarrow x_1 = 0.5$$

$$x_2 = 0.5$$

**Nghi·ªám:** $$x^* = (0.5, 0.5)^T$$

**Ki·ªÉm tra feasibility:** $$0.5 + 0.5 = 1$$ ‚úì, $$0.12(0.5) + 0.10(0.5) = 0.11$$ ‚úì

**Risk (variance):**

$$\sigma^2 = x^{*T} \Sigma x^* = \begin{bmatrix} 0.5 & 0.5 \end{bmatrix} \begin{bmatrix} 0.04 & 0.01 \\ 0.01 & 0.09 \end{bmatrix} \begin{bmatrix} 0.5 \\ 0.5 \end{bmatrix}$$

$$= \begin{bmatrix} 0.5 & 0.5 \end{bmatrix} \begin{bmatrix} 0.025 \\ 0.05 \end{bmatrix} = 0.0375$$

**Standard deviation:** $$\sigma = \sqrt{0.0375} \approx 0.194 = 19.4\%$$

---

**c) Efficient frontier:**

Vary $$r$$ t·ª´ $$\min(\mu_i) = 0.10$$ ƒë·∫øn $$\max(\mu_i) = 0.12$$:

| Return $$r$$ | $$x_1$$ | $$x_2$$ | Risk $$\sigma$$ |
|-------------|---------|---------|-----------------|
| 0.10 | 0 | 1 | 0.30 |
| 0.105 | 0.25 | 0.75 | 0.23 |
| 0.11 | 0.5 | 0.5 | 0.194 |
| 0.115 | 0.75 | 0.25 | 0.184 |
| 0.12 | 1 | 0 | 0.20 |

**K·∫øt lu·∫≠n:** Efficient frontier l√† ƒë∆∞·ªùng cong l√µm trong kh√¥ng gian (risk, return).

</details>

---

## üìù **Ph·∫ßn III: QCQP v√† SOCP**

### **B√†i t·∫≠p 3: Robust Least Squares (SOCP)**

Cho d·ªØ li·ªáu $$A \in \mathbb{R}^{m \times n}$$, $$b \in \mathbb{R}^m$$. Thay v√¨ least squares th√¥ng th∆∞·ªùng, x√©t robust version:

$$
\min_{x} \quad \|Ax - b\|_2 + \gamma \|x\|_2
$$

v·ªõi $$\gamma > 0$$ l√† regularization parameter.

**Y√™u c·∫ßu:**  
a) Vi·∫øt d∆∞·ªõi d·∫°ng SOCP  
b) V·ªõi $$A = \begin{bmatrix} 1 & 1 \\ 1 & -1 \\ 2 & 0 \end{bmatrix}$$, $$b = \begin{bmatrix} 2 \\ 0 \\ 3 \end{bmatrix}$$, $$\gamma = 0.1$$, t√¨m nghi·ªám

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**a) SOCP formulation:**

ƒê·∫∑t:
- $$t_1$$ sao cho $$\|Ax - b\|_2 \leq t_1$$
- $$t_2$$ sao cho $$\|x\|_2 \leq t_2$$

B√†i to√°n tr·ªü th√†nh:

$$
\begin{align}
\min_{x, t_1, t_2} \quad & t_1 + \gamma t_2 \\
\text{s.t.} \quad & \|Ax - b\|_2 \leq t_1 \\
& \|x\|_2 \leq t_2
\end{align}
$$

ƒê√¢y l√† **SOCP** v·ªõi 2 second-order cone constraints.

**D·∫°ng chu·∫©n SOCP:**

$$
\begin{align}
\min \quad & c^T y \\
\text{s.t.} \quad & \|A_i y + b_i\|_2 \leq c_i^T y + d_i, \quad i = 1, \ldots, k
\end{align}
$$

---

**b) Gi·∫£i s·ªë:**

D·ªØ li·ªáu:

$$A = \begin{bmatrix} 1 & 1 \\ 1 & -1 \\ 2 & 0 \end{bmatrix}, \quad b = \begin{bmatrix} 2 \\ 0 \\ 3 \end{bmatrix}, \quad \gamma = 0.1$$

**Ph∆∞∆°ng ph√°p gi·∫£i t√≠ch (x·∫•p x·ªâ):**

Gradient c·ªßa $$f(x) = \|Ax-b\|_2 + \gamma\|x\|_2$$:

$$\nabla f(x) = \frac{A^T(Ax-b)}{\|Ax-b\|_2} + \gamma \frac{x}{\|x\|_2}$$

(Ph·ª©c t·∫°p do non-smooth t·∫°i $$x = 0$$ v√† $$Ax = b$$)

**S·ª≠ d·ª•ng closed-form cho regularized LS:**

X·∫•p x·ªâ b·∫±ng $$\min \|Ax-b\|_2^2 + \gamma^2\|x\|_2^2$$:

$$x^* = (A^TA + \gamma^2 I)^{-1} A^T b$$

T√≠nh:

$$A^TA = \begin{bmatrix} 1 & 1 & 2 \\ 1 & -1 & 0 \end{bmatrix} \begin{bmatrix} 1 & 1 \\ 1 & -1 \\ 2 & 0 \end{bmatrix} = \begin{bmatrix} 6 & 2 \\ 2 & 2 \end{bmatrix}$$

$$A^TA + 0.01I = \begin{bmatrix} 6.01 & 2 \\ 2 & 2.01 \end{bmatrix}$$

$$A^Tb = \begin{bmatrix} 1 & 1 & 2 \\ 1 & -1 & 0 \end{bmatrix} \begin{bmatrix} 2 \\ 0 \\ 3 \end{bmatrix} = \begin{bmatrix} 8 \\ 2 \end{bmatrix}$$

Gi·∫£i: $$x^* \approx (1.21, 0.39)^T$$

**Objective:** $$f(x^*) \approx 0.35$$

</details>

---

## üìù **Ph·∫ßn IV: Semidefinite Programming (SDP)**

### **B√†i t·∫≠p 4: Matrix Completion**

Cho ma tr·∫≠n $$M \in \mathbb{R}^{3 \times 3}$$ v·ªõi m·ªôt s·ªë entries b·ªã thi·∫øu. Bi·∫øt:

$$M_{11} = 4, \quad M_{12} = 2, \quad M_{22} = 5, \quad M_{23} = 1$$

T√¨m ma tr·∫≠n positive semidefinite $$X$$ ho√†n ch·ªânh v·ªõi trace nh·ªè nh·∫•t.

**Y√™u c·∫ßu:**  
a) Vi·∫øt b√†i to√°n SDP  
b) T√¨m nghi·ªám

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**a) SDP formulation:**

$$
\begin{align}
\min_{X} \quad & \text{tr}(X) \\
\text{s.t.} \quad & X_{11} = 4 \\
& X_{12} = X_{21} = 2 \\
& X_{22} = 5 \\
& X_{23} = X_{32} = 1 \\
& X \succeq 0 \\
& X = X^T
\end{align}
$$

Ma tr·∫≠n:

$$X = \begin{bmatrix} 4 & 2 & x_{13} \\ 2 & 5 & 1 \\ x_{13} & 1 & x_{33} \end{bmatrix}$$

---

**b) Gi·∫£i:**

**ƒêi·ªÅu ki·ªán PSD:** T·∫•t c·∫£ principal minors $$\geq 0$$.

**Minor 1√ó1:** $$4 > 0$$ ‚úì

**Minor 2√ó2:** 

$$\begin{vmatrix} 4 & 2 \\ 2 & 5 \end{vmatrix} = 20 - 4 = 16 > 0$$ ‚úì

**Minor 3√ó3 (determinant):**

$$\det(X) = 4(5x_{33} - 1) - 2(2x_{33} - x_{13}) + x_{13}(2 - 5x_{13})$$

$$= 20x_{33} - 4 - 4x_{33} + 2x_{13} + 2x_{13} - 5x_{13}^2$$

$$= 16x_{33} - 5x_{13}^2 + 4x_{13} - 4$$

ƒê·ªÉ $$\det(X) \geq 0$$: $$16x_{33} \geq 5x_{13}^2 - 4x_{13} + 4$$

**Minimize $$\text{tr}(X) = 4 + 5 + x_{33} = 9 + x_{33}$$:**

C·∫ßn minimize $$x_{33}$$ subject to PSD.

T·ª´ PSD, c·∫ßn:

$$x_{33} \geq \frac{5x_{13}^2 - 4x_{13} + 4}{16}$$

Minimize RHS over $$x_{13}$$:

$$\frac{d}{dx_{13}}\left(\frac{5x_{13}^2 - 4x_{13} + 4}{16}\right) = \frac{10x_{13} - 4}{16} = 0$$

$$x_{13}^* = 0.4$$

$$x_{33}^{\min} = \frac{5(0.4)^2 - 4(0.4) + 4}{16} = \frac{0.8 - 1.6 + 4}{16} = \frac{3.2}{16} = 0.2$$

**Nghi·ªám:**

$$X^* = \begin{bmatrix} 4 & 2 & 0.4 \\ 2 & 5 & 1 \\ 0.4 & 1 & 0.2 \end{bmatrix}, \quad \text{tr}(X^*) = 9.2$$

**Ki·ªÉm tra:** $$\det(X^*) = 16(0.2) - 5(0.16) + 1.6 - 4 = 0$$ (rank-deficient, nh∆∞ng $$\succeq 0$$ ‚úì)

</details>

---

## üìù **Ph·∫ßn V: T·ªïng h·ª£p**

### **B√†i t·∫≠p 5: Ch·ªçn Formulation ph√π h·ª£p**

V·ªõi m·ªói b√†i to√°n, x√°c ƒë·ªãnh d·∫°ng chu·∫©n (LP, QP, QCQP, SOCP, SDP):

**a)** $$\min c^T x$$ s.t. $$Ax = b$$, $$\|x\|_\infty \leq 1$$

**b)** $$\min \|Ax - b\|_1$$

**c)** $$\min x^TQx$$ s.t. $$\|Ax - b\|_2 \leq \delta$$

**d)** $$\min \text{tr}(X)$$ s.t. $$X \succeq yy^T$$, $$X \succeq 0$$

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**a) $$\min c^Tx$$ s.t. $$Ax = b$$, $$\|x\|_\infty \leq 1$$:**

$$\|x\|_\infty \leq 1 \Leftrightarrow -1 \leq x_i \leq 1$$ (linear constraints)

‚Üí **Linear Programming (LP)**

---

**b) $$\min \|Ax - b\|_1$$:**

$$\|Ax - b\|_1 = \sum_i |r_i|$$ v·ªõi $$r = Ax - b$$

ƒê·∫∑t $$t_i \geq |r_i|$$:

$$
\begin{align}
\min \quad & \sum_i t_i \\
\text{s.t.} \quad & -t_i \leq (Ax - b)_i \leq t_i
\end{align}
$$

‚Üí **Linear Programming (LP)**

---

**c) $$\min x^TQx$$ s.t. $$\|Ax - b\|_2 \leq \delta$$:**

- Objective: quadratic
- Constraint: second-order cone ($$\ell_2$$ norm)

‚Üí **Second-Order Cone Programming (SOCP)**

(Ho·∫∑c QCQP n·∫øu vi·∫øt $$\|Ax-b\|_2^2 \leq \delta^2$$)

---

**d) $$\min \text{tr}(X)$$ s.t. $$X \succeq yy^T$$, $$X \succeq 0$$:**

- Objective: linear trong $$X$$
- Constraint: $$X \succeq yy^T$$ ‚Üí $$X - yy^T \succeq 0$$ (PSD constraint)

‚Üí **Semidefinite Programming (SDP)**

</details>

---

## üí° **T·ªïng k·∫øt**

### **Hierarchy of Convex Problems:**

$$
\text{LP} \subset \text{QP} \subset \text{SOCP} \subset \text{SDP}
$$

| Problem | Objective | Constraints | Example |
|---------|-----------|-------------|---------|
| **LP** | Linear | Linear | Diet problem, transportation |
| **QP** | Quadratic | Linear | Portfolio, least squares |
| **QCQP** | Quadratic | Quadratic | Robust optimization |
| **SOCP** | Linear | $$\ell_2$$ cones | Robust LS, antenna design |
| **SDP** | Linear | PSD cones | Matrix completion, relaxation |

### **Khi n√†o d√πng g√¨:**
- **LP:** Khi m·ªçi th·ª© ƒë·ªÅu tuy·∫øn t√≠nh
- **QP:** Risk minimization, LS v·ªõi regularization
- **SOCP:** Robust optimization, $$\ell_2$$ constraints
- **SDP:** Matrix variables, combinatorial relaxation

---

## üìö **T√†i li·ªáu Tham kh·∫£o**

1. **Boyd, S., & Vandenberghe, L.** (2004). *Convex Optimization*. Cambridge University Press. Chapter 4.

2. **Ben-Tal, A., & Nemirovski, A.** (2001). *Lectures on Modern Convex Optimization*. SIAM.

3. **Lobo, M. S., et al.** (1998). "Applications of Second-Order Cone Programming". *Linear Algebra and Applications*.

