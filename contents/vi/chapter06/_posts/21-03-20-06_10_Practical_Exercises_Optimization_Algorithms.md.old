---
layout: post
title: 6-10 B√†i T·∫≠p Th·ª±c H√†nh - Thu·∫≠t To√°n T·ªëi ∆Øu H√≥a
chapter: '6'
order: 11
owner: GitHub Copilot
lang: vi
categories:
- chapter06
lesson_type: required
---

# B√†i T·∫≠p Th·ª±c H√†nh - Thu·∫≠t To√°n T·ªëi ∆Øu H√≥a

## üìù **B√†i t·∫≠p 1: Gradient descent implementation v√† analysis**

**ƒê·ªÅ b√†i:** L·∫≠p tr√¨nh v√† ph√¢n t√≠ch gradient descent cho c√°c h√†m:

a) **H√†m b·∫≠c hai:** $$f(x) = \frac{1}{2}x^T Q x - b^T x$$ v·ªõi $$Q \succ 0$$

b) **H·ªìi quy logistic:** $$f(w) = \sum_{i=1}^n \log(1 + e^{-y_i w^T x_i}) + \frac{\lambda}{2}\lVert w \rVert_2^2$$

c) **H√†m m·∫•t m√°t Huber:** $$f(x) = \sum_{i=1}^n \phi(a_i^T x - b_i)$$ v·ªõi $$\phi(t) = \begin{cases} \frac{1}{2}t^2 & |t| \leq 1 \\ |t| - \frac{1}{2} & |t| > 1 \end{cases}$$

**Y√™u c·∫ßu:**
1. T√≠nh gradient m·ªôt c√°ch gi·∫£i t√≠ch
2. L·∫≠p tr√¨nh k√≠ch th∆∞·ªõc b∆∞·ªõc c·ªë ƒë·ªãnh v√† t√¨m ki·∫øm ƒë∆∞·ªùng quay lui
3. Ph√¢n t√≠ch t·ªëc ƒë·ªô h·ªôi t·ª• v·ªÅ m·∫∑t l√Ω thuy·∫øt
4. So s√°nh v·ªõi nghi·ªám ch√≠nh x√°c (n·∫øu c√≥)

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Quadratic function**

**Gradient:** $$\nabla f(x) = Qx - b$$

**Optimal solution:** $$x^* = Q^{-1}b$$

**Fixed step size:** $$x^{(k+1)} = x^{(k)} - \alpha(Qx^{(k)} - b)$$

**Convergence condition:** $$0 < \alpha < \frac{2}{\lambda_{\max}(Q)}$$

**Convergence rate:** $$\lVert x^{(k)} - x^* \rVert_2 \leq (1 - \alpha \lambda_{\min}(Q))^k \lVert x^{(0)} - x^* \rVert_2$$

**Implementation:**
```python
def gradient_descent_quadratic(Q, b, x0, alpha, max_iter=1000, tol=1e-6):
    x = x0.copy()
    history = [x.copy()]
    
    for k in range(max_iter):
        grad = Q @ x - b
        x_new = x - alpha * grad
        
        if np.linalg.norm(grad) < tol:
            break
            
        x = x_new
        history.append(x.copy())
    
    return x, history
```

**B∆∞·ªõc 2: Logistic regression**

**Gradient:** $$\nabla f(w) = -\sum_{i=1}^n \frac{y_i x_i}{1 + e^{y_i w^T x_i}} + \lambda w$$

**Hessian:** $$\nabla^2 f(w) = \sum_{i=1}^n \frac{e^{y_i w^T x_i}}{(1 + e^{y_i w^T x_i})^2} x_i x_i^T + \lambda I$$

**Strong convexity:** $$\nabla^2 f(w) \succeq \lambda I$$

**Convergence rate:** $$O((1 - \alpha \lambda)^k)$$ v·ªõi appropriate $$\alpha$$

**Backtracking line search:**
```python
def backtracking_line_search(f, grad_f, x, d, alpha=1, rho=0.5, c=1e-4):
    while f(x + alpha * d) > f(x) + c * alpha * grad_f(x).T @ d:
        alpha *= rho
    return alpha
```

**B∆∞·ªõc 3: Huber loss**

**Subdifferential:** 
$$\partial \phi(t) = \begin{cases} t & |t| < 1 \\ [-1, 1] & t = 0 \\ \text{sign}(t) & |t| > 1 \end{cases}$$

**Gradient:** $$\nabla f(x) = \sum_{i=1}^n a_i \cdot \text{clip}(a_i^T x - b_i, -1, 1)$$

**Non-smooth:** Requires subgradient methods ho·∫∑c smoothing

**Smoothed version:** $$\phi_\mu(t) = \begin{cases} \frac{1}{2}t^2 & |t| \leq \mu \\ |t| - \frac{\mu}{2} & |t| > \mu \end{cases}$$

</details>

---

## üìù **B√†i t·∫≠p 2: Newton's method v√† quasi-Newton methods**

**ƒê·ªÅ b√†i:** L·∫≠p tr√¨nh v√† so s√°nh c√°c ph∆∞∆°ng ph√°p ki·ªÉu Newton:

a) **Ph∆∞∆°ng ph√°p Newton thu·∫ßn t√∫y** v·ªõi Hessian ch√≠nh x√°c
b) **BFGS** (Broyden-Fletcher-Goldfarb-Shanno)
c) **L-BFGS** (BFGS b·ªô nh·ªõ gi·ªõi h·∫°n)
d) **Gauss-Newton** cho b√¨nh ph∆∞∆°ng t·ªëi thi·ªÉu phi tuy·∫øn

**H√†m ki·ªÉm tra:**
- Rosenbrock: $$f(x,y) = 100(y - x^2)^2 + (1 - x)^2$$
- B√¨nh ph∆∞∆°ng t·ªëi thi·ªÉu phi tuy·∫øn: $$f(x) = \frac{1}{2}\sum_{i=1}^m r_i(x)^2$$

**Y√™u c·∫ßu:**
1. L·∫≠p tr√¨nh t·∫•t c·∫£ c√°c ph∆∞∆°ng ph√°p v·ªõi t√¨m ki·∫øm ƒë∆∞·ªùng
2. So s√°nh t·ªëc ƒë·ªô h·ªôi t·ª•
3. Ph√¢n t√≠ch ƒë·ªô ph·ª©c t·∫°p t√≠nh to√°n
4. X·ª≠ l√Ω ƒëi·ªÅu ki·ªán x·∫•u

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Newton's method**

**Update rule:** $$x^{(k+1)} = x^{(k)} - \alpha^{(k)} [\nabla^2 f(x^{(k)})]^{-1} \nabla f(x^{(k)})$$

**Convergence:** Quadratic near solution (if Hessian well-conditioned)

**Implementation:**
```python
def newton_method(f, grad_f, hess_f, x0, max_iter=100, tol=1e-6):
    x = x0.copy()
    history = [x.copy()]
    
    for k in range(max_iter):
        g = grad_f(x)
        H = hess_f(x)
        
        if np.linalg.norm(g) < tol:
            break
            
        # Solve Newton system
        try:
            d = -np.linalg.solve(H, g)
        except np.linalg.LinAlgError:
            # Fallback to gradient descent
            d = -g
            
        # Line search
        alpha = backtracking_line_search(f, grad_f, x, d)
        x = x + alpha * d
        history.append(x.copy())
    
    return x, history
```

**B∆∞·ªõc 2: BFGS method**

**Hessian approximation update:**
$$B_{k+1} = B_k + \frac{y_k y_k^T}{y_k^T s_k} - \frac{B_k s_k s_k^T B_k}{s_k^T B_k s_k}$$

v·ªõi $$s_k = x_{k+1} - x_k$$, $$y_k = \nabla f(x_{k+1}) - \nabla f(x_k)$$

**Implementation:**
```python
def bfgs_method(f, grad_f, x0, max_iter=100, tol=1e-6):
    x = x0.copy()
    n = len(x)
    B = np.eye(n)  # Initial Hessian approximation
    history = [x.copy()]
    
    for k in range(max_iter):
        g = grad_f(x)
        
        if np.linalg.norm(g) < tol:
            break
            
        # Search direction
        d = -np.linalg.solve(B, g)
        
        # Line search
        alpha = backtracking_line_search(f, grad_f, x, d)
        x_new = x + alpha * d
        
        # Update Hessian approximation
        s = x_new - x
        y = grad_f(x_new) - g
        
        if y.T @ s > 1e-10:  # Curvature condition
            B = B + np.outer(y, y) / (y.T @ s) - (B @ np.outer(s, s) @ B) / (s.T @ B @ s)
        
        x = x_new
        history.append(x.copy())
    
    return x, history
```

**B∆∞·ªõc 3: L-BFGS**

**Limited memory:** Store only last $$m$$ vector pairs $$(s_i, y_i)$$

**Two-loop recursion:** Efficient computation c·ªßa $$H_k \nabla f(x_k)$$

**Memory complexity:** $$O(mn)$$ instead of $$O(n^2)$$

**B∆∞·ªõc 4: Gauss-Newton**

**For $$f(x) = \frac{1}{2}\sum_{i=1}^m r_i(x)^2$$:**

**Jacobian:** $$J(x) = [\nabla r_1(x), \ldots, \nabla r_m(x)]^T$$

**Gauss-Newton Hessian:** $$H_{GN} = J(x)^T J(x)$$

**Update:** $$x^{(k+1)} = x^{(k)} - \alpha [J(x^{(k)})^T J(x^{(k)})]^{-1} J(x^{(k)})^T r(x^{(k)})$$

**Advantages:** No need for second derivatives, works well when residuals small

</details>

---

## üìù **B√†i t·∫≠p 3: Constrained optimization - Barrier v√† penalty methods**

**ƒê·ªÅ b√†i:** L·∫≠p tr√¨nh c√°c ph∆∞∆°ng ph√°p ƒëi·ªÉm trong:

a) **Ph∆∞∆°ng ph√°p r√†o c·∫£n** cho r√†ng bu·ªôc b·∫•t ƒë·∫≥ng th·ª©c:
$$\min_x f(x) \quad \text{s.t.} \quad h_i(x) \leq 0$$

b) **Ph∆∞∆°ng ph√°p ph·∫°t** cho r√†ng bu·ªôc ƒë·∫≥ng th·ª©c:
$$\min_x f(x) \quad \text{s.t.} \quad g_j(x) = 0$$

c) **Ph∆∞∆°ng ph√°p Lagrange tƒÉng c∆∞·ªùng**

d) **Ph∆∞∆°ng ph√°p ƒëi·ªÉm trong primal-dual** cho LP

**B√†i to√°n ki·ªÉm tra:**
- Quy ho·∫°ch b·∫≠c hai v·ªõi r√†ng bu·ªôc h·ªôp
- T·ªëi ∆∞u danh m·ª•c ƒë·∫ßu t∆∞
- M√°y vector h·ªó tr·ª£

**Y√™u c·∫ßu:**
1. L·∫≠p tr√¨nh c√°c h√†m r√†o c·∫£n v√† ph·∫°t
2. Ph√¢n t√≠ch t√≠nh ch·∫•t h·ªôi t·ª•
3. X·ª≠ l√Ω c√°c v·∫•n ƒë·ªÅ s·ªë h·ªçc
4. So s√°nh v·ªõi ph∆∞∆°ng ph√°p t·∫≠p ho·∫°t ƒë·ªông

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Barrier method**

**Barrier function:** $$\phi(x) = -\sum_{i=1}^m \log(-h_i(x))$$

**Barrier problem:** $$\min_x t f(x) + \phi(x)$$

**Central path:** $$x^*(t)$$ as function c·ªßa barrier parameter $$t$$

**Algorithm:**
```python
def barrier_method(f, grad_f, h, grad_h, x0, t_init=1, mu=10, tol=1e-6):
    x = x0.copy()
    t = t_init
    path = []
    
    while True:
        # Solve barrier subproblem
        def barrier_obj(x):
            if np.any(h(x) >= 0):
                return np.inf
            return t * f(x) - np.sum(np.log(-h(x)))
        
        def barrier_grad(x):
            h_val = h(x)
            grad_h_val = grad_h(x)
            return t * grad_f(x) + np.sum(grad_h_val / h_val[:, None], axis=0)
        
        # Newton method for barrier subproblem
        x = newton_method_barrier(barrier_obj, barrier_grad, x)
        path.append(x.copy())
        
        # Check stopping criterion
        if len(h(x)) / t < tol:
            break
            
        # Update barrier parameter
        t *= mu
    
    return x, path
```

**B∆∞·ªõc 2: Penalty method**

**Penalty function:** $$P(x, \rho) = f(x) + \frac{\rho}{2}\sum_{j=1}^p g_j(x)^2$$

**Algorithm:**
```python
def penalty_method(f, grad_f, g, grad_g, x0, rho_init=1, rho_mult=10, tol=1e-6):
    x = x0.copy()
    rho = rho_init
    
    while True:
        # Solve penalty subproblem
        def penalty_obj(x):
            g_val = g(x)
            return f(x) + 0.5 * rho * np.sum(g_val**2)
        
        def penalty_grad(x):
            g_val = g(x)
            grad_g_val = grad_g(x)
            return grad_f(x) + rho * grad_g_val.T @ g_val
        
        # Minimize penalty function
        x = bfgs_method(penalty_obj, penalty_grad, x)
        
        # Check convergence
        if np.linalg.norm(g(x)) < tol:
            break
            
        # Increase penalty parameter
        rho *= rho_mult
    
    return x
```

**B∆∞·ªõc 3: Augmented Lagrangian**

**Augmented Lagrangian:** $$L_A(x, \lambda, \rho) = f(x) + \lambda^T g(x) + \frac{\rho}{2}\lVert g(x) \rVert_2^2$$

**Dual update:** $$\lambda^{(k+1)} = \lambda^{(k)} + \rho g(x^{(k+1)})$$

**Advantages:** Better conditioning than pure penalty method

**B∆∞·ªõc 4: Primal-dual interior-point**

**KKT system:**
$$\begin{bmatrix} \nabla^2 L & A^T \\ A & 0 \end{bmatrix} \begin{bmatrix} \Delta x \\ \Delta \lambda \end{bmatrix} = -\begin{bmatrix} \nabla f + A^T \lambda \\ Ax - b \end{bmatrix}$$

**Predictor-corrector:** Mehrotra's algorithm

**Convergence:** Polynomial-time complexity

</details>

---

## üìù **B√†i t·∫≠p 4: Proximal methods**

**ƒê·ªÅ b√†i:** L·∫≠p tr√¨nh c√°c thu·∫≠t to√°n g·∫ßn k·ªÅ cho t·ªëi ∆∞u kh√¥ng tr∆°n:

a) **Ph∆∞∆°ng ph√°p gradient g·∫ßn k·ªÅ:**
$$\min_x f(x) + g(x)$$
v·ªõi $$f$$ tr∆°n, $$g$$ kh√¥ng tr∆°n

b) **ADMM** (Ph∆∞∆°ng ph√°p nh√¢n t·ª≠ h∆∞·ªõng xen k·∫Ω):
$$\min_{x,z} f(x) + g(z) \quad \text{s.t.} \quad Ax + Bz = c$$

c) **T√°ch ti·∫øn-l√πi**

d) **T√°ch Douglas-Rachford**

**·ª®ng d·ª•ng:**
- H·ªìi quy LASSO: $$\min_x \frac{1}{2}\lVert Ax - b \rVert_2^2 + \lambda \lVert x \rVert_1$$
- Kh·ª≠ nhi·ªÖu bi·∫øn ph√¢n to√†n ph·∫ßn
- Ho√†n thi·ªán ma tr·∫≠n

**Y√™u c·∫ßu:**
1. T√≠nh to√°n c√°c to√°n t·ª≠ g·∫ßn k·ªÅ
2. L·∫≠p tr√¨nh c√°c thu·∫≠t to√°n t√°ch
3. Ph√¢n t√≠ch t·ªëc ƒë·ªô h·ªôi t·ª•
4. X·ª≠ l√Ω b√†i to√°n quy m√¥ l·ªõn

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Proximal operators**

**Definition:** $$\text{prox}_{\gamma g}(x) = \arg\min_z \left\{g(z) + \frac{1}{2\gamma}\lVert z - x \rVert_2^2\right\}$$

**Examples:**
- **$$\ell_1$$ norm:** $$\text{prox}_{\gamma \lVert \cdot \rVert_1}(x) = \text{soft}(x, \gamma)$$
- **Indicator function:** $$\text{prox}_{\gamma I_C}(x) = \text{proj}_C(x)$$
- **$$\ell_2$$ norm:** $$\text{prox}_{\gamma \lVert \cdot \rVert_2}(x) = \max(0, 1 - \gamma/\lVert x \rVert_2) x$$

**Soft thresholding:**
```python
def soft_threshold(x, gamma):
    return np.sign(x) * np.maximum(np.abs(x) - gamma, 0)
```

**B∆∞·ªõc 2: Proximal gradient method**

**Algorithm:** $$x^{(k+1)} = \text{prox}_{\gamma g}(x^{(k)} - \gamma \nabla f(x^{(k)}))$$

**LASSO implementation:**
```python
def proximal_gradient_lasso(A, b, lambda_reg, x0, gamma, max_iter=1000):
    x = x0.copy()
    history = [x.copy()]
    
    for k in range(max_iter):
        # Gradient step for smooth part
        grad = A.T @ (A @ x - b)
        x_temp = x - gamma * grad
        
        # Proximal step for non-smooth part
        x = soft_threshold(x_temp, gamma * lambda_reg)
        history.append(x.copy())
        
        # Check convergence
        if k > 0 and np.linalg.norm(x - history[-2]) < 1e-6:
            break
    
    return x, history
```

**B∆∞·ªõc 3: ADMM**

**Algorithm:**
```
x^(k+1) = argmin_x {f(x) + (œÅ/2)||Ax + Bz^(k) - c + u^(k)||¬≤}
z^(k+1) = argmin_z {g(z) + (œÅ/2)||Ax^(k+1) + Bz - c + u^(k)||¬≤}
u^(k+1) = u^(k) + Ax^(k+1) + Bz^(k+1) - c
```

**LASSO via ADMM:**
```python
def admm_lasso(A, b, lambda_reg, rho=1, max_iter=1000):
    m, n = A.shape
    x = np.zeros(n)
    z = np.zeros(n)
    u = np.zeros(n)
    
    # Precompute for x-update
    AtA = A.T @ A
    Atb = A.T @ b
    L = np.linalg.cholesky(AtA + rho * np.eye(n))
    
    for k in range(max_iter):
        # x-update
        q = Atb + rho * (z - u)
        x = np.linalg.solve(L.T, np.linalg.solve(L, q))
        
        # z-update
        z = soft_threshold(x + u, lambda_reg / rho)
        
        # u-update
        u = u + x - z
        
        # Check convergence
        if np.linalg.norm(x - z) < 1e-6:
            break
    
    return x
```

**B∆∞·ªõc 4: Convergence analysis**

**Proximal gradient:** $$O(1/k)$$ for convex, $$O((1-\mu/L)^k)$$ for strongly convex

**ADMM:** $$O(1/k)$$ convergence for convex problems

**Acceleration:** FISTA, accelerated ADMM achieve $$O(1/k^2)$$

</details>

---

## üìù **B√†i t·∫≠p 5: Stochastic optimization**

**ƒê·ªÅ b√†i:** L·∫≠p tr√¨nh c√°c ph∆∞∆°ng ph√°p gradient ng·∫´u nhi√™n:

a) **H·∫° gradient ng·∫´u nhi√™n (SGD)**
b) **SGD theo l√¥ nh·ªè**  
c) **Ph∆∞∆°ng ph√°p ƒë·ªông l∆∞·ª£ng** (Heavy-ball, Nesterov)
d) **Ph∆∞∆°ng ph√°p th√≠ch nghi** (AdaGrad, RMSprop, Adam)

**·ª®ng d·ª•ng:**
- H·ªìi quy logistic tr√™n t·∫≠p d·ªØ li·ªáu l·ªõn
- Hu·∫•n luy·ªán m·∫°ng n∆°-ron
- H·ªçc tr·ª±c tuy·∫øn

**Y√™u c·∫ßu:**
1. X·ª≠ l√Ω l√¥ nh·ªè m·ªôt c√°ch hi·ªáu qu·∫£
2. L·∫≠p tr√¨nh l·ªãch tr√¨nh t·ªëc ƒë·ªô h·ªçc
3. So s√°nh h√†nh vi h·ªôi t·ª•
4. Ph√¢n t√≠ch c√°c k·ªπ thu·∫≠t gi·∫£m ph∆∞∆°ng sai

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Stochastic Gradient Descent**

**Update rule:** $$x^{(k+1)} = x^{(k)} - \alpha_k \nabla f_{i_k}(x^{(k)})$$

v·ªõi $$i_k$$ sampled uniformly from $$\{1, \ldots, n\}$$

**Implementation:**
```python
def sgd(grad_f_i, x0, alpha, n_samples, max_iter=1000):
    x = x0.copy()
    history = [x.copy()]
    
    for k in range(max_iter):
        # Sample random index
        i = np.random.randint(0, n_samples)
        
        # Stochastic gradient step
        grad = grad_f_i(x, i)
        x = x - alpha * grad
        
        if k % 100 == 0:  # Store periodically
            history.append(x.copy())
    
    return x, history
```

**Learning rate schedules:**
- **Constant:** $$\alpha_k = \alpha$$
- **Decreasing:** $$\alpha_k = \alpha_0 / (1 + \beta k)$$
- **Step decay:** $$\alpha_k = \alpha_0 \gamma^{\lfloor k/s \rfloor}$$

**B∆∞·ªõc 2: Mini-batch SGD**

**Update:** $$x^{(k+1)} = x^{(k)} - \alpha_k \frac{1}{|B_k|} \sum_{i \in B_k} \nabla f_i(x^{(k)})$$

**Batch size effects:**
- **Small batches:** More noise, faster iterations
- **Large batches:** Less noise, slower iterations
- **Optimal:** Balance between variance v√† computational cost

**B∆∞·ªõc 3: Momentum methods**

**Heavy-ball method:**
```
v^(k+1) = Œ≤ v^(k) + Œ± ‚àáf(x^(k))
x^(k+1) = x^(k) - v^(k+1)
```

**Nesterov momentum:**
```
v^(k+1) = Œ≤ v^(k) + Œ± ‚àáf(x^(k) - Œ≤ v^(k))
x^(k+1) = x^(k) - v^(k+1)
```

**Implementation:**
```python
def sgd_momentum(grad_f, x0, alpha, beta, max_iter=1000):
    x = x0.copy()
    v = np.zeros_like(x)
    
    for k in range(max_iter):
        # Nesterov momentum
        grad = grad_f(x - beta * v)
        v = beta * v + alpha * grad
        x = x - v
    
    return x
```

**B∆∞·ªõc 4: Adaptive methods**

**AdaGrad:**
```python
def adagrad(grad_f, x0, alpha, eps=1e-8, max_iter=1000):
    x = x0.copy()
    G = np.zeros_like(x)  # Accumulated squared gradients
    
    for k in range(max_iter):
        grad = grad_f(x)
        G += grad**2
        x = x - alpha * grad / (np.sqrt(G) + eps)
    
    return x
```

**Adam:**
```python
def adam(grad_f, x0, alpha=0.001, beta1=0.9, beta2=0.999, eps=1e-8, max_iter=1000):
    x = x0.copy()
    m = np.zeros_like(x)  # First moment
    v = np.zeros_like(x)  # Second moment
    
    for k in range(1, max_iter + 1):
        grad = grad_f(x)
        
        # Update moments
        m = beta1 * m + (1 - beta1) * grad
        v = beta2 * v + (1 - beta2) * grad**2
        
        # Bias correction
        m_hat = m / (1 - beta1**k)
        v_hat = v / (1 - beta2**k)
        
        # Update parameters
        x = x - alpha * m_hat / (np.sqrt(v_hat) + eps)
    
    return x
```

</details>

---

## üìù **B√†i t·∫≠p 6: Coordinate descent methods**

**ƒê·ªÅ b√†i:** L·∫≠p tr√¨nh c√°c thu·∫≠t to√°n h·∫° t·ªça ƒë·ªô:

a) **H·∫° t·ªça ƒë·ªô tu·∫ßn ho√†n**
b) **H·∫° t·ªça ƒë·ªô ng·∫´u nhi√™n**  
c) **H·∫° t·ªça ƒë·ªô theo kh·ªëi**
d) **H·∫° t·ªça ƒë·ªô tƒÉng t·ªëc**

**·ª®ng d·ª•ng:**
- H·ªìi quy LASSO
- Hu·∫•n luy·ªán SVM
- Ph√¢n t√≠ch ma tr·∫≠n
- ƒêi·ªÅu chu·∫©n elastic net

**Y√™u c·∫ßu:**
1. T√≠nh c·∫≠p nh·∫≠t theo t·ª´ng t·ªça ƒë·ªô
2. X·ª≠ l√Ω c√°c h√†m ƒëi·ªÅu chu·∫©n kh√¥ng t√°ch ƒë∆∞·ª£c
3. L·∫≠p tr√¨nh c·∫≠p nh·∫≠t theo kh·ªëi
4. Ph√¢n t√≠ch t·ªëc ƒë·ªô h·ªôi t·ª•

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Cyclic coordinate descent**

**Algorithm:** Minimize over one coordinate t·∫°i m·ªôt time

**LASSO coordinate update:**
$$x_j^{(k+1)} = \text{soft}\left(\frac{1}{a_{jj}}(b_j - \sum_{i \neq j} a_{ji} x_i^{(k)}), \frac{\lambda}{a_{jj}}\right)$$

**Implementation:**
```python
def coordinate_descent_lasso(A, b, lambda_reg, x0, max_iter=1000, tol=1e-6):
    x = x0.copy()
    n = len(x)
    
    for iter in range(max_iter):
        x_old = x.copy()
        
        for j in range(n):
            # Compute partial residual
            r_j = b - A @ x + A[:, j] * x[j]
            
            # Coordinate update
            x[j] = soft_threshold(A[:, j].T @ r_j / np.linalg.norm(A[:, j])**2, 
                                lambda_reg / np.linalg.norm(A[:, j])**2)
        
        # Check convergence
        if np.linalg.norm(x - x_old) < tol:
            break
    
    return x
```

**B∆∞·ªõc 2: Randomized coordinate descent**

**Random selection:** Choose coordinate $$j$$ uniformly at random

**Convergence:** $$\mathbb{E}[f(x^{(k)})] - f^* \leq (1 - \frac{\mu}{nL})^k [f(x^{(0)}) - f^*]$$

**Implementation:**
```python
def randomized_coordinate_descent(grad_f_j, prox_j, x0, max_iter=1000):
    x = x0.copy()
    n = len(x)
    
    for k in range(max_iter):
        # Random coordinate selection
        j = np.random.randint(0, n)
        
        # Coordinate gradient
        grad_j = grad_f_j(x, j)
        
        # Proximal update
        x[j] = prox_j(x[j] - grad_j / L_j, j)
    
    return x
```

**B∆∞·ªõc 3: Block coordinate descent**

**Block partition:** $$x = (x_1, \ldots, x_B)$$ v·ªõi $$x_i \in \mathbb{R}^{n_i}$$

**Block update:** $$x_i^{(k+1)} = \arg\min_{x_i} f(x_1^{(k+1)}, \ldots, x_{i-1}^{(k+1)}, x_i, x_{i+1}^{(k)}, \ldots, x_B^{(k)})$$

**Matrix factorization example:**
$$\min_{U,V} \frac{1}{2}\lVert M - UV^T \rVert_F^2 + \frac{\lambda}{2}(\lVert U \rVert_F^2 + \lVert V \rVert_F^2)$$

**Alternating updates:**
- **U-update:** $$U^{(k+1)} = \arg\min_U \frac{1}{2}\lVert M - UV^{(k)T} \rVert_F^2 + \frac{\lambda}{2}\lVert U \rVert_F^2$$
- **V-update:** $$V^{(k+1)} = \arg\min_V \frac{1}{2}\lVert M - U^{(k+1)}V^T \rVert_F^2 + \frac{\lambda}{2}\lVert V \rVert_F^2$$

**B∆∞·ªõc 4: Accelerated coordinate descent**

**Nesterov acceleration:** Apply momentum to coordinate updates

**FISTA-style acceleration:**
```
y^(k) = x^(k) + Œ≤_k(x^(k) - x^(k-1))
x^(k+1) = coordinate_update(y^(k))
```

**Convergence:** $$O(1/k^2)$$ instead of $$O(1/k)$$

</details>

---

## üìù **B√†i t·∫≠p 7: Parallel v√† distributed optimization**

**ƒê·ªÅ b√†i:** L·∫≠p tr√¨nh c√°c thu·∫≠t to√°n t·ªëi ∆∞u song song:

a) **H·∫° t·ªça ƒë·ªô song song**
b) **H·∫° gradient ph√¢n t√°n**
c) **Thi·∫øt l·∫≠p h·ªçc li√™n k·∫øt**
d) **Ph∆∞∆°ng ph√°p kh√¥ng ƒë·ªìng b·ªô**

**Ki·∫øn tr√∫c:**
- B·ªô nh·ªõ d√πng chung (ƒëa lu·ªìng)
- B·ªô nh·ªõ ph√¢n t√°n (MPI)
- M√¥ h√¨nh m√°y ch·ªß tham s·ªë
- M·∫°ng phi t·∫≠p trung

**Y√™u c·∫ßu:**
1. X·ª≠ l√Ω chi ph√≠ truy·ªÅn th√¥ng
2. L·∫≠p tr√¨nh c√°c chi·∫øn l∆∞·ª£c ƒë·ªìng b·ªô
3. Ph√¢n t√≠ch tƒÉng t·ªëc v√† hi·ªáu su·∫•t
4. X·ª≠ l√Ω h·ªá th·ªëng kh√¥ng ƒë·ªìng nh·∫•t

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Parallel coordinate descent**

**Asynchronous updates:** Multiple threads update different coordinates

**Lock-free implementation:**
```python
import threading
import numpy as np

class ParallelCoordinateDescent:
    def __init__(self, A, b, lambda_reg, n_threads=4):
        self.A = A
        self.b = b
        self.lambda_reg = lambda_reg
        self.n_threads = n_threads
        self.x = np.zeros(A.shape[1])
        self.lock = threading.Lock()
    
    def coordinate_update(self, j):
        with self.lock:
            # Compute residual
            r = self.b - self.A @ self.x + self.A[:, j] * self.x[j]
            
            # Update coordinate
            self.x[j] = soft_threshold(
                self.A[:, j].T @ r / np.linalg.norm(self.A[:, j])**2,
                self.lambda_reg / np.linalg.norm(self.A[:, j])**2
            )
    
    def worker(self, coordinates):
        for j in coordinates:
            self.coordinate_update(j)
    
    def fit(self, max_iter=1000):
        n_features = self.A.shape[1]
        coords_per_thread = np.array_split(range(n_features), self.n_threads)
        
        for iteration in range(max_iter):
            threads = []
            for coords in coords_per_thread:
                t = threading.Thread(target=self.worker, args=(coords,))
                threads.append(t)
                t.start()
            
            for t in threads:
                t.join()
```

**B∆∞·ªõc 2: Distributed gradient descent**

**Parameter server architecture:**
- **Workers:** Compute gradients on local data
- **Parameter server:** Aggregates gradients, updates parameters

**Synchronous SGD:**
```python
class DistributedSGD:
    def __init__(self, model, learning_rate):
        self.model = model
        self.lr = learning_rate
        self.workers = []
    
    def add_worker(self, worker):
        self.workers.append(worker)
    
    def train_step(self):
        # Broadcast current parameters
        params = self.model.get_parameters()
        for worker in self.workers:
            worker.set_parameters(params)
        
        # Compute gradients in parallel
        gradients = []
        for worker in self.workers:
            grad = worker.compute_gradient()
            gradients.append(grad)
        
        # Aggregate gradients
        avg_gradient = np.mean(gradients, axis=0)
        
        # Update parameters
        new_params = params - self.lr * avg_gradient
        self.model.set_parameters(new_params)
```

**B∆∞·ªõc 3: Federated learning**

**Key challenges:**
- **Data privacy:** Data stays on devices
- **Communication efficiency:** Limited bandwidth
- **Heterogeneity:** Non-IID data distribution

**FedAvg algorithm:**
```python
class FederatedAveraging:
    def __init__(self, global_model, clients):
        self.global_model = global_model
        self.clients = clients
    
    def federated_round(self, fraction=1.0, local_epochs=1):
        # Select subset of clients
        n_selected = int(fraction * len(self.clients))
        selected_clients = np.random.choice(self.clients, n_selected, replace=False)
        
        # Local training
        client_weights = []
        client_sizes = []
        
        for client in selected_clients:
            # Send global model to client
            client.set_model(self.global_model.get_weights())
            
            # Local training
            weights, data_size = client.local_train(local_epochs)
            client_weights.append(weights)
            client_sizes.append(data_size)
        
        # Weighted aggregation
        total_size = sum(client_sizes)
        new_weights = np.zeros_like(self.global_model.get_weights())
        
        for weights, size in zip(client_weights, client_sizes):
            new_weights += (size / total_size) * weights
        
        self.global_model.set_weights(new_weights)
```

**B∆∞·ªõc 4: Asynchronous methods**

**Hogwild!:** Asynchronous parallel SGD

**Key insight:** Sparse updates rarely conflict

**Implementation considerations:**
- **Memory consistency:** Relaxed consistency models
- **Staleness:** Handle delayed updates
- **Load balancing:** Dynamic work distribution

</details>

---

## üìù **B√†i t·∫≠p 8: Specialized algorithms**

**ƒê·ªÅ b√†i:** L·∫≠p tr√¨nh c√°c thu·∫≠t to√°n t·ªëi ∆∞u chuy√™n bi·ªát:

a) **Ph∆∞∆°ng ph√°p Frank-Wolfe** (gradient c√≥ ƒëi·ªÅu ki·ªán)
b) **H·∫° g∆∞∆°ng** v·ªõi h√¨nh h·ªçc phi Euclide
c) **Ph∆∞∆°ng ph√°p gradient t·ª± nhi√™n**
d) **Thu·∫≠t to√°n ti·∫øn h√≥a** (CMA-ES)

**·ª®ng d·ª•ng:**
- Kh√¥i ph·ª•c t√≠n hi·ªáu th∆∞a
- V·∫≠n chuy·ªÉn t·ªëi ∆∞u
- H√¨nh h·ªçc th√¥ng tin
- T·ªëi ∆∞u h·ªôp ƒëen

**Y√™u c·∫ßu:**
1. Hi·ªÉu tr·ª±c gi√°c h√¨nh h·ªçc
2. L·∫≠p tr√¨nh c√°c oracle chuy√™n bi·ªát
3. X·ª≠ l√Ω r√†ng bu·ªôc phi ti√™u chu·∫©n
4. So s√°nh v·ªõi c√°c ph∆∞∆°ng ph√°p chu·∫©n

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Frank-Wolfe method**

**Algorithm:** $$x^{(k+1)} = (1-\gamma_k) x^{(k)} + \gamma_k s^{(k)}$$

v·ªõi $$s^{(k)} = \arg\min_{s \in \mathcal{D}} \nabla f(x^{(k)})^T s$$

**Linear minimization oracle:** Key component

**Implementation:**
```python
def frank_wolfe(f, grad_f, linear_oracle, x0, max_iter=1000):
    x = x0.copy()
    history = [x.copy()]
    
    for k in range(max_iter):
        # Compute gradient
        grad = grad_f(x)
        
        # Linear minimization oracle
        s = linear_oracle(grad)
        
        # Line search (or fixed step size)
        gamma = 2.0 / (k + 2)  # Standard choice
        
        # Update
        x = (1 - gamma) * x + gamma * s
        history.append(x.copy())
    
    return x, history
```

**Example - $$\ell_1$$ ball constraint:**
```python
def l1_ball_oracle(grad, radius=1):
    # Find coordinate with largest absolute gradient
    j = np.argmax(np.abs(grad))
    s = np.zeros_like(grad)
    s[j] = -radius * np.sign(grad[j])
    return s
```

**B∆∞·ªõc 2: Mirror descent**

**Bregman divergence:** $$D_\phi(x, y) = \phi(x) - \phi(y) - \nabla \phi(y)^T (x - y)$$

**Update rule:** $$x^{(k+1)} = \arg\min_x \{\eta \nabla f(x^{(k)})^T x + D_\phi(x, x^{(k)})\}$$

**Entropy mirror map:** $$\phi(x) = \sum_{i=1}^n x_i \log x_i$$

**Simplex projection:**
```python
def mirror_descent_simplex(grad_f, x0, eta, max_iter=1000):
    x = x0.copy()  # x0 should be in probability simplex
    
    for k in range(max_iter):
        grad = grad_f(x)
        
        # Mirror descent update
        log_x = np.log(x) - eta * grad
        x_new = np.exp(log_x)
        
        # Normalize to simplex
        x = x_new / np.sum(x_new)
    
    return x
```

**B∆∞·ªõc 3: Natural gradient**

**Fisher information matrix:** $$F(\theta) = \mathbb{E}[\nabla \log p(x|\theta) \nabla \log p(x|\theta)^T]$$

**Natural gradient:** $$\tilde{\nabla} f(\theta) = F(\theta)^{-1} \nabla f(\theta)$$

**Exponential family example:**
```python
def natural_gradient_exponential_family(theta, data, learning_rate):
    # Compute sufficient statistics
    T_data = compute_sufficient_statistics(data)
    
    # Expected sufficient statistics under current model
    T_model = expected_sufficient_statistics(theta)
    
    # Natural gradient (no Fisher matrix inversion needed)
    nat_grad = T_data - T_model
    
    # Update natural parameters
    theta_new = theta + learning_rate * nat_grad
    
    return theta_new
```

**B∆∞·ªõc 4: CMA-ES (Covariance Matrix Adaptation)**

**Evolution strategy:** Sample from multivariate Gaussian, adapt covariance

**Key components:**
- **Mean update:** Weighted average c·ªßa best solutions
- **Covariance adaptation:** Learn search distribution
- **Step-size control:** Adapt overall scale

**Simplified implementation:**
```python
class CMAES:
    def __init__(self, x0, sigma0):
        self.dim = len(x0)
        self.mean = x0.copy()
        self.sigma = sigma0
        self.C = np.eye(self.dim)  # Covariance matrix
        self.lambda_ = 4 + int(3 * np.log(self.dim))  # Population size
        self.mu = self.lambda_ // 2  # Number of parents
        
    def ask(self):
        # Sample population
        z = np.random.multivariate_normal(np.zeros(self.dim), np.eye(self.dim), self.lambda_)
        L = np.linalg.cholesky(self.C)
        x = self.mean + self.sigma * (z @ L.T)
        return x
    
    def tell(self, solutions, fitness_values):
        # Sort by fitness
        idx = np.argsort(fitness_values)
        solutions = solutions[idx[:self.mu]]
        
        # Update mean
        self.mean = np.mean(solutions, axis=0)
        
        # Update covariance (simplified)
        centered = solutions - self.mean
        self.C = np.cov(centered.T)
        
        # Update step size (simplified)
        self.sigma *= 1.1 if np.mean(fitness_values[:self.mu]) < np.mean(fitness_values) else 0.9
```

</details>

---

## üìù **B√†i t·∫≠p 9: Algorithm selection v√† hyperparameter tuning**

**ƒê·ªÅ b√†i:** Ph√°t tri·ªÉn ph∆∞∆°ng ph√°p c√≥ h·ªá th·ªëng ƒë·ªÉ ch·ªçn thu·∫≠t to√°n:

a) **Ph√¢n t√≠ch hi·ªáu nƒÉng** c·ªßa c√°c thu·∫≠t to√°n kh√°c nhau
b) **T·ªëi ∆∞u si√™u tham s·ªë** (t√¨m ki·∫øm l∆∞·ªõi, t·ªëi ∆∞u Bayes)
c) **Ch·ªçn thu·∫≠t to√°n th√≠ch nghi**
d) **Khung ƒëo l∆∞·ªùng chu·∫©n**

**B·ªô ki·ªÉm tra:**
- B√†i to√°n t·ªëi ∆∞u CUTEst
- T·∫≠p d·ªØ li·ªáu h·ªçc m√°y
- B√†i to√°n t·ªïng h·ª£p v·ªõi t√≠nh ch·∫•t ƒë√£ bi·∫øt

**Y√™u c·∫ßu:**
1. Thi·∫øt k·∫ø c√°c b√†i ƒëo l∆∞·ªùng to√†n di·ªán
2. L·∫≠p tr√¨nh ƒëi·ªÅu ch·ªânh t·ª± ƒë·ªông
3. Ph√¢n t√≠ch ƒë·∫∑c ƒëi·ªÉm thu·∫≠t to√°n
4. Cung c·∫•p h∆∞·ªõng d·∫´n l·ª±a ch·ªçn

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Performance profiling**

**Metrics to track:**
- **Convergence rate:** Function value vs iterations
- **Wall-clock time:** Actual runtime
- **Memory usage:** Peak memory consumption
- **Robustness:** Performance across different initializations

**Profiling framework:**
```python
class OptimizationProfiler:
    def __init__(self):
        self.results = {}
    
    def profile_algorithm(self, algorithm, problem, name, n_runs=10):
        results = {
            'function_values': [],
            'runtimes': [],
            'memory_usage': [],
            'convergence_history': []
        }
        
        for run in range(n_runs):
            # Random initialization
            x0 = problem.random_initialization()
            
            # Profile single run
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss
            
            x_opt, history = algorithm(problem.f, problem.grad_f, x0)
            
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss
            
            # Store results
            results['function_values'].append(problem.f(x_opt))
            results['runtimes'].append(end_time - start_time)
            results['memory_usage'].append(end_memory - start_memory)
            results['convergence_history'].append(history)
        
        self.results[name] = results
    
    def compare_algorithms(self):
        # Generate performance plots
        # Statistical significance tests
        # Ranking analysis
        pass
```

**B∆∞·ªõc 2: Hyperparameter optimization**

**Bayesian optimization v·ªõi Gaussian processes:**
```python
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern
from scipy.optimize import minimize

class BayesianHyperparameterOptimizer:
    def __init__(self, objective, bounds, n_initial=5):
        self.objective = objective
        self.bounds = bounds
        self.gp = GaussianProcessRegressor(kernel=Matern(nu=2.5))
        self.X_observed = []
        self.y_observed = []
        
        # Initial random sampling
        for _ in range(n_initial):
            x = self.random_sample()
            y = self.objective(x)
            self.X_observed.append(x)
            self.y_observed.append(y)
    
    def acquisition_function(self, x, xi=0.01):
        # Expected Improvement
        mu, sigma = self.gp.predict([x], return_std=True)
        mu, sigma = mu[0], sigma[0]
        
        if sigma == 0:
            return 0
        
        f_best = min(self.y_observed)
        z = (f_best - mu - xi) / sigma
        ei = (f_best - mu - xi) * norm.cdf(z) + sigma * norm.pdf(z)
        return ei
    
    def optimize_step(self):
        # Fit GP to observed data
        self.gp.fit(self.X_observed, self.y_observed)
        
        # Optimize acquisition function
        result = minimize(lambda x: -self.acquisition_function(x),
                         bounds=self.bounds, method='L-BFGS-B')
        
        # Evaluate objective at new point
        x_next = result.x
        y_next = self.objective(x_next)
        
        self.X_observed.append(x_next)
        self.y_observed.append(y_next)
        
        return x_next, y_next
```

**B∆∞·ªõc 3: Adaptive algorithm selection**

**Algorithm portfolio approach:**
```python
class AdaptiveAlgorithmSelector:
    def __init__(self, algorithms, feature_extractor):
        self.algorithms = algorithms
        self.feature_extractor = feature_extractor
        self.performance_model = None
        self.training_data = []
    
    def extract_problem_features(self, problem):
        # Problem characteristics
        features = {
            'dimension': problem.dimension,
            'condition_number': self.estimate_condition_number(problem),
            'smoothness': self.estimate_smoothness(problem),
            'sparsity': self.estimate_sparsity(problem),
            'constraint_type': problem.constraint_type
        }
        return features
    
    def train_selector(self, training_problems):
        # Run all algorithms on training problems
        for problem in training_problems:
            features = self.extract_problem_features(problem)
            
            for alg_name, algorithm in self.algorithms.items():
                performance = self.evaluate_algorithm(algorithm, problem)
                self.training_data.append((features, alg_name, performance))
        
        # Train performance prediction model
        self.train_performance_model()
    
    def select_algorithm(self, problem):
        features = self.extract_problem_features(problem)
        predicted_performance = {}
        
        for alg_name in self.algorithms:
            predicted_performance[alg_name] = self.performance_model.predict(features, alg_name)
        
        # Select best predicted algorithm
        best_algorithm = min(predicted_performance, key=predicted_performance.get)
        return self.algorithms[best_algorithm]
```

**B∆∞·ªõc 4: Benchmarking framework**

**Standardized evaluation protocol:**
```python
class OptimizationBenchmark:
    def __init__(self, problem_suite, algorithms, metrics):
        self.problems = problem_suite
        self.algorithms = algorithms
        self.metrics = metrics
        self.results = {}
    
    def run_benchmark(self, n_runs=10, max_time=60):
        for problem_name, problem in self.problems.items():
            self.results[problem_name] = {}
            
            for alg_name, algorithm in self.algorithms.items():
                print(f"Running {alg_name} on {problem_name}")
                
                alg_results = []
                for run in range(n_runs):
                    result = self.run_single_trial(algorithm, problem, max_time)
                    alg_results.append(result)
                
                self.results[problem_name][alg_name] = alg_results
    
    def generate_report(self):
        # Performance profiles
        # Statistical tests
        # Ranking tables
        # Convergence plots
        pass
    
    def performance_profile(self, metric='function_value'):
        # Data profiles and performance profiles
        # Dolan-Mor√© plots
        pass
```

</details>

---

## üìù **B√†i t·∫≠p 10: Real-world optimization pipeline**

**ƒê·ªÅ b√†i:** X√¢y d·ª±ng pipeline t·ªëi ∆∞u ho√†n ch·ªânh cho b√†i to√°n th·ª±c t·∫ø:

a) **C√¥ng th·ª©c h√≥a b√†i to√°n** v√† m√¥ h√¨nh h√≥a
b) **Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu** v√† k·ªπ thu·∫≠t ƒë·∫∑c tr∆∞ng
c) **Ch·ªçn thu·∫≠t to√°n** v√† ƒëi·ªÅu ch·ªânh
d) **Ki·ªÉm ch·ª©ng nghi·ªám** v√† gi·∫£i th√≠ch
e) **C√¢n nh·∫Øc tri·ªÉn khai**

**Nghi√™n c·ª©u ƒëi·ªÉn h√¨nh:** T·ªëi ∆∞u danh m·ª•c ƒë·∫ßu t∆∞ v·ªõi d·ªØ li·ªáu th·ªã tr∆∞·ªùng th·ª±c

**Th√†nh ph·∫ßn pipeline:**
- Thu th·∫≠p v√† l√†m s·∫°ch d·ªØ li·ªáu
- ∆Ø·ªõc l∆∞·ª£ng m√¥ h√¨nh r·ªßi ro
- X·ª≠ l√Ω r√†ng bu·ªôc
- Khung ki·ªÉm tra ng∆∞·ª£c
- Gi√°m s√°t hi·ªáu nƒÉng

**Y√™u c·∫ßu:**
1. L·∫≠p tr√¨nh ƒë·∫ßy ƒë·ªß t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi
2. X·ª≠ l√Ω c√°c ph·ª©c t·∫°p th·ª±c t·∫ø
3. X·ª≠ l√Ω l·ªói m·∫°nh m·∫Ω
4. Ki·∫øn tr√∫c c√≥ kh·∫£ nƒÉng m·ªü r·ªông

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Problem formulation**

**Portfolio optimization:**
$$\min_w w^T \Sigma w \quad \text{s.t.} \quad \mu^T w \geq r, \quad \mathbf{1}^T w = 1, \quad w \geq 0$$

**Real-world extensions:**
- Transaction costs
- Turnover constraints
- Sector constraints
- Risk budgeting

**Enhanced formulation:**
```python
class PortfolioOptimizer:
    def __init__(self, returns_data, transaction_costs=0.001):
        self.returns = returns_data
        self.n_assets = returns_data.shape[1]
        self.transaction_costs = transaction_costs
        
    def estimate_parameters(self, method='sample'):
        if method == 'sample':
            self.mu = np.mean(self.returns, axis=0)
            self.Sigma = np.cov(self.returns.T)
        elif method == 'shrinkage':
            self.mu, self.Sigma = self.ledoit_wolf_shrinkage()
        elif method == 'factor_model':
            self.mu, self.Sigma = self.factor_model_estimation()
    
    def add_constraints(self, constraints):
        # Sector constraints
        # Turnover limits
        # Position limits
        pass
    
    def solve(self, target_return, current_weights=None):
        # Formulate as convex optimization problem
        # Handle transaction costs
        # Solve using appropriate algorithm
        pass
```

**B∆∞·ªõc 2: Data preprocessing**

**Data quality issues:**
- Missing values
- Outliers
- Corporate actions
- Survivorship bias

**Preprocessing pipeline:**
```python
class DataPreprocessor:
    def __init__(self):
        self.scalers = {}
        self.outlier_detectors = {}
    
    def clean_returns_data(self, raw_data):
        # Handle missing values
        cleaned_data = self.handle_missing_values(raw_data)
        
        # Detect and handle outliers
        cleaned_data = self.handle_outliers(cleaned_data)
        
        # Adjust for corporate actions
        cleaned_data = self.adjust_corporate_actions(cleaned_data)
        
        return cleaned_data
    
    def handle_missing_values(self, data, method='forward_fill'):
        if method == 'forward_fill':
            return data.fillna(method='ffill')
        elif method == 'interpolation':
            return data.interpolate()
        elif method == 'factor_model':
            return self.factor_model_imputation(data)
    
    def detect_outliers(self, data, method='iqr', threshold=3):
        if method == 'iqr':
            Q1 = data.quantile(0.25)
            Q3 = data.quantile(0.75)
            IQR = Q3 - Q1
            outliers = (data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))
        elif method == 'zscore':
            z_scores = np.abs(stats.zscore(data))
            outliers = z_scores > threshold
        
        return outliers
```

**B∆∞·ªõc 3: Algorithm selection v√† tuning**

**Multi-stage selection process:**
```python
class AlgorithmSelector:
    def __init__(self):
        self.algorithms = {
            'interior_point': self.interior_point_solver,
            'active_set': self.active_set_solver,
            'admm': self.admm_solver,
            'frank_wolfe': self.frank_wolfe_solver
        }
        self.performance_history = {}
    
    def select_algorithm(self, problem_characteristics):
        # Problem size
        n_assets = problem_characteristics['n_assets']
        n_constraints = problem_characteristics['n_constraints']
        
        # Sparsity pattern
        constraint_sparsity = problem_characteristics['sparsity']
        
        # Historical performance
        if self.performance_history:
            predicted_performance = self.predict_performance(problem_characteristics)
            return min(predicted_performance, key=predicted_performance.get)
        
        # Default heuristics
        if n_assets < 100:
            return 'interior_point'
        elif constraint_sparsity > 0.8:
            return 'active_set'
        else:
            return 'admm'
    
    def tune_hyperparameters(self, algorithm, problem, validation_set):
        # Bayesian optimization for hyperparameter tuning
        optimizer = BayesianHyperparameterOptimizer(
            objective=lambda params: self.cross_validate(algorithm, params, validation_set),
            bounds=self.get_parameter_bounds(algorithm)
        )
        
        best_params = optimizer.optimize(n_iterations=50)
        return best_params
```

**B∆∞·ªõc 4: Solution validation**

**Backtesting framework:**
```python
class PortfolioBacktester:
    def __init__(self, returns_data, rebalance_frequency='monthly'):
        self.returns = returns_data
        self.rebalance_frequency = rebalance_frequency
        self.results = {}
    
    def backtest(self, optimizer, start_date, end_date):
        rebalance_dates = self.get_rebalance_dates(start_date, end_date)
        portfolio_weights = []
        portfolio_returns = []
        
        for i, date in enumerate(rebalance_dates[:-1]):
            # Estimate parameters using data up to current date
            historical_data = self.returns.loc[:date]
            optimizer.estimate_parameters(historical_data)
            
            # Optimize portfolio
            current_weights = portfolio_weights[-1] if portfolio_weights else None
            weights = optimizer.solve(current_weights=current_weights)
            portfolio_weights.append(weights)
            
            # Calculate returns until next rebalance
            next_date = rebalance_dates[i + 1]
            period_returns = self.returns.loc[date:next_date]
            portfolio_return = (period_returns * weights).sum(axis=1)
            portfolio_returns.extend(portfolio_return.tolist())
        
        return self.analyze_performance(portfolio_returns)
    
    def analyze_performance(self, returns):
        returns = np.array(returns)
        
        metrics = {
            'total_return': np.prod(1 + returns) - 1,
            'annualized_return': np.mean(returns) * 252,
            'volatility': np.std(returns) * np.sqrt(252),
            'sharpe_ratio': np.mean(returns) / np.std(returns) * np.sqrt(252),
            'max_drawdown': self.calculate_max_drawdown(returns),
            'var_95': np.percentile(returns, 5),
            'cvar_95': np.mean(returns[returns <= np.percentile(returns, 5)])
        }
        
        return metrics
```

**B∆∞·ªõc 5: Deployment considerations**

**Production system requirements:**
```python
class ProductionOptimizer:
    def __init__(self, config):
        self.config = config
        self.model_store = ModelStore()
        self.data_pipeline = DataPipeline()
        self.monitoring = PerformanceMonitor()
    
    def optimize_portfolio(self, request):
        try:
            # Validate input
            self.validate_request(request)
            
            # Load latest model
            model = self.model_store.load_latest_model()
            
            # Get fresh data
            data = self.data_pipeline.get_latest_data()
            
            # Preprocess data
            processed_data = self.preprocess_data(data)
            
            # Optimize
            solution = model.optimize(processed_data, request.constraints)
            
            # Validate solution
            self.validate_solution(solution)
            
            # Log performance
            self.monitoring.log_optimization(request, solution)
            
            return solution
            
        except Exception as e:
            self.monitoring.log_error(e)
            return self.fallback_solution(request)
    
    def fallback_solution(self, request):
        # Simple equal-weight or market-cap weighted portfolio
        # Ensure system remains operational
        pass
    
    def health_check(self):
        # System health monitoring
        # Data freshness checks
        # Model performance monitoring
        pass
```

**Monitoring v√† alerting:**
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics_store = MetricsStore()
        self.alert_manager = AlertManager()
    
    def monitor_optimization_performance(self):
        # Track solve times
        # Monitor convergence rates
        # Detect performance degradation
        
        recent_performance = self.get_recent_performance()
        
        if self.detect_anomaly(recent_performance):
            self.alert_manager.send_alert("Optimization performance degraded")
    
    def monitor_portfolio_performance(self):
        # Track realized returns
        # Compare with expectations
        # Risk monitoring
        pass
```

</details>

---

## üí° M·∫πo Th·ª±c H√†nh

#### **Khi l·∫≠p tr√¨nh thu·∫≠t to√°n t·ªëi ∆∞u:**
- **B·∫Øt ƒë·∫ßu ƒë∆°n gi·∫£n:** L·∫≠p tr√¨nh phi√™n b·∫£n c∆° b·∫£n tr∆∞·ªõc khi t·ªëi ∆∞u h√≥a
- **V√©c-t∆° h√≥a:** S·ª≠ d·ª•ng c√°c ph√©p to√°n NumPy thay v√¨ v√≤ng l·∫∑p
- **·ªîn ƒë·ªãnh s·ªë:** X·ª≠ l√Ω ƒëi·ªÅu ki·ªán x·∫•u v√† c√°c tr∆∞·ªùng h·ª£p bi√™n
- **Ti√™u ch√≠ h·ªôi t·ª•:** Nhi·ªÅu ƒëi·ªÅu ki·ªán d·ª´ng

#### **Khi ƒëi·ªÅu ch·ªânh si√™u tham s·ªë:**
- **Ki·ªÉm ƒë·ªãnh ch√©o:** Tr√°nh kh·ªõp qu√° v·ªõi b√†i to√°n c·ª• th·ªÉ
- **T·ªëi ∆∞u Bayes:** Hi·ªáu qu·∫£ h∆°n t√¨m ki·∫øm l∆∞·ªõi
- **ƒêi·ªÅu ch·ªânh theo b√†i to√°n:** C√°c b√†i to√°n kh√°c nhau c·∫ßn c√†i ƒë·∫∑t kh√°c nhau
- **Ng√¢n s√°ch t√≠nh to√°n:** C√¢n b·∫±ng ƒë·ªô ch√≠nh x√°c v√† t·ªëc ƒë·ªô

#### **Khi tri·ªÉn khai thu·∫≠t to√°n:**
- **T√≠nh m·∫°nh m·∫Ω:** X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p bi√™n v√† l·ªói m·ªôt c√°ch kh√©o l√©o
- **Gi√°m s√°t:** Theo d√µi hi·ªáu nƒÉng trong m√¥i tr∆∞·ªùng s·∫£n xu·∫•t
- **Chi·∫øn l∆∞·ª£c d·ª± ph√≤ng:** ƒê·∫£m b·∫£o h·ªá th·ªëng v·∫´n ho·∫°t ƒë·ªông
- **T√†i li·ªáu:** API r√µ r√†ng v√† h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng

---

## üìö T√†i li·ªáu tham kh·∫£o

1. **Boyd, S., & Vandenberghe, L.** (2004). *Convex Optimization*. Cambridge University Press.
   - Chapters 9-11: Algorithms

2. **Nocedal, J., & Wright, S. J.** (2006). *Numerical Optimization*. Springer.

3. **Beck, A.** (2017). *First-Order Methods in Optimization*. SIAM.

4. **Parikh, N., & Boyd, S.** (2014). *Proximal Algorithms*. Foundations and Trends in Optimization.

5. **Bottou, L., Curtis, F. E., & Nocedal, J.** (2018). *Optimization Methods for Large-Scale Machine Learning*. SIAM Review.

6. **Sra, S., Nowozin, S., & Wright, S. J.** (2012). *Optimization for Machine Learning*. MIT Press.
