---
layout: post
title: 12-8 B√†i T·∫≠p Th·ª±c H√†nh - ƒêi·ªÅu Ki·ªán KKT
chapter: '12'
order: 9
owner: GitHub Copilot
lang: vi
categories:
- chapter12
lesson_type: required
---

# B√†i T·∫≠p Th·ª±c H√†nh - ƒêi·ªÅu Ki·ªán KKT (Karush-Kuhn-Tucker)

C√°c b√†i t·∫≠p ƒë∆∞·ª£c tham kh·∫£o t·ª´ Boyd & Vandenberghe (2004), Nocedal & Wright (2006), v√† Bertsekas (1999).

---

## üìù **Ph·∫ßn I: Ki·ªÉm ch·ª©ng ƒêi·ªÅu ki·ªán KKT**

### **B√†i t·∫≠p 1: B√†i to√°n c∆° b·∫£n (Boyd & Vandenberghe, Ex. 5.1)**

Cho b√†i to√°n:

$$
\begin{align}
\min_{x} \quad & x_1^2 + x_2^2 \\
\text{s.t.} \quad & x_1 + x_2 = 1 \\
& x_1 \geq 0
\end{align}
$$

Ki·ªÉm tra hai nghi·ªám ·ª©ng vi√™n:
1. $$x^{(1)} = (0.5, 0.5)$$, $$\nu = 1$$, $$\lambda = 0$$
2. $$x^{(2)} = (0, 1)$$, $$\nu = 2$$, $$\lambda = 2$$

**Y√™u c·∫ßu:** Vi·∫øt ƒëi·ªÅu ki·ªán KKT, ki·ªÉm tra t·ª´ng ƒëi·ªÅu ki·ªán, x√°c ƒë·ªãnh nghi·ªám t·ªëi ∆∞u.

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**Lagrangian:** $$L(x,\nu,\lambda) = x_1^2 + x_2^2 - \nu(x_1+x_2-1) - \lambda(-x_1)$$

**B·ªën ƒëi·ªÅu ki·ªán KKT:**

1. **Stationarity:** $$2x_1 - \nu + \lambda = 0$$, $$2x_2 - \nu = 0$$
2. **Primal Feasibility:** $$x_1 + x_2 = 1$$, $$x_1 \geq 0$$
3. **Dual Feasibility:** $$\lambda \geq 0$$
4. **Complementary Slackness:** $$\lambda \cdot (-x_1) = 0$$

**Ki·ªÉm tra $$x^{(1)} = (0.5,0.5)$$, $$\nu=1$$, $$\lambda=0$$:**
- Stationarity: $$2(0.5)-1+0=0$$ ‚úì, $$2(0.5)-1=0$$ ‚úì
- Primal Feasibility: $$0.5+0.5=1$$ ‚úì, $$0.5 \geq 0$$ ‚úì
- Dual Feasibility: $$0 \geq 0$$ ‚úì
- Comp. Slackness: $$0 \cdot (-0.5)=0$$ ‚úì

**Th·ªèa m√£n!** Gi√° tr·ªã: $$f^{(1)} = 0.5$$

**Ki·ªÉm tra $$x^{(2)} = (0,1)$$, $$\nu=2$$, $$\lambda=2$$:**
- Stationarity: $$0-2+2=0$$ ‚úì, $$2-2=0$$ ‚úì
- Primal Feasibility: $$0+1=1$$ ‚úì, $$0 \geq 0$$ ‚úì
- Dual Feasibility: $$2 \geq 0$$ ‚úì
- Comp. Slackness: $$2 \cdot 0=0$$ ‚úì

**Th·ªèa m√£n!** Gi√° tr·ªã: $$f^{(2)} = 1$$

**K·∫øt lu·∫≠n:** C·∫£ hai th·ªèa KKT nh∆∞ng $$x^* = (0.5,0.5)$$ l√† t·ªëi ∆∞u v√¨ $$f^{(1)} < f^{(2)}$$.

**Gi·∫£i th√≠ch:** B√†i to√°n l·ªìi n√™n KKT ƒë·ªß cho global optimum. Nghi·ªám th·ª© 2 kh√¥ng t·ªëi ∆∞u d√π th·ªèa KKT.

</details>

---

### **B√†i t·∫≠p 2: QP ƒë∆°n gi·∫£n (Nocedal & Wright, Ex. 12.1)**

$$
\begin{align}
\min_{x} \quad & \frac{1}{2}(x_1^2 + x_2^2) \\
\text{s.t.} \quad & x_1 + x_2 = 1 \\
& x_1, x_2 \geq 0
\end{align}
$$

**Y√™u c·∫ßu:** Gi·∫£i b·∫±ng ph∆∞∆°ng ph√°p active set.

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**3 tr∆∞·ªùng h·ª£p active set:**

**TH1:** Kh√¥ng c√≥ r√†ng bu·ªôc $$\geq 0$$ active ($$\lambda_1=\lambda_2=0$$)

T·ª´ stationarity: $$x_1=\nu$$, $$x_2=\nu$$  
T·ª´ $$x_1+x_2=1$$: $$2\nu=1 \Rightarrow \nu=0.5$$

‚Üí $$x=(0.5, 0.5)$$, $$f=0.25$$, feasible ‚úì

**TH2:** $$x_1=0$$ active

$$x_2=1$$, stationarity cho $$x_2$$: $$\nu=1$$  
Stationarity cho $$x_1$$: $$\lambda_1=1$$

‚Üí $$x=(0,1)$$, $$f=0.5$$, feasible ‚úì

**TH3:** $$x_2=0$$ active

‚Üí $$x=(1,0)$$, $$f=0.5$$, feasible ‚úì

**Nghi·ªám t·ªëi ∆∞u:** $$x^*=(0.5,0.5)$$ v·ªõi $$f^*=0.25$$

</details>

---

## üìù **Ph·∫ßn II: ·ª®ng d·ª•ng Portfolio Optimization**

### **B√†i t·∫≠p 3: Markowitz Mean-Variance**

$$
\begin{align}
\min_{x} \quad & \frac{1}{2} x^T \Sigma x \\
\text{s.t.} \quad & \mu^T x \geq r_{\min} \\
& \mathbf{1}^T x = 1 \\
& x \geq 0
\end{align}
$$

V·ªõi $$n=3$$:

$$
\Sigma = \begin{bmatrix} 0.04 & 0.01 & 0 \\ 0.01 & 0.09 & 0.02 \\ 0 & 0.02 & 0.16 \end{bmatrix}, \quad
\mu = \begin{bmatrix} 0.10 \\ 0.15 \\ 0.08 \end{bmatrix}, \quad
r_{\min} = 0.12
$$

**Y√™u c·∫ßu:** Gi·∫£ s·ª≠ $$x_3=0$$, t√¨m $$x_1, x_2$$ v√† c√°c dual variables.

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**Gi·∫£ s·ª≠:** $$x_3=0$$ ($$\nu_{2,3} > 0$$), $$x_1,x_2>0$$, r√†ng bu·ªôc return ch·∫∑t ($$\lambda>0$$)

**R√†ng bu·ªôc:**
$$
\begin{cases}
x_1 + x_2 = 1 \\
0.10x_1 + 0.15x_2 = 0.12
\end{cases}
$$

T·ª´ ph∆∞∆°ng tr√¨nh 2: $$0.10x_1 + 0.15x_2 = 0.12$$  
Th·∫ø $$x_1 = 1-x_2$$:

$$
0.10(1-x_2) + 0.15x_2 = 0.12 \\
0.10 + 0.05x_2 = 0.12 \\
x_2 = 0.4
$$

‚Üí $$x_1 = 0.6$$

**Nghi·ªám:** $$x^* = (0.6, 0.4, 0)^T$$

**T√≠nh dual variables t·ª´ stationarity:**

$$\Sigma x^* = \begin{bmatrix} 0.028 \\ 0.042 \\ 0.008 \end{bmatrix}$$

Stationarity: $$\Sigma x^* = \lambda\mu - \nu_1\mathbf{1} - \nu_2$$

T·ª´ c√°c ph∆∞∆°ng tr√¨nh v·ªõi $$\nu_{2,1}=\nu_{2,2}=0$$:

$$
\begin{cases}
0.028 = 0.10\lambda - \nu_1 \\
0.042 = 0.15\lambda - \nu_1
\end{cases}
$$

Tr·ª´: $$0.014 = 0.05\lambda \Rightarrow \lambda = 0.28$$  
‚Üí $$\nu_1 = 0$$

T·ª´ ph∆∞∆°ng tr√¨nh 3:
$$\nu_{2,3} = 0.08(0.28) - 0.008 = 0.0144 > 0$$ ‚úì

**√ù nghƒ©a:**
- $$\lambda^*=0.28$$: Shadow price c·ªßa r√†ng bu·ªôc return (gi·∫£m $$r_{\min}$$ 1% ‚Üí risk gi·∫£m 0.28%)
- $$\nu_{2,3}^*=0.0144$$: T√†i s·∫£n 3 c√≥ Sharpe ratio k√©m, kh√¥ng ƒë·∫ßu t∆∞

</details>

---

## üìù **Ph·∫ßn III: Support Vector Machines**

### **B√†i t·∫≠p 4: SVM Hard-Margin (Boyd & Vandenberghe, Ex. 8.6)**

**D·ªØ li·ªáu:**
- L·ªõp +1: $$(1,2)$$, $$(2,3)$$, $$(3,3)$$
- L·ªõp -1: $$(1,1)$$, $$(2,1)$$, $$(3,2)$$

**Primal:**

$$
\begin{align}
\min_{w,b} \quad & \frac{1}{2}\|w\|^2 \\
\text{s.t.} \quad & y_i(w^Tx_i + b) \geq 1, \quad i=1,\ldots,6
\end{align}
$$

**Dual:**

$$
\begin{align}
\max_{\alpha} \quad & \sum_i \alpha_i - \frac{1}{2}\sum_{i,j} \alpha_i\alpha_j y_iy_j x_i^Tx_j \\
\text{s.t.} \quad & \sum_i \alpha_i y_i = 0 \\
& \alpha_i \geq 0
\end{align}
$$

**Y√™u c·∫ßu:** X√°c ƒë·ªãnh support vectors v√† hyperplane.

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**Quan s√°t h√¨nh h·ªçc:** Hai l·ªõp t√°ch r√µ r√†ng. Support vectors c√≥ th·ªÉ l√† c√°c ƒëi·ªÉm g·∫ßn nh·∫•t gi·ªØa hai l·ªõp.

**Gi·∫£ s·ª≠ nghi·ªám (t·ª´ solver):**
- Support vectors: $$x_1=(1,2)$$, $$x_4=(1,1)$$, $$x_6=(3,2)$$
- $$\alpha_1^* = 0.5$$, $$\alpha_4^* = 0.3$$, $$\alpha_6^* = 0.2$$
- C√°c $$\alpha$$ kh√°c = 0

**T√≠nh $$w^*$$:**

$$
w^* = \sum_i \alpha_i^* y_i x_i = 0.5(1)(1,2) - 0.3(1,1) - 0.2(3,2)
$$

$$
= (0.5,1.0) - (0.3,0.3) - (0.6,0.4) = (-0.4, 0.3)
$$

**T√≠nh $$b^*$$ t·ª´ SV $$x_1$$:**

$$y_1(w^{*T}x_1 + b^*) = 1$$

$$1 \cdot ((-0.4)(1) + (0.3)(2) + b^*) = 1$$

$$-0.4 + 0.6 + b^* = 1 \Rightarrow b^* = 0.8$$

**Decision boundary:** $$-0.4x_1 + 0.3x_2 + 0.8 = 0$$ hay $$x_2 = \frac{4x_1-8}{3}$$

*(L∆∞u √Ω: C·∫ßn solver s·ªë th·ª±c t·∫ø ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c)*

</details>

---

## üìù **Ph·∫ßn IV: Water-Filling Algorithm**

### **B√†i t·∫≠p 5: Power Allocation (Boyd & Vandenberghe, Ex. 5.7)**

$$
\begin{align}
\max_{p} \quad & \sum_{i=1}^n \log(1 + p_i/\sigma_i^2) \\
\text{s.t.} \quad & \sum_i p_i \leq P_{\text{total}} \\
& p_i \geq 0
\end{align}
$$

V·ªõi $$n=4$$, $$\sigma^2=(1,2,3,4)$$, $$P_{\text{total}}=10$$.

**Y√™u c·∫ßu:** Suy ra c√¥ng th·ª©c water-filling v√† t√≠nh nghi·ªám.

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**ƒêi·ªÅu ki·ªán KKT (chuy·ªÉn v·ªÅ min):**

Lagrangian: $$L = -\sum \log(1+p_i/\sigma_i^2) + \lambda(\sum p_i - P) - \sum \mu_i p_i$$

Stationarity: $$\frac{\partial L}{\partial p_i} = -\frac{1}{\sigma_i^2 + p_i} + \lambda - \mu_i = 0$$

**Ph√¢n t√≠ch:**

- N·∫øu $$p_i > 0$$: $$\mu_i=0 \Rightarrow \frac{1}{\sigma_i^2+p_i}=\lambda \Rightarrow p_i = \frac{1}{\lambda}-\sigma_i^2$$
- N·∫øu $$p_i = 0$$: $$\mu_i \geq 0 \Rightarrow \sigma_i^2 \geq \frac{1}{\lambda}$$

**C√¥ng th·ª©c water-filling:**

$$
\boxed{p_i^* = \max\left(0, \frac{1}{\lambda^*} - \sigma_i^2\right)}
$$

v·ªõi $$\lambda^*$$ sao cho $$\sum p_i^* = P_{\text{total}}$$.

---

**T√≠nh nghi·ªám:**

Gi·∫£ s·ª≠ t·∫•t c·∫£ k√™nh active:

$$
\sum_{i=1}^4 \left(\frac{1}{\lambda}-\sigma_i^2\right) = 10
$$

$$
\frac{4}{\lambda} - (1+2+3+4) = 10
$$

$$
\frac{4}{\lambda} = 20 \Rightarrow \lambda = 0.2
$$

**Water level:** $$\frac{1}{\lambda} = 5$$

**C√¥ng su·∫•t:**
- $$p_1 = 5-1 = 4$$ ‚úì
- $$p_2 = 5-2 = 3$$ ‚úì
- $$p_3 = 5-3 = 2$$ ‚úì
- $$p_4 = 5-4 = 1$$ ‚úì

**T·ªïng:** $$4+3+2+1=10$$ ‚úì

**Nghi·ªám:** $$p^* = (4,3,2,1)$$

**Gi·∫£i th√≠ch Water Level:**

```
Water level = 5
|     |     |     |
|  4  |  3  |  2  |  1  |  ‚Üê C√¥ng su·∫•t
+-----+-----+-----+-----+
|  1  |  2  |  3  |  4  |  ‚Üê Noise floor
+-----+-----+-----+-----+
  p‚ÇÅ    p‚ÇÇ    p‚ÇÉ    p‚ÇÑ
```

K√™nh t·ªët (noise th·∫•p) nh·∫≠n nhi·ªÅu c√¥ng su·∫•t h∆°n!

**Capacity:** 

$$C = \sum \log_2(1+p_i^*/\sigma_i^2) \approx 4.70 \text{ bits/s/Hz}$$

</details>

---

## üìù **Ph·∫ßn V: B√†i t·∫≠p N√¢ng cao**

### **B√†i t·∫≠p 6: Constrained Least Squares (Bertsekas, Ex. 3.2.2)**

$$
\begin{align}
\min_{x} \quad & \frac{1}{2}\|Ax-b\|^2 \\
\text{s.t.} \quad & Cx = d \\
& x \geq 0
\end{align}
$$

V·ªõi:

$$
A = \begin{bmatrix} 1&1\\1&-1\\2&0 \end{bmatrix}, \quad
b = \begin{bmatrix} 2\\0\\3 \end{bmatrix}, \quad
C = [1\ 1], \quad
d = 2
$$

**Y√™u c·∫ßu:** Gi·∫£i b·∫±ng KKT.

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

$$\nabla f(x) = A^TAx - A^Tb$$

$$
A^TA = \begin{bmatrix} 6&2\\2&2 \end{bmatrix}, \quad
A^Tb = \begin{bmatrix} 8\\2 \end{bmatrix}
$$

**KKT system (kh√¥ng c√≥ $$x \geq 0$$):**

$$
\begin{bmatrix} 6&2&-1\\2&2&-1\\1&1&0 \end{bmatrix}
\begin{bmatrix} x_1\\x_2\\\nu \end{bmatrix} =
\begin{bmatrix} 8\\2\\2 \end{bmatrix}
$$

Gi·∫£i:
- T·ª´ (3): $$x_1+x_2=2$$
- T·ª´ (1)-(2): $$4x_1=6 \Rightarrow x_1=1.5, x_2=0.5$$
- T·ª´ (1): $$\nu = 2$$

**Ki·ªÉm tra $$x \geq 0$$:** $$x_1=1.5>0$$, $$x_2=0.5>0$$ ‚úì

**Ki·ªÉm tra $$\lambda$$:**

$$\lambda = A^TAx - A^Tb - C^T\nu = \begin{bmatrix} 0\\0 \end{bmatrix} \geq 0$$ ‚úì

**Nghi·ªám:** $$x^*=(1.5, 0.5)^T$$, $$f^*=0.5$$

</details>

---

### **B√†i t·∫≠p 7: Penalty Method (Nocedal & Wright, Ex. 17.1)**

$$
\begin{align}
\min_{x} \quad & x_1 + x_2 \\
\text{s.t.} \quad & x_1^2 + x_2^2 = 1
\end{align}
$$

**Penalty:** $$\min \phi(x;\mu) = x_1+x_2 + \frac{\mu}{2}(x_1^2+x_2^2-1)^2$$

**Y√™u c·∫ßu:** Gi·∫£i b·∫±ng KKT, t√≠nh nghi·ªám penalty v·ªõi $$\mu=1,10,100$$, ph√¢n t√≠ch h·ªôi t·ª•.

<details>
<summary><strong>üí° L·ªùi gi·∫£i</strong></summary>

**Gi·∫£i b·∫±ng KKT:**

Lagrangian: $$L = x_1+x_2 - \nu(x_1^2+x_2^2-1)$$

Stationarity: $$1-2\nu x_1=0$$, $$1-2\nu x_2=0$$ ‚Üí $$x_1=x_2=\frac{1}{2\nu}$$

Feasibility: $$\frac{1}{4\nu^2}+\frac{1}{4\nu^2}=1 \Rightarrow \nu = \pm\frac{1}{\sqrt{2}}$$

**Hai nghi·ªám KKT:**
1. $$x=(1/\sqrt{2}, 1/\sqrt{2})$$, $$f=\sqrt{2}$$
2. $$x=(-1/\sqrt{2}, -1/\sqrt{2})$$, $$f=-\sqrt{2}$$

**T·ªëi ∆∞u (min):** $$x^* = (-1/\sqrt{2}, -1/\sqrt{2})$$

---

**Penalty method:**

FOC: $$1 + 2\mu x_i(x_1^2+x_2^2-1)=0$$

V·ªõi $$x_1=x_2=x$$: $$1 + 2\mu x(2x^2-1)=0$$ hay $$4\mu x^3 - 2\mu x + 1=0$$

**Nghi·ªám s·ªë:**
- $$\mu=1$$: $$x \approx -0.618$$
- $$\mu=10$$: $$x \approx -0.700$$
- $$\mu=100$$: $$x \approx -0.707 \approx -1/\sqrt{2}$$

**H·ªôi t·ª•:** Khi $$\mu \to \infty$$, nghi·ªám penalty h·ªôi t·ª• ƒë·∫øn nghi·ªám KKT!

**M·ªëi li√™n h·ªá:** $$\nu \approx \mu(x_1^2+x_2^2-1)$$

</details>

---

## üí° **T·ªïng k·∫øt Chi·∫øn l∆∞·ª£c**

### **Ki·ªÉm ch·ª©ng KKT:**
- Ki·ªÉm tra **4 ƒëi·ªÅu ki·ªán** ri√™ng bi·ªát
- KKT **c·∫ßn** cho local optimum (v·ªõi CQ), **ƒë·ªß** cho global optimum (b√†i to√°n l·ªìi)

### **Gi·∫£i b·∫±ng KKT:**
- **Active set strategy:** Th·ª≠ c√°c tr∆∞·ªùng h·ª£p active set
- Gi·∫£i h·ªá KKT t·ª´ stationarity + active constraints
- Ki·ªÉm tra feasibility v√† so s√°nh objective

### **Complementary Slackness:**
- $$\lambda_i > 0 \Rightarrow$$ r√†ng bu·ªôc $$i$$ active
- **Shadow price:** $$\lambda_i^*$$ = gi√° tr·ªã bi√™n c·ªßa r√†ng bu·ªôc $$i$$

### **B√†i to√°n l·ªìi:**
- KKT ƒë·ªß ‚Üí m·ªôt KKT point l√† global optimal
- Strong duality: $$f^*=g^*$$

---

## üìö **T√†i li·ªáu Tham kh·∫£o**

1. **Boyd, S., & Vandenberghe, L.** (2004). *Convex Optimization*. Cambridge University Press. Chapter 5.

2. **Nocedal, J., & Wright, S. J.** (2006). *Numerical Optimization* (2nd ed.). Springer. Chapters 12, 16-17.

3. **Bertsekas, D. P.** (1999). *Nonlinear Programming* (2nd ed.). Athena Scientific. Chapter 3.

4. **Luenberger, D. G., & Ye, Y.** (2008). *Linear and Nonlinear Programming* (3rd ed.). Springer. Chapter 10.

5. **Bazaraa, M. S., Sherali, H. D., & Shetty, C. M.** (2006). *Nonlinear Programming: Theory and Algorithms* (3rd ed.). Wiley.

