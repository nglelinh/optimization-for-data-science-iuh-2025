---
layout: post
title: 12-8 B√†i T·∫≠p Th·ª±c H√†nh - ƒêi·ªÅu Ki·ªán KKT
chapter: '12'
order: 9
owner: GitHub Copilot
lang: vi
categories:
- chapter12
lesson_type: required
---

# B√†i T·∫≠p Th·ª±c H√†nh - ƒêi·ªÅu Ki·ªán KKT

## üìù **B√†i t·∫≠p 1: KKT Conditions Framework v√† Verification**

**ƒê·ªÅ b√†i:** (Tham kh·∫£o Boyd & Vandenberghe, Chapter 12)
L·∫≠p tr√¨nh khung h·ªá th·ªëng ƒë·ªÉ ki·ªÉm ch·ª©ng v√† gi·∫£i ƒëi·ªÅu ki·ªán KKT:

a) **C√¥ng c·ª• ki·ªÉm tra ƒëi·ªÅu ki·ªán KKT** cho b√†i to√°n c√≥ r√†ng bu·ªôc t·ªïng qu√°t
b) **Nghi·ªám gi·∫£i t√≠ch** s·ª≠ d·ª•ng ƒëi·ªÅu ki·ªán KKT
c) **X√°c ƒë·ªãnh t·∫≠p ho·∫°t ƒë·ªông** v√† ph√¢n t√≠ch tr∆∞·ªùng h·ª£p
d) **Ki·ªÉm ch·ª©ng t√≠nh t·ªëi ∆∞u** cho c√°c nghi·ªám ·ª©ng vi√™n

**Y√™u c·∫ßu:**
1. Khung ki·ªÉm ch·ª©ng KKT c√≥ h·ªá th·ªëng
2. C√°c ph∆∞∆°ng ph√°p nghi·ªám gi·∫£i t√≠ch
3. Tri·ªÉn khai s·ªë
4. Gi·∫£i th√≠ch h√¨nh h·ªçc

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: KKT Conditions Framework**

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
import cvxpy as cp
from scipy.linalg import null_space

class KKTConditionsChecker:
    def __init__(self, tolerance=1e-6):
        self.tol = tolerance
        self.results = {}
        
    def check_kkt_conditions(self, x, lam, nu, objective, eq_constraints, ineq_constraints, 
                           problem_name="Unknown"):
        """
        Check all four KKT conditions for a given solution
        
        Parameters:
        - x: primal variables
        - lam: dual variables for inequality constraints (Œª ‚â• 0)
        - nu: dual variables for equality constraints (ŒΩ unrestricted)
        - objective: objective function and its gradient
        - eq_constraints: list of equality constraint functions and gradients
        - ineq_constraints: list of inequality constraint functions and gradients
        """
        
        print(f"KKT Conditions Verification: {problem_name}")
        print("=" * 50)
        
        # Extract function values and gradients
        f_val, grad_f = objective(x)
        
        eq_vals = []
        eq_grads = []
        for eq_constraint in eq_constraints:
            val, grad = eq_constraint(x)
            eq_vals.append(val)
            eq_grads.append(grad)
        
        ineq_vals = []
        ineq_grads = []
        for ineq_constraint in ineq_constraints:
            val, grad = ineq_constraint(x)
            ineq_vals.append(val)
            ineq_grads.append(grad)
        
        eq_vals = np.array(eq_vals)
        ineq_vals = np.array(ineq_vals)
        
        # Check each KKT condition
        results = {}
        
        # 1. Stationarity: ‚àáf + Œ£Œª·µ¢‚àáh·µ¢ + Œ£ŒΩ‚±º‚àál‚±º = 0
        lagrangian_grad = grad_f.copy()
        
        for i, grad in enumerate(ineq_grads):
            lagrangian_grad += lam[i] * grad
            
        for j, grad in enumerate(eq_grads):
            lagrangian_grad += nu[j] * grad
        
        stationarity_residual = np.linalg.norm(lagrangian_grad)
        stationarity_satisfied = stationarity_residual < self.tol
        
        print(f"1. Stationarity:")
        print(f"   ||‚àáL|| = {stationarity_residual:.8f}")
        print(f"   Satisfied: {'‚úì' if stationarity_satisfied else '‚úó'}")
        
        results['stationarity'] = {
            'satisfied': stationarity_satisfied,
            'residual': stationarity_residual,
            'gradient': lagrangian_grad
        }
        
        # 2. Complementary Slackness: Œª·µ¢ * h·µ¢(x) = 0 ‚àÄi
        comp_slack_violations = []
        comp_slack_satisfied = True
        
        print(f"\n2. Complementary Slackness:")
        for i in range(len(ineq_vals)):
            violation = abs(lam[i] * ineq_vals[i])
            comp_slack_violations.append(violation)
            
            if violation > self.tol:
                comp_slack_satisfied = False
            
            print(f"   Œª_{i} * h_{i}(x) = {lam[i]:.6f} * {ineq_vals[i]:.6f} = {lam[i] * ineq_vals[i]:.8f}")
        
        print(f"   Satisfied: {'‚úì' if comp_slack_satisfied else '‚úó'}")
        
        results['complementary_slackness'] = {
            'satisfied': comp_slack_satisfied,
            'violations': comp_slack_violations
        }
        
        # 3. Primal Feasibility: h·µ¢(x) ‚â§ 0, l‚±º(x) = 0
        primal_feasible = True
        
        print(f"\n3. Primal Feasibility:")
        
        # Inequality constraints
        for i, val in enumerate(ineq_vals):
            feasible = val <= self.tol
            if not feasible:
                primal_feasible = False
            print(f"   h_{i}(x) = {val:.6f} ‚â§ 0: {'‚úì' if feasible else '‚úó'}")
        
        # Equality constraints
        for j, val in enumerate(eq_vals):
            feasible = abs(val) <= self.tol
            if not feasible:
                primal_feasible = False
            print(f"   l_{j}(x) = {val:.6f} = 0: {'‚úì' if feasible else '‚úó'}")
        
        print(f"   Satisfied: {'‚úì' if primal_feasible else '‚úó'}")
        
        results['primal_feasibility'] = {
            'satisfied': primal_feasible,
            'ineq_values': ineq_vals,
            'eq_values': eq_vals
        }
        
        # 4. Dual Feasibility: Œª·µ¢ ‚â• 0 ‚àÄi
        dual_feasible = np.all(lam >= -self.tol)
        
        print(f"\n4. Dual Feasibility:")
        for i, val in enumerate(lam):
            feasible = val >= -self.tol
            print(f"   Œª_{i} = {val:.6f} ‚â• 0: {'‚úì' if feasible else '‚úó'}")
        
        print(f"   Satisfied: {'‚úì' if dual_feasible else '‚úó'}")
        
        results['dual_feasibility'] = {
            'satisfied': dual_feasible,
            'lambda_values': lam
        }
        
        # Overall KKT satisfaction
        all_satisfied = (stationarity_satisfied and comp_slack_satisfied and 
                        primal_feasible and dual_feasible)
        
        print(f"\n" + "="*50)
        print(f"Overall KKT Conditions: {'‚úì SATISFIED' if all_satisfied else '‚úó VIOLATED'}")
        
        if all_satisfied:
            print("This point satisfies all KKT conditions!")
            if self._is_convex_problem():
                print("Since the problem is convex, this is a global optimum.")
        
        results['overall'] = all_satisfied
        self.results[problem_name] = results
        
        return results
    
    def _is_convex_problem(self):
        """Check if problem is convex (simplified check)"""
        # This would need problem-specific implementation
        # For now, assume user specifies convexity
        return True
    
    def solve_kkt_analytically(self, objective, eq_constraints, ineq_constraints, 
                              initial_guess=None, problem_name="Analytical"):
        """
        Solve KKT conditions analytically using case analysis
        """
        
        print(f"\nAnalytical KKT Solution: {problem_name}")
        print("=" * 40)
        
        # This is a framework - specific implementation depends on problem structure
        print("Strategy:")
        print("1. Identify possible active sets")
        print("2. For each active set, solve KKT system")
        print("3. Check feasibility and optimality")
        print("4. Compare objective values")
        
        # Example implementation for simple cases
        return self._solve_simple_qp_kkt()
    
    def _solve_simple_qp_kkt(self):
        """Solve simple QP using KKT conditions"""
        
        # Example: min (1/2)x^T Q x + c^T x s.t. Ax ‚â§ b, Ex = d
        # This would be implemented based on specific problem structure
        
        print("\nExample: Simple QP Solution")
        print("For QP: min (1/2)x^T Q x + c^T x s.t. Ax ‚â§ b")
        print("KKT: Qx + c + A^T Œª = 0, Œª ‚â• 0, Ax ‚â§ b, Œª^T(Ax - b) = 0")
        
        return None

# Example 1: Simple constrained optimization
def example_simple_constrained():
    """Example: min x‚ÇÅ¬≤ + x‚ÇÇ¬≤ s.t. x‚ÇÅ + x‚ÇÇ = 1, x‚ÇÅ ‚â• 0"""
    
    print("Example 1: Simple Constrained Optimization")
    print("min x‚ÇÅ¬≤ + x‚ÇÇ¬≤ s.t. x‚ÇÅ + x‚ÇÇ = 1, x‚ÇÅ ‚â• 0")
    
    # Define problem functions
    def objective(x):
        f_val = x[0]**2 + x[1]**2
        grad_f = np.array([2*x[0], 2*x[1]])
        return f_val, grad_f
    
    def eq_constraint_1(x):
        # l‚ÇÅ(x) = x‚ÇÅ + x‚ÇÇ - 1 = 0
        val = x[0] + x[1] - 1
        grad = np.array([1, 1])
        return val, grad
    
    def ineq_constraint_1(x):
        # h‚ÇÅ(x) = -x‚ÇÅ ‚â§ 0 (i.e., x‚ÇÅ ‚â• 0)
        val = -x[0]
        grad = np.array([-1, 0])
        return val, grad
    
    # Test different candidate solutions
    checker = KKTConditionsChecker()
    
    # Case 1: Interior solution x‚ÇÅ > 0
    print("\n" + "="*60)
    print("Case 1: Interior solution (x‚ÇÅ > 0)")
    x1 = np.array([0.5, 0.5])
    lam1 = np.array([0.0])  # Œª‚ÇÅ = 0 (inactive constraint)
    nu1 = np.array([1.0])   # ŒΩ‚ÇÅ from stationarity
    
    results1 = checker.check_kkt_conditions(
        x1, lam1, nu1, objective, [eq_constraint_1], [ineq_constraint_1],
        "Interior Solution"
    )
    
    # Case 2: Boundary solution x‚ÇÅ = 0
    print("\n" + "="*60)
    print("Case 2: Boundary solution (x‚ÇÅ = 0)")
    x2 = np.array([0.0, 1.0])
    lam2 = np.array([2.0])  # Œª‚ÇÅ > 0 (active constraint)
    nu2 = np.array([2.0])   # ŒΩ‚ÇÅ from stationarity
    
    results2 = checker.check_kkt_conditions(
        x2, lam2, nu2, objective, [eq_constraint_1], [ineq_constraint_1],
        "Boundary Solution"
    )
    
    # Compare solutions
    f1_val, _ = objective(x1)
    f2_val, _ = objective(x2)
    
    print(f"\n" + "="*60)
    print("Solution Comparison:")
    print(f"Interior solution: f(x) = {f1_val:.6f}, KKT satisfied: {results1['overall']}")
    print(f"Boundary solution: f(x) = {f2_val:.6f}, KKT satisfied: {results2['overall']}")
    print(f"Optimal solution: {'Interior' if f1_val < f2_val else 'Boundary'}")
    
    return checker

# Run example
checker_result = example_simple_constrained()
```

**B∆∞·ªõc 2: Advanced KKT Analysis**

```python
class AdvancedKKTAnalyzer:
    def __init__(self):
        self.active_sets = []
        self.solutions = []
        
    def active_set_enumeration(self, ineq_constraints, n_vars):
        """
        Enumerate all possible active sets for systematic KKT solution
        """
        
        m = len(ineq_constraints)  # Number of inequality constraints
        
        print("Active Set Enumeration")
        print("=" * 30)
        print(f"Number of inequality constraints: {m}")
        print(f"Number of variables: {n_vars}")
        print(f"Maximum possible active sets: 2^{m} = {2**m}")
        
        active_sets = []
        
        # Generate all possible combinations of active constraints
        for i in range(2**m):
            active_set = []
            for j in range(m):
                if (i >> j) & 1:  # Check if j-th bit is set
                    active_set.append(j)
            active_sets.append(active_set)
        
        print(f"\nActive sets to consider:")
        for i, active_set in enumerate(active_sets):
            print(f"  {i}: Active constraints = {active_set}")
        
        return active_sets
    
    def solve_kkt_for_active_set(self, active_set, objective, eq_constraints, 
                                ineq_constraints, n_vars):
        """
        Solve KKT system for a given active set
        """
        
        print(f"\nSolving KKT for active set: {active_set}")
        print("-" * 40)
        
        # For active set, we have:
        # 1. Stationarity: ‚àáf + Œ£(active) Œª·µ¢‚àáh·µ¢ + Œ£ŒΩ‚±º‚àál‚±º = 0
        # 2. Active constraints: h·µ¢(x) = 0 for i in active_set
        # 3. Equality constraints: l‚±º(x) = 0
        # 4. Œª·µ¢ ‚â• 0 for active constraints, Œª·µ¢ = 0 for inactive
        
        # This is a simplified framework - actual implementation would
        # solve the linear system formed by stationarity + active constraints
        
        # Example structure:
        # [‚àá¬≤L  A_active^T  E^T] [x ]   [0]
        # [A_active  0      0  ] [Œª ] = [0]
        # [E         0      0  ] [ŒΩ ]   [0]
        
        print("KKT System Structure:")
        print("Stationarity: ‚àáf + A_active^T Œª + E^T ŒΩ = 0")
        print("Active constraints: A_active x = b_active")
        print("Equality constraints: E x = d")
        print("Non-negativity: Œª ‚â• 0")
        
        return None  # Placeholder for actual solution
    
    def geometric_interpretation(self, x_opt, active_constraints, objective):
        """
        Provide geometric interpretation of KKT conditions
        """
        
        print("\nGeometric Interpretation of KKT Conditions")
        print("=" * 45)
        
        f_val, grad_f = objective(x_opt)
        
        print(f"At optimal point x* = {x_opt}:")
        print(f"Objective gradient: ‚àáf(x*) = {grad_f}")
        
        print(f"\nActive constraints:")
        for i, constraint in enumerate(active_constraints):
            val, grad = constraint(x_opt)
            print(f"  Constraint {i}: gradient = {grad}")
        
        print(f"\nKKT Interpretation:")
        print("- ‚àáf(x*) is a linear combination of active constraint gradients")
        print("- This means ‚àáf(x*) is orthogonal to the feasible directions")
        print("- The optimal point lies at the intersection of active constraints")
        
        return grad_f

# Example with geometric visualization
def visualize_kkt_geometry():
    """Visualize KKT conditions geometrically"""
    
    print("Geometric Visualization of KKT Conditions")
    print("=" * 45)
    
    # Problem: min x‚ÇÅ¬≤ + x‚ÇÇ¬≤ s.t. x‚ÇÅ + x‚ÇÇ ‚â• 1, x‚ÇÅ ‚â• 0, x‚ÇÇ ‚â• 0
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # Plot 1: Feasible region and optimal point
    ax1 = axes[0]
    
    # Create grid
    x1 = np.linspace(-0.5, 2, 100)
    x2 = np.linspace(-0.5, 2, 100)
    X1, X2 = np.meshgrid(x1, x2)
    
    # Objective function contours
    Z = X1**2 + X2**2
    contours = ax1.contour(X1, X2, Z, levels=20, colors='blue', alpha=0.6)
    ax1.clabel(contours, inline=True, fontsize=8)
    
    # Constraints
    # x‚ÇÅ + x‚ÇÇ ‚â• 1
    x1_line = np.linspace(0, 2, 100)
    x2_line = 1 - x1_line
    ax1.plot(x1_line, x2_line, 'r-', linewidth=2, label='x‚ÇÅ + x‚ÇÇ = 1')
    
    # Feasible region
    ax1.fill_between(x1_line, x2_line, 2, where=(x2_line >= 0), alpha=0.3, color='lightgreen')
    ax1.axhline(y=0, color='black', linewidth=1)
    ax1.axvline(x=0, color='black', linewidth=1)
    
    # Optimal point
    x_opt = np.array([0.5, 0.5])
    ax1.plot(x_opt[0], x_opt[1], 'ro', markersize=10, label='Optimal point')
    
    # Gradient at optimal point
    grad_f = 2 * x_opt  # ‚àáf = [2x‚ÇÅ, 2x‚ÇÇ]
    ax1.arrow(x_opt[0], x_opt[1], -grad_f[0]*0.1, -grad_f[1]*0.1, 
             head_width=0.05, head_length=0.05, fc='red', ec='red', label='‚àáf')
    
    # Constraint gradient
    grad_h = np.array([1, 1])  # ‚àáh = [1, 1] for x‚ÇÅ + x‚ÇÇ = 1
    ax1.arrow(x_opt[0], x_opt[1], grad_h[0]*0.1, grad_h[1]*0.1,
             head_width=0.05, head_length=0.05, fc='green', ec='green', label='‚àáh')
    
    ax1.set_xlim(-0.2, 1.5)
    ax1.set_ylim(-0.2, 1.5)
    ax1.set_xlabel('x‚ÇÅ')
    ax1.set_ylabel('x‚ÇÇ')
    ax1.set_title('KKT Geometric Interpretation')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_aspect('equal')
    
    # Plot 2: KKT conditions verification
    ax2 = axes[1]
    
    # Check KKT conditions numerically
    conditions = ['Stationarity', 'Comp. Slackness', 'Primal Feas.', 'Dual Feas.']
    satisfied = [True, True, True, True]  # For this example
    residuals = [1e-8, 0, 1e-8, 0]  # Example residuals
    
    colors = ['green' if s else 'red' for s in satisfied]
    bars = ax2.bar(conditions, residuals, color=colors, alpha=0.7)
    
    ax2.set_yscale('log')
    ax2.set_ylabel('Residual (log scale)')
    ax2.set_title('KKT Conditions Verification')
    ax2.grid(True, alpha=0.3)
    
    # Add text annotations
    for i, (bar, res) in enumerate(zip(bars, residuals)):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{res:.1e}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.show()
    
    print(f"\nNumerical Verification:")
    print(f"Optimal point: x* = {x_opt}")
    print(f"Objective value: f(x*) = {np.sum(x_opt**2):.6f}")
    print(f"Constraint value: x‚ÇÅ + x‚ÇÇ - 1 = {np.sum(x_opt) - 1:.6f}")
    print(f"Lagrange multiplier: Œª* = 1.0 (from stationarity)")

# Run geometric visualization
visualize_kkt_geometry()
```

**B∆∞·ªõc 3: Constraint qualification analysis**

```python
def analyze_constraint_qualifications():
    """Analyze constraint qualifications for KKT necessity"""
    
    print("Constraint Qualifications Analysis")
    print("=" * 40)
    
    qualifications = {
        "LICQ (Linear Independence CQ)": {
            "condition": "‚àáh·µ¢(x*), ‚àál‚±º(x*) linearly independent",
            "strength": "Strong",
            "applicability": "Smooth problems",
            "example": "Most well-posed problems"
        },
        
        "MFCQ (Mangasarian-Fromovitz CQ)": {
            "condition": "‚àál‚±º(x*) lin. indep., ‚àÉd: ‚àáh·µ¢(x*)·µÄd < 0 ‚àÄi ‚àà I(x*)",
            "strength": "Medium", 
            "applicability": "When LICQ fails",
            "example": "Problems with dependent gradients"
        },
        
        "Slater's Condition": {
            "condition": "‚àÉx: h·µ¢(x) < 0 ‚àÄi, l‚±º(x) = 0 ‚àÄj",
            "strength": "Medium",
            "applicability": "Convex problems",
            "example": "Interior point exists"
        },
        
        "CPLD (Constant Positive Linear Dependence)": {
            "condition": "Technical condition on constraint gradients",
            "strength": "Weak",
            "applicability": "General problems",
            "example": "When other CQs fail"
        }
    }
    
    print("Constraint Qualifications Hierarchy:")
    print("(Stronger ‚Üí Weaker)")
    print()
    
    for name, info in qualifications.items():
        print(f"{name}:")
        print(f"  Condition: {info['condition']}")
        print(f"  Strength: {info['strength']}")
        print(f"  Applicability: {info['applicability']}")
        print(f"  Example: {info['example']}")
        print()
    
    # Example where LICQ fails
    print("Example: LICQ Failure")
    print("Problem: min x s.t. x¬≥ ‚â§ 0")
    print("At x* = 0:")
    print("‚àáh(x*) = ‚àá(x¬≥) = 3x¬≤|‚Çì‚Çå‚ÇÄ = 0")
    print("LICQ fails because gradient is zero!")
    print("But KKT conditions may still be necessary under weaker CQs")

analyze_constraint_qualifications()
```

</details>

---

## üìù **B√†i t·∫≠p 2: Quadratic Programming v·ªõi KKT**

**ƒê·ªÅ b√†i:** (Tham kh·∫£o Boyd & Vandenberghe, Section 12.2)
Gi·∫£i c√°c b√†i to√°n quy ho·∫°ch b·∫≠c hai s·ª≠ d·ª•ng ƒëi·ªÅu ki·ªán KKT:

a) **QP c√≥ r√†ng bu·ªôc ƒë·∫≥ng th·ª©c**
b) **QP c√≥ r√†ng bu·ªôc b·∫•t ƒë·∫≥ng th·ª©c** 
c) **T·ªëi ∆∞u danh m·ª•c ƒë·∫ßu t∆∞** v·ªõi c√°c r√†ng bu·ªôc
d) **C√¥ng th·ª©c ƒë·ªëi ng·∫´u M√°y vector h·ªó tr·ª£**

**Y√™u c·∫ßu:**
1. Nghi·ªám gi·∫£i t√≠ch s·ª≠ d·ª•ng KKT
2. X√°c ƒë·ªãnh t·∫≠p ho·∫°t ƒë·ªông
3. Ki·ªÉm ch·ª©ng s·ªë
4. Gi·∫£i th√≠ch kinh t·∫ø

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Equality constrained QP**

```python
class QuadraticProgrammingKKT:
    def __init__(self):
        self.solutions = {}
        
    def solve_equality_constrained_qp(self, Q, c, A, b, problem_name="EQ-QP"):
        """
        Solve: min (1/2)x^T Q x + c^T x s.t. Ax = b
        using KKT conditions
        """
        
        print(f"Equality Constrained QP: {problem_name}")
        print("=" * 40)
        print("Problem: min (1/2)x^T Q x + c^T x s.t. Ax = b")
        print(f"Q = \n{Q}")
        print(f"c = {c}")
        print(f"A = \n{A}")
        print(f"b = {b}")
        
        # KKT conditions:
        # Stationarity: Qx + c + A^T ŒΩ = 0
        # Primal feasibility: Ax = b
        
        # Form KKT system: [Q  A^T] [x] = [-c]
        #                  [A   0 ] [ŒΩ]   [ b]
        
        n = Q.shape[0]  # Number of variables
        m = A.shape[0]  # Number of equality constraints
        
        # Build KKT matrix
        KKT_matrix = np.block([
            [Q, A.T],
            [A, np.zeros((m, m))]
        ])
        
        rhs = np.concatenate([-c, b])
        
        print(f"\nKKT System:")
        print(f"KKT matrix shape: {KKT_matrix.shape}")
        print(f"RHS shape: {rhs.shape}")
        
        # Solve KKT system
        try:
            solution = np.linalg.solve(KKT_matrix, rhs)
            x_opt = solution[:n]
            nu_opt = solution[n:]
            
            print(f"\nSolution:")
            print(f"x* = {x_opt}")
            print(f"ŒΩ* = {nu_opt}")
            
            # Verify solution
            obj_val = 0.5 * x_opt.T @ Q @ x_opt + c.T @ x_opt
            constraint_residual = np.linalg.norm(A @ x_opt - b)
            stationarity_residual = np.linalg.norm(Q @ x_opt + c + A.T @ nu_opt)
            
            print(f"\nVerification:")
            print(f"Objective value: {obj_val:.6f}")
            print(f"Constraint residual: {constraint_residual:.8f}")
            print(f"Stationarity residual: {stationarity_residual:.8f}")
            
            self.solutions[problem_name] = {
                'x': x_opt,
                'nu': nu_opt,
                'objective': obj_val,
                'feasible': constraint_residual < 1e-10,
                'optimal': stationarity_residual < 1e-10
            }
            
            return x_opt, nu_opt
            
        except np.linalg.LinAlgError as e:
            print(f"Error solving KKT system: {e}")
            return None, None
    
    def solve_inequality_constrained_qp(self, Q, c, A, b, problem_name="INEQ-QP"):
        """
        Solve: min (1/2)x^T Q x + c^T x s.t. Ax ‚â§ b
        using active set method with KKT conditions
        """
        
        print(f"\nInequality Constrained QP: {problem_name}")
        print("=" * 45)
        print("Problem: min (1/2)x^T Q x + c^T x s.t. Ax ‚â§ b")
        
        n = Q.shape[0]  # Number of variables
        m = A.shape[0]  # Number of inequality constraints
        
        print(f"Variables: {n}, Constraints: {m}")
        
        # Try all possible active sets
        best_solution = None
        best_objective = np.inf
        
        print(f"\nActive Set Enumeration:")
        
        for active_mask in range(2**m):
            active_set = []
            for i in range(m):
                if (active_mask >> i) & 1:
                    active_set.append(i)
            
            if len(active_set) > n:  # Skip overconstrained cases
                continue
                
            print(f"\nTrying active set: {active_set}")
            
            # Solve with current active set
            if len(active_set) == 0:
                # Unconstrained case
                x_candidate = -np.linalg.solve(Q, c)
                lambda_candidate = np.zeros(m)
            else:
                # Form reduced KKT system
                A_active = A[active_set, :]
                b_active = b[active_set]
                
                # KKT system: [Q  A_active^T] [x] = [-c     ]
                #             [A_active  0  ] [Œª]   [b_active]
                
                try:
                    KKT_active = np.block([
                        [Q, A_active.T],
                        [A_active, np.zeros((len(active_set), len(active_set)))]
                    ])
                    
                    rhs_active = np.concatenate([-c, b_active])
                    sol_active = np.linalg.solve(KKT_active, rhs_active)
                    
                    x_candidate = sol_active[:n]
                    lambda_active = sol_active[n:]
                    
                    # Reconstruct full lambda vector
                    lambda_candidate = np.zeros(m)
                    lambda_candidate[active_set] = lambda_active
                    
                except np.linalg.LinAlgError:
                    print("  Singular KKT matrix, skipping")
                    continue
            
            # Check KKT conditions
            # 1. Primal feasibility: Ax ‚â§ b
            constraint_vals = A @ x_candidate - b
            primal_feasible = np.all(constraint_vals <= 1e-10)
            
            # 2. Dual feasibility: Œª ‚â• 0
            dual_feasible = np.all(lambda_candidate >= -1e-10)
            
            # 3. Complementary slackness: Œª·µ¢(A·µ¢x - b·µ¢) = 0
            comp_slack = np.abs(lambda_candidate * constraint_vals)
            comp_slack_satisfied = np.all(comp_slack <= 1e-10)
            
            # 4. Stationarity: Qx + c + A^T Œª = 0
            stationarity_residual = Q @ x_candidate + c + A.T @ lambda_candidate
            stationarity_satisfied = np.linalg.norm(stationarity_residual) <= 1e-10
            
            kkt_satisfied = (primal_feasible and dual_feasible and 
                           comp_slack_satisfied and stationarity_satisfied)
            
            print(f"  Primal feasible: {primal_feasible}")
            print(f"  Dual feasible: {dual_feasible}")
            print(f"  Comp. slackness: {comp_slack_satisfied}")
            print(f"  Stationarity: {stationarity_satisfied}")
            print(f"  KKT satisfied: {kkt_satisfied}")
            
            if kkt_satisfied:
                obj_val = 0.5 * x_candidate.T @ Q @ x_candidate + c.T @ x_candidate
                print(f"  Objective: {obj_val:.6f}")
                
                if obj_val < best_objective:
                    best_objective = obj_val
                    best_solution = {
                        'x': x_candidate,
                        'lambda': lambda_candidate,
                        'active_set': active_set,
                        'objective': obj_val
                    }
        
        if best_solution is not None:
            print(f"\nOptimal Solution Found:")
            print(f"x* = {best_solution['x']}")
            print(f"Œª* = {best_solution['lambda']}")
            print(f"Active set: {best_solution['active_set']}")
            print(f"Optimal value: {best_solution['objective']:.6f}")
            
            self.solutions[problem_name] = best_solution
            return best_solution
        else:
            print("No feasible solution found!")
            return None

# Example 1: Equality constrained QP
def example_equality_qp():
    """Example: Portfolio optimization with budget constraint"""
    
    print("Example: Portfolio Optimization (Equality Constrained)")
    print("min (1/2)x^T Œ£ x s.t. 1^T x = 1")
    
    # Covariance matrix (positive definite)
    np.random.seed(42)
    n = 3
    A_rand = np.random.randn(n, n)
    Sigma = A_rand.T @ A_rand + 0.1 * np.eye(n)
    
    c = np.zeros(n)  # No linear term
    A = np.ones((1, n))  # Budget constraint: sum(x) = 1
    b = np.array([1])
    
    solver = QuadraticProgrammingKKT()
    x_opt, nu_opt = solver.solve_equality_constrained_qp(Sigma, c, A, b, "Portfolio")
    
    if x_opt is not None:
        print(f"\nPortfolio Interpretation:")
        print(f"Asset weights: {x_opt}")
        print(f"Portfolio risk: {0.5 * x_opt.T @ Sigma @ x_opt:.6f}")
        print(f"Budget multiplier (ŒΩ): {nu_opt[0]:.6f}")
        print("ŒΩ represents the marginal cost of the budget constraint")
    
    return solver

# Example 2: Inequality constrained QP
def example_inequality_qp():
    """Example: Constrained least squares"""
    
    print("\n" + "="*60)
    print("Example: Constrained Least Squares (Inequality Constrained)")
    print("min (1/2)||x||¬≤ s.t. x‚ÇÅ + x‚ÇÇ ‚â§ 1, x‚ÇÅ ‚â• 0, x‚ÇÇ ‚â• 0")
    
    Q = np.eye(2)
    c = np.zeros(2)
    A = np.array([
        [1, 1],   # x‚ÇÅ + x‚ÇÇ ‚â§ 1
        [-1, 0],  # -x‚ÇÅ ‚â§ 0 (x‚ÇÅ ‚â• 0)
        [0, -1]   # -x‚ÇÇ ‚â§ 0 (x‚ÇÇ ‚â• 0)
    ])
    b = np.array([1, 0, 0])
    
    solver = QuadraticProgrammingKKT()
    solution = solver.solve_inequality_constrained_qp(Q, c, A, b, "Constrained LS")
    
    if solution is not None:
        print(f"\nGeometric Interpretation:")
        print("The optimal point lies at the origin (0,0)")
        print("This makes sense: minimizing ||x||¬≤ subject to x ‚â• 0")
    
    return solver

# Run examples
solver1 = example_equality_qp()
solver2 = example_inequality_qp()
```

**B∆∞·ªõc 2: Portfolio optimization v·ªõi KKT**

```python
def advanced_portfolio_optimization():
    """Advanced portfolio optimization with multiple constraints"""
    
    print("Advanced Portfolio Optimization with KKT")
    print("=" * 45)
    
    # Problem: min (1/2)x^T Œ£ x - Œº^T x s.t. 1^T x = 1, x ‚â• 0
    # This is mean-variance optimization with long-only constraint
    
    np.random.seed(42)
    n_assets = 4
    
    # Generate realistic financial data
    mu = np.array([0.08, 0.12, 0.10, 0.06])  # Expected returns
    
    # Correlation matrix
    corr = np.array([
        [1.0, 0.3, 0.2, 0.1],
        [0.3, 1.0, 0.4, 0.2],
        [0.2, 0.4, 1.0, 0.3],
        [0.1, 0.2, 0.3, 1.0]
    ])
    
    # Volatilities
    vol = np.array([0.15, 0.25, 0.20, 0.12])
    
    # Covariance matrix
    Sigma = np.outer(vol, vol) * corr
    
    print(f"Expected returns: {mu}")
    print(f"Volatilities: {vol}")
    print(f"Covariance matrix:\n{Sigma}")
    
    # Solve for different risk aversion levels
    risk_aversions = [0.5, 1.0, 2.0, 5.0]
    
    portfolios = []
    
    for gamma in risk_aversions:
        print(f"\nRisk Aversion Œ≥ = {gamma}")
        print("-" * 30)
        
        # Problem: min (Œ≥/2)x^T Œ£ x - Œº^T x s.t. 1^T x = 1, x ‚â• 0
        Q = gamma * Sigma
        c = -mu  # Negative because we maximize Œº^T x
        
        # Constraints: 1^T x = 1 (budget), x ‚â• 0 (long-only)
        A_eq = np.ones((1, n_assets))
        b_eq = np.array([1])
        A_ineq = -np.eye(n_assets)  # -x ‚â§ 0 (x ‚â• 0)
        b_ineq = np.zeros(n_assets)
        
        # Solve using CVXPY for comparison
        x = cp.Variable(n_assets)
        objective = cp.Minimize(0.5 * gamma * cp.quad_form(x, Sigma) - mu.T @ x)
        constraints = [cp.sum(x) == 1, x >= 0]
        
        prob = cp.Problem(objective, constraints)
        prob.solve()
        
        if prob.status == 'optimal':
            x_opt = x.value
            portfolio_return = mu.T @ x_opt
            portfolio_risk = np.sqrt(x_opt.T @ Sigma @ x_opt)
            
            print(f"Optimal portfolio: {x_opt}")
            print(f"Expected return: {portfolio_return:.4f}")
            print(f"Portfolio risk: {portfolio_risk:.4f}")
            print(f"Sharpe ratio: {portfolio_return/portfolio_risk:.4f}")
            
            # Get dual variables (shadow prices)
            budget_price = constraints[0].dual_value
            non_neg_prices = constraints[1].dual_value
            
            print(f"Budget constraint price: {budget_price:.4f}")
            print(f"Non-negativity prices: {non_neg_prices}")
            
            portfolios.append({
                'gamma': gamma,
                'weights': x_opt,
                'return': portfolio_return,
                'risk': portfolio_risk,
                'budget_price': budget_price,
                'non_neg_prices': non_neg_prices
            })
    
    # Plot efficient frontier
    plt.figure(figsize=(12, 8))
    
    # Plot 1: Efficient frontier
    plt.subplot(2, 2, 1)
    risks = [p['risk'] for p in portfolios]
    returns = [p['return'] for p in portfolios]
    
    plt.plot(risks, returns, 'bo-', linewidth=2, markersize=8)
    for i, p in enumerate(portfolios):
        plt.annotate(f'Œ≥={p["gamma"]}', (p['risk'], p['return']), 
                    xytext=(5, 5), textcoords='offset points')
    
    plt.xlabel('Portfolio Risk (œÉ)')
    plt.ylabel('Expected Return (Œº)')
    plt.title('Efficient Frontier')
    plt.grid(True, alpha=0.3)
    
    # Plot 2: Portfolio weights
    plt.subplot(2, 2, 2)
    gammas = [p['gamma'] for p in portfolios]
    weights = np.array([p['weights'] for p in portfolios])
    
    for i in range(n_assets):
        plt.plot(gammas, weights[:, i], 'o-', label=f'Asset {i+1}', linewidth=2)
    
    plt.xlabel('Risk Aversion (Œ≥)')
    plt.ylabel('Portfolio Weight')
    plt.title('Portfolio Weights vs Risk Aversion')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot 3: Shadow prices
    plt.subplot(2, 2, 3)
    budget_prices = [p['budget_price'] for p in portfolios]
    plt.plot(gammas, budget_prices, 'ro-', linewidth=2)
    plt.xlabel('Risk Aversion (Œ≥)')
    plt.ylabel('Budget Constraint Price')
    plt.title('Shadow Price of Budget Constraint')
    plt.grid(True, alpha=0.3)
    
    # Plot 4: Active constraints
    plt.subplot(2, 2, 4)
    active_constraints = []
    for p in portfolios:
        active = np.sum(p['weights'] < 1e-6)  # Number of zero weights
        active_constraints.append(active)
    
    plt.bar(range(len(gammas)), active_constraints, alpha=0.7)
    plt.xlabel('Portfolio Index')
    plt.ylabel('Number of Inactive Assets')
    plt.title('Active Set Size')
    plt.xticks(range(len(gammas)), [f'Œ≥={g}' for g in gammas])
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    return portfolios

# Run advanced portfolio optimization
portfolio_results = advanced_portfolio_optimization()
```

**B∆∞·ªõc 3: Support Vector Machine dual**

```python
def svm_kkt_analysis():
    """Analyze SVM using KKT conditions"""
    
    print("Support Vector Machine KKT Analysis")
    print("=" * 40)
    
    # Generate synthetic 2D data
    np.random.seed(42)
    n_samples = 20
    
    # Class +1: centered at (1, 1)
    X_pos = np.random.randn(n_samples//2, 2) * 0.3 + np.array([1, 1])
    y_pos = np.ones(n_samples//2)
    
    # Class -1: centered at (-1, -1)
    X_neg = np.random.randn(n_samples//2, 2) * 0.3 + np.array([-1, -1])
    y_neg = -np.ones(n_samples//2)
    
    X = np.vstack([X_pos, X_neg])
    y = np.hstack([y_pos, y_neg])
    
    print(f"Dataset: {n_samples} samples, 2 features")
    print(f"Class distribution: {np.sum(y == 1)} positive, {np.sum(y == -1)} negative")
    
    # Solve SVM dual problem
    # max Œ£Œ±·µ¢ - (1/2)Œ£Œ£Œ±·µ¢Œ±‚±ºy·µ¢y‚±ºx·µ¢·µÄx‚±º s.t. Œ£Œ±·µ¢y·µ¢ = 0, Œ±·µ¢ ‚â• 0
    
    alpha = cp.Variable(n_samples)
    
    # Gram matrix
    K = X @ X.T
    
    # Dual objective
    dual_obj = cp.Maximize(cp.sum(alpha) - 0.5 * cp.quad_form(cp.multiply(y, alpha), K))
    
    # Dual constraints
    constraints = [
        cp.sum(cp.multiply(y, alpha)) == 0,  # Œ£Œ±·µ¢y·µ¢ = 0
        alpha >= 0  # Œ±·µ¢ ‚â• 0
    ]
    
    prob = cp.Problem(dual_obj, constraints)
    prob.solve()
    
    if prob.status == 'optimal':
        alpha_opt = alpha.value
        
        print(f"\nDual Solution:")
        print(f"Dual objective: {prob.value:.6f}")
        print(f"Œ± values: {alpha_opt}")
        
        # Identify support vectors
        support_threshold = 1e-6
        support_vectors = alpha_opt > support_threshold
        sv_indices = np.where(support_vectors)[0]
        
        print(f"\nSupport Vectors:")
        print(f"Number of SVs: {len(sv_indices)}")
        print(f"SV indices: {sv_indices}")
        print(f"Œ± values for SVs: {alpha_opt[support_vectors]}")
        
        # Recover primal variables
        w = np.sum((alpha_opt * y)[:, np.newaxis] * X, axis=0)
        
        # Compute bias using support vectors
        # For support vectors: y·µ¢(w·µÄx·µ¢ + b) = 1
        sv_margins = y[sv_indices] * (X[sv_indices] @ w)
        b = np.mean(y[sv_indices] - sv_margins)
        
        print(f"\nPrimal Variables (recovered from dual):")
        print(f"w = {w}")
        print(f"b = {b:.6f}")
        
        # Verify KKT conditions
        print(f"\nKKT Conditions Verification:")
        
        # 1. Stationarity: w = Œ£Œ±·µ¢y·µ¢x·µ¢ (already satisfied by construction)
        w_check = np.sum((alpha_opt * y)[:, np.newaxis] * X, axis=0)
        stationarity_error = np.linalg.norm(w - w_check)
        print(f"1. Stationarity error: {stationarity_error:.8f}")
        
        # 2. Primal feasibility: y·µ¢(w·µÄx·µ¢ + b) ‚â• 1
        margins = y * (X @ w + b)
        primal_feasible = np.all(margins >= 1 - 1e-6)
        print(f"2. Primal feasibility: {primal_feasible}")
        print(f"   Min margin: {np.min(margins):.6f}")
        
        # 3. Dual feasibility: Œ±·µ¢ ‚â• 0 (enforced by solver)
        dual_feasible = np.all(alpha_opt >= -1e-6)
        print(f"3. Dual feasibility: {dual_feasible}")
        
        # 4. Complementary slackness: Œ±·µ¢(y·µ¢(w·µÄx·µ¢ + b) - 1) = 0
        slack = margins - 1
        comp_slack_violations = np.abs(alpha_opt * slack)
        comp_slack_satisfied = np.all(comp_slack_violations <= 1e-6)
        print(f"4. Complementary slackness: {comp_slack_satisfied}")
        print(f"   Max violation: {np.max(comp_slack_violations):.8f}")
        
        # Visualization
        plt.figure(figsize=(15, 5))
        
        # Plot 1: Data and decision boundary
        plt.subplot(1, 3, 1)
        
        # Plot data points
        plt.scatter(X[y == 1, 0], X[y == 1, 1], c='red', marker='o', s=50, label='Class +1')
        plt.scatter(X[y == -1, 0], X[y == -1, 1], c='blue', marker='s', s=50, label='Class -1')
        
        # Highlight support vectors
        plt.scatter(X[sv_indices, 0], X[sv_indices, 1], 
                   s=200, facecolors='none', edgecolors='black', linewidth=2, label='Support Vectors')
        
        # Plot decision boundary and margins
        x_min, x_max = plt.xlim()
        y_min, y_max = plt.ylim()
        
        xx = np.linspace(x_min, x_max, 100)
        
        # Decision boundary: w^T x + b = 0
        if abs(w[1]) > 1e-10:
            yy = -(w[0] * xx + b) / w[1]
            plt.plot(xx, yy, 'k-', linewidth=2, label='Decision Boundary')
            
            # Margins: w^T x + b = ¬±1
            yy_pos = -(w[0] * xx + b - 1) / w[1]
            yy_neg = -(w[0] * xx + b + 1) / w[1]
            plt.plot(xx, yy_pos, 'k--', alpha=0.5, label='Margin')
            plt.plot(xx, yy_neg, 'k--', alpha=0.5)
        
        plt.xlabel('x‚ÇÅ')
        plt.ylabel('x‚ÇÇ')
        plt.title('SVM Classification')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Plot 2: Dual variables
        plt.subplot(1, 3, 2)
        plt.bar(range(n_samples), alpha_opt, alpha=0.7)
        
        # Highlight support vectors
        for idx in sv_indices:
            plt.bar(idx, alpha_opt[idx], color='red', alpha=0.8)
        
        plt.xlabel('Sample Index')
        plt.ylabel('Œ± value')
        plt.title('Dual Variables (Lagrange Multipliers)')
        plt.grid(True, alpha=0.3)
        
        # Plot 3: KKT conditions
        plt.subplot(1, 3, 3)
        
        conditions = ['Stationarity', 'Primal Feas.', 'Dual Feas.', 'Comp. Slack.']
        residuals = [stationarity_error, 1-np.min(margins), 
                    max(0, -np.min(alpha_opt)), np.max(comp_slack_violations)]
        satisfied = [r < 1e-6 for r in residuals]
        
        colors = ['green' if s else 'red' for s in satisfied]
        bars = plt.bar(conditions, residuals, color=colors, alpha=0.7)
        
        plt.yscale('log')
        plt.ylabel('Residual (log scale)')
        plt.title('KKT Conditions Verification')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        return {
            'w': w,
            'b': b,
            'alpha': alpha_opt,
            'support_vectors': sv_indices,
            'kkt_satisfied': all([stationarity_error < 1e-6, primal_feasible, 
                                dual_feasible, comp_slack_satisfied])
        }
    
    else:
        print("Failed to solve SVM dual problem")
        return None

# Run SVM KKT analysis
svm_result = svm_kkt_analysis()
```

</details>

---

## üìù **B√†i t·∫≠p 3: Water-Filling Algorithm v√† KKT**

**ƒê·ªÅ b√†i:** (Tham kh·∫£o Boyd & Vandenberghe, Section 12.3)
L·∫≠p tr√¨nh thu·∫≠t to√°n water-filling s·ª≠ d·ª•ng ƒëi·ªÅu ki·ªán KKT:

a) **Water-filling c·ªï ƒëi·ªÉn** cho ph√¢n b·ªï c√¥ng su·∫•t
b) **Water-filling t·ªïng qu√°t** v·ªõi c√°c r√†ng bu·ªôc kh√°c nhau
c) **L·∫≠p tr√¨nh thu·∫≠t to√°n l·∫∑p**
d) **Ph√¢n t√≠ch h·ªôi t·ª•** v√† ki·ªÉm ch·ª©ng t√≠nh t·ªëi ∆∞u

**Y√™u c·∫ßu:**
1. X√¢y d·ª±ng d·ª±a tr√™n KKT
2. L·∫≠p tr√¨nh thu·∫≠t to√°n
3. Ph√¢n t√≠ch h·ªôi t·ª•
4. ·ª®ng d·ª•ng trong truy·ªÅn th√¥ng

<details>
<summary><strong>üí° L·ªùi gi·∫£i chi ti·∫øt</strong></summary>

**B∆∞·ªõc 1: Classical water-filling derivation**

```python
class WaterFillingKKT:
    def __init__(self, tolerance=1e-8):
        self.tol = tolerance
        self.history = []
        
    def derive_water_filling(self, noise_powers, total_power):
        """
        Derive water-filling solution using KKT conditions
        
        Problem: max Œ£·µ¢ log(1 + p·µ¢/n·µ¢) s.t. Œ£·µ¢ p·µ¢ ‚â§ P, p·µ¢ ‚â• 0
        """
        
        print("Water-Filling Algorithm Derivation")
        print("=" * 40)
        print("Problem: max Œ£·µ¢ log(1 + p·µ¢/n·µ¢) s.t. Œ£·µ¢ p·µ¢ ‚â§ P, p·µ¢ ‚â• 0")
        print(f"Noise powers: {noise_powers}")
        print(f"Total power: {total_power}")
        
        n_channels = len(noise_powers)
        
        print(f"\nKKT Conditions Derivation:")
        print("Lagrangian: L(p,Œª,Œº) = Œ£·µ¢ log(1 + p·µ¢/n·µ¢) - Œª(Œ£·µ¢ p·µ¢ - P) - Œ£·µ¢ Œº·µ¢p·µ¢")
        print()
        print("KKT Conditions:")
        print("1. Stationarity: ‚àÇL/‚àÇp·µ¢ = 1/(n·µ¢ + p·µ¢) - Œª - Œº·µ¢ = 0")
        print("2. Complementary slackness: Œº·µ¢p·µ¢ = 0, Œª(Œ£·µ¢ p·µ¢ - P) = 0")
        print("3. Primal feasibility: Œ£·µ¢ p·µ¢ ‚â§ P, p·µ¢ ‚â• 0")
        print("4. Dual feasibility: Œª ‚â• 0, Œº·µ¢ ‚â• 0")
        print()
        
        print("Analysis:")
        print("From stationarity: 1/(n·µ¢ + p·µ¢) = Œª + Œº·µ¢")
        print()
        print("Case 1: p·µ¢ > 0 ‚üπ Œº·µ¢ = 0 ‚üπ 1/(n·µ¢ + p·µ¢) = Œª")
        print("        ‚üπ p·µ¢ = 1/Œª - n·µ¢")
        print()
        print("Case 2: p·µ¢ = 0 ‚üπ Œº·µ¢ ‚â• 0 ‚üπ 1/n·µ¢ ‚â§ Œª")
        print("        ‚üπ n·µ¢ ‚â• 1/Œª")
        print()
        print("Water-filling solution: p·µ¢* = max(0, 1/Œª* - n·µ¢)")
        print("where Œª* is chosen so that Œ£·µ¢ p·µ¢* = P")
        
        return self._solve_water_filling_numerical(noise_powers, total_power)
    
    def _solve_water_filling_numerical(self, noise_powers, total_power):
        """Solve water-filling numerically"""
        
        noise_powers = np.array(noise_powers)
        n_channels = len(noise_powers)
        
        # Binary search for optimal Œª
        lambda_min = 0
        lambda_max = 1.0 / np.min(noise_powers)  # Upper bound
        
        print(f"\nNumerical Solution:")
        print(f"Binary search range: Œª ‚àà [{lambda_min:.6f}, {lambda_max:.6f}]")
        
        iteration = 0
        while lambda_max - lambda_min > self.tol:
            lambda_mid = (lambda_min + lambda_max) / 2
            
            # Compute power allocation
            powers = np.maximum(0, 1/lambda_mid - noise_powers)
            total_used = np.sum(powers)
            
            if iteration % 10 == 0:
                print(f"  Iter {iteration}: Œª = {lambda_mid:.8f}, total power = {total_used:.6f}")
            
            if total_used > total_power:
                lambda_min = lambda_mid
            else:
                lambda_max = lambda_mid
            
            iteration += 1
        
        lambda_opt = (lambda_min + lambda_max) / 2
        powers_opt = np.maximum(0, 1/lambda_opt - noise_powers)
        
        print(f"\nOptimal Solution:")
        print(f"Œª* = {lambda_opt:.8f}")
        print(f"Optimal powers: {powers_opt}")
        print(f"Total power used: {np.sum(powers_opt):.6f}")
        print(f"Water level (1/Œª*): {1/lambda_opt:.6f}")
        
        # Verify KKT conditions
        self._verify_water_filling_kkt(powers_opt, noise_powers, total_power, lambda_opt)
        
        return {
            'powers': powers_opt,
            'lambda': lambda_opt,
            'water_level': 1/lambda_opt,
            'capacity': np.sum(np.log2(1 + powers_opt/noise_powers))
        }
    
    def _verify_water_filling_kkt(self, powers, noise_powers, total_power, lambda_opt):
        """Verify KKT conditions for water-filling solution"""
        
        print(f"\nKKT Verification:")
        
        n_channels = len(powers)
        active_channels = powers > self.tol
        
        # 1. Stationarity for active channels
        print("1. Stationarity:")
        for i in range(n_channels):
            if active_channels[i]:
                gradient = 1/(noise_powers[i] + powers[i])
                error = abs(gradient - lambda_opt)
                print(f"   Channel {i}: ‚àáf·µ¢ = {gradient:.8f}, Œª = {lambda_opt:.8f}, error = {error:.2e}")
        
        # 2. Complementary slackness
        print("2. Complementary Slackness:")
        power_constraint_slack = total_power - np.sum(powers)
        print(f"   Power constraint slack: {power_constraint_slack:.8f}")
        print(f"   Œª √ó slack = {lambda_opt * power_constraint_slack:.2e}")
        
        for i in range(n_channels):
            if not active_channels[i]:
                print(f"   Channel {i}: p·µ¢ = 0, constraint 1/n·µ¢ ‚â§ Œª: {1/noise_powers[i]:.6f} ‚â§ {lambda_opt:.6f}")
        
        # 3. Primal feasibility
        print("3. Primal Feasibility:")
        print(f"   Total power: {np.sum(powers):.6f} ‚â§ {total_power}: {np.sum(powers) <= total_power + self.tol}")
        print(f"   Non-negativity: all p·µ¢ ‚â• 0: {np.all(powers >= -self.tol)}")
        
        # 4. Dual feasibility
        print("4. Dual Feasibility:")
        print(f"   Œª = {lambda_opt:.8f} ‚â• 0: {lambda_opt >= 0}")
    
    def iterative_water_filling(self, noise_powers, total_power, max_iterations=1000):
        """Implement iterative water-filling algorithm"""
        
        print(f"\nIterative Water-Filling Algorithm")
        print("=" * 40)
        
        noise_powers = np.array(noise_powers)
        n_channels = len(noise_powers)
        
        # Initialize with equal power allocation
        powers = np.full(n_channels, total_power / n_channels)
        
        self.history = []
        
        for iteration in range(max_iterations):
            # Compute water level
            active_channels = powers > self.tol
            n_active = np.sum(active_channels)
            
            if n_active == 0:
                break
            
            # Water level for active channels
            water_level = (total_power + np.sum(noise_powers[active_channels])) / n_active
            
            # Update power allocation
            new_powers = np.zeros(n_channels)
            new_powers[active_channels] = water_level - noise_powers[active_channels]
            new_powers = np.maximum(0, new_powers)
            
            # Check convergence
            power_change = np.linalg.norm(new_powers - powers)
            
            self.history.append({
                'iteration': iteration,
                'powers': new_powers.copy(),
                'water_level': water_level,
                'active_channels': np.sum(new_powers > self.tol),
                'change': power_change
            })
            
            if iteration % 100 == 0:
                print(f"  Iter {iteration}: water level = {water_level:.6f}, "
                      f"active channels = {np.sum(new_powers > self.tol)}, "
                      f"change = {power_change:.2e}")
            
            if power_change < self.tol:
                print(f"Converged in {iteration} iterations")
                break
            
            powers = new_powers
        
        return {
            'powers': powers,
            'water_level': water_level,
            'iterations': iteration + 1,
            'converged': power_change < self.tol
        }
    
    def plot_water_filling_solution(self, noise_powers, solution):
        """Visualize water-filling solution"""
        
        powers = solution['powers']
        water_level = solution['water_level']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Plot 1: Water-filling visualization
        ax1 = axes[0, 0]
        
        n_channels = len(noise_powers)
        channel_indices = np.arange(n_channels)
        
        # Plot noise floor
        ax1.bar(channel_indices, noise_powers, alpha=0.7, color='brown', label='Noise Floor')
        
        # Plot allocated power
        ax1.bar(channel_indices, powers, bottom=noise_powers, alpha=0.7, color='blue', label='Allocated Power')
        
        # Plot water level
        ax1.axhline(y=water_level, color='cyan', linestyle='--', linewidth=2, label=f'Water Level = {water_level:.3f}')
        
        ax1.set_xlabel('Channel Index')
        ax1.set_ylabel('Power Level')
        ax1.set_title('Water-Filling Power Allocation')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # Plot 2: Channel capacities
        ax2 = axes[0, 1]
        
        capacities = np.log2(1 + powers/noise_powers)
        ax2.bar(channel_indices, capacities, alpha=0.7, color='green')
        ax2.set_xlabel('Channel Index')
        ax2.set_ylabel('Channel Capacity (bits/s/Hz)')
        ax2.set_title('Channel Capacities')
        ax2.grid(True, alpha=0.3)
        
        # Plot 3: Power vs noise relationship
        ax3 = axes[1, 0]
        
        sorted_indices = np.argsort(noise_powers)
        ax3.plot(noise_powers[sorted_indices], powers[sorted_indices], 'bo-', linewidth=2, markersize=8)
        ax3.set_xlabel('Noise Power')
        ax3.set_ylabel('Allocated Power')
        ax3.set_title('Power Allocation vs Noise Level')
        ax3.grid(True, alpha=0.3)
        
        # Plot 4: Convergence history (if available)
        ax4 = axes[1, 1]
        
        if hasattr(self, 'history') and self.history:
            iterations = [h['iteration'] for h in self.history]
            changes = [h['change'] for h in self.history]
            
            ax4.semilogy(iterations, changes, 'r-', linewidth=2)
            ax4.set_xlabel('Iteration')
            ax4.set_ylabel('Power Change')
            ax4.set_title('Convergence History')
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(0.5, 0.5, 'No convergence\nhistory available', 
                    ha='center', va='center', transform=ax4.transAxes, fontsize=12)
            ax4.set_title('Convergence History')
        
        plt.tight_layout()
        plt.show()
        
        # Print summary
        print(f"\nSolution Summary:")
        print(f"Total capacity: {np.sum(capacities):.4f} bits/s/Hz")
        print(f"Active channels: {np.sum(powers > self.tol)}/{n_channels}")
        print(f"Power efficiency: {np.sum(capacities)/np.sum(powers):.4f} bits/J")

# Example 1: Classical water-filling
def example_classical_water_filling():
    """Example: Power allocation in parallel channels"""
    
    print("Example: Classical Water-Filling")
    print("Parallel Gaussian channels with different noise levels")
    
    # Channel noise powers (higher = worse channel)
    noise_powers = [0.1, 0.5, 0.2, 1.0, 0.3]
    total_power = 2.0
    
    wf = WaterFillingKKT()
    
    # Derive and solve
    solution = wf.derive_water_filling(noise_powers, total_power)
    
    # Compare with iterative algorithm
    print(f"\n" + "="*60)
    print("Comparison with Iterative Algorithm:")
    
    iterative_solution = wf.iterative_water_filling(noise_powers, total_power)
    
    print(f"Direct solution powers: {solution['powers']}")
    print(f"Iterative solution powers: {iterative_solution['powers']}")
    print(f"Difference: {np.linalg.norm(solution['powers'] - iterative_solution['powers']):.2e}")
    
    # Visualize
    wf.plot_water_filling_solution(noise_powers, solution)
    
    return wf, solution

# Example 2: Generalized water-filling with individual constraints
def example_generalized_water_filling():
    """Example: Water-filling with individual power constraints"""
    
    print(f"\n" + "="*80)
    print("Example: Generalized Water-Filling with Individual Constraints")
    print("max Œ£·µ¢ log(1 + p·µ¢/n·µ¢) s.t. Œ£·µ¢ p·µ¢ ‚â§ P, 0 ‚â§ p·µ¢ ‚â§ p·µ¢·µê·µÉÀ£")
    
    noise_powers = np.array([0.1, 0.5, 0.2, 1.0, 0.3])
    total_power = 2.0
    max_powers = np.array([0.8, 0.6, 1.0, 0.4, 0.7])  # Individual constraints
    
    print(f"Noise powers: {noise_powers}")
    print(f"Total power: {total_power}")
    print(f"Individual limits: {max_powers}")
    
    # Solve using CVXPY
    n_channels = len(noise_powers)
    p = cp.Variable(n_channels)
    
    objective = cp.Maximize(cp.sum(cp.log(1 + cp.divide(p, noise_powers))))
    constraints = [
        cp.sum(p) <= total_power,
        p >= 0,
        p <= max_powers
    ]
    
    prob = cp.Problem(objective, constraints)
    prob.solve()
    
    if prob.status == 'optimal':
        powers_opt = p.value
        capacity = prob.value / np.log(2)  # Convert to bits
        
        print(f"\nOptimal Solution:")
        print(f"Powers: {powers_opt}")
        print(f"Total capacity: {capacity:.4f} bits/s/Hz")
        print(f"Total power used: {np.sum(powers_opt):.4f}")
        
        # Check which constraints are active
        print(f"\nActive Constraints:")
        total_power_slack = total_power - np.sum(powers_opt)
        print(f"Total power slack: {total_power_slack:.6f}")
        
        for i in range(n_channels):
            individual_slack = max_powers[i] - powers_opt[i]
            if individual_slack < 1e-6:
                print(f"Channel {i}: individual constraint active (p·µ¢ = {powers_opt[i]:.4f})")
            elif powers_opt[i] < 1e-6:
                print(f"Channel {i}: non-negativity active (p·µ¢ = 0)")
            else:
                print(f"Channel {i}: interior solution (p·µ¢ = {powers_opt[i]:.4f})")
        
        # Visualize comparison
        wf = WaterFillingKKT()
        unconstrained_solution = wf.derive_water_filling(noise_powers, total_power)
        
        plt.figure(figsize=(12, 5))
        
        # Plot 1: Power allocation comparison
        plt.subplot(1, 2, 1)
        x = np.arange(n_channels)
        width = 0.35
        
        plt.bar(x - width/2, unconstrained_solution['powers'], width, 
               label='Unconstrained', alpha=0.7)
        plt.bar(x + width/2, powers_opt, width, 
               label='With Individual Limits', alpha=0.7)
        plt.plot(x, max_powers, 'r--', linewidth=2, label='Individual Limits')
        
        plt.xlabel('Channel Index')
        plt.ylabel('Allocated Power')
        plt.title('Power Allocation Comparison')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Plot 2: Capacity comparison
        plt.subplot(1, 2, 2)
        
        unconstrained_capacities = np.log2(1 + unconstrained_solution['powers']/noise_powers)
        constrained_capacities = np.log2(1 + powers_opt/noise_powers)
        
        plt.bar(x - width/2, unconstrained_capacities, width, 
               label='Unconstrained', alpha=0.7)
        plt.bar(x + width/2, constrained_capacities, width, 
               label='With Individual Limits', alpha=0.7)
        
        plt.xlabel('Channel Index')
        plt.ylabel('Channel Capacity (bits/s/Hz)')
        plt.title('Channel Capacity Comparison')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        print(f"\nCapacity Loss due to Individual Constraints:")
        unconstrained_total = np.sum(unconstrained_capacities)
        constrained_total = np.sum(constrained_capacities)
        loss = unconstrained_total - constrained_total
        print(f"Unconstrained capacity: {unconstrained_total:.4f} bits/s/Hz")
        print(f"Constrained capacity: {constrained_total:.4f} bits/s/Hz")
        print(f"Capacity loss: {loss:.4f} bits/s/Hz ({loss/unconstrained_total*100:.2f}%)")
        
        return powers_opt, capacity
    
    else:
        print("Failed to solve generalized water-filling problem")
        return None, None

# Run examples
wf_result, solution_result = example_classical_water_filling()
gen_powers, gen_capacity = example_generalized_water_filling()
```

</details>

---

## üí° M·∫πo Th·ª±c H√†nh

#### **Khi ki·ªÉm ch·ª©ng ƒëi·ªÅu ki·ªán KKT:**
- Ki·ªÉm tra t·ª´ng ƒëi·ªÅu ki·ªán m·ªôt c√°ch c√≥ h·ªá th·ªëng v√† ri√™ng bi·ªát
- S·ª≠ d·ª•ng sai s·ªë s·ªë h·ªçc ph√π h·ª£p
- Ch√∫ √Ω ƒë·∫øn gi·∫£i th√≠ch ƒëi·ªÅu ki·ªán b√π
- Ki·ªÉm ch·ª©ng ƒëi·ªÅu ki·ªán ƒë·ªß r√†ng bu·ªôc cho t√≠nh c·∫ßn thi·∫øt

#### **Khi gi·∫£i gi·∫£i t√≠ch v·ªõi KKT:**
- S·ª≠ d·ª•ng li·ªát k√™ t·∫≠p ho·∫°t ƒë·ªông cho c√°c b√†i to√°n nh·ªè
- √Åp d·ª•ng ƒëi·ªÅu ki·ªán b√π ƒë·ªÉ x√°c ƒë·ªãnh r√†ng bu·ªôc ho·∫°t ƒë·ªông
- Gi·∫£i c√°c h·ªá tuy·∫øn t√≠nh ƒë∆∞·ª£c h√¨nh th√†nh b·ªüi t√≠nh d·ª´ng + r√†ng bu·ªôc ho·∫°t ƒë·ªông
- Ki·ªÉm tra t√≠nh kh·∫£ thi v√† t√≠nh t·ªëi ∆∞u c·ªßa t·ª´ng ·ª©ng vi√™n

#### **Khi l·∫≠p tr√¨nh c√°c thu·∫≠t to√°n:**
- Gi√°m s√°t ph·∫ßn d∆∞ KKT ƒë·ªÉ ki·ªÉm tra h·ªôi t·ª•
- S·ª≠ d·ª•ng k√≠ch th∆∞·ªõc b∆∞·ªõc v√† ƒëi·ªÅu chu·∫©n ph√π h·ª£p
- X·ª≠ l√Ω c√°c v·∫•n ƒë·ªÅ s·ªë v·ªõi h·ªá ƒëi·ªÅu ki·ªán x·∫•u
- L·∫≠p tr√¨nh c√°c chi·∫øn l∆∞·ª£c kh·ªüi ƒë·ªông ·∫•m

#### **Khi gi·∫£i th√≠ch k·∫øt qu·∫£:**
- Bi·∫øn ƒë·ªëi ng·∫´u cung c·∫•p gi·∫£i th√≠ch kinh t·∫ø
- R√†ng bu·ªôc ho·∫°t ƒë·ªông cho bi·∫øt gi·ªõi h·∫°n r√†ng bu·ªôc
- ƒêi·ªÅu ki·ªán b√π ti·∫øt l·ªô c√°c s·ª± ƒë√°nh ƒë·ªïi
- Ph√¢n t√≠ch ƒë·ªô nh·∫°y th√¥ng qua bi·∫øn ƒë·ªëi ng·∫´u

---

## üìö T√†i li·ªáu tham kh·∫£o

1. **Boyd, S., & Vandenberghe, L.** (2004). *Convex Optimization*. Cambridge University Press.
   - Chapter 12: KKT Conditions

2. **Nocedal, J., & Wright, S. J.** (2006). *Numerical Optimization*. Springer.

3. **Bertsekas, D. P.** (1999). *Nonlinear Programming*. Athena Scientific.
