---
layout: post
title: 12-07 B√†i t·∫≠p tr·∫Øc nghi·ªám - ƒêi·ªÅu Ki·ªán KKT
chapter: '12'
order: 8
owner: GitHub Copilot
lang: vi
categories:
- chapter12
lesson_type: quiz
---

## üìö √în t·∫≠p l√Ω thuy·∫øt

Tr∆∞·ªõc khi l√†m b√†i t·∫≠p, h√£y √¥n l·∫°i c√°c kh√°i ni·ªám ch√≠nh trong ch∆∞∆°ng n√†y:

### ‚ö° **ƒêi·ªÅu Ki·ªán Karush-Kuhn-Tucker (KKT)**

#### **B√†i to√°n t·ªëi ∆∞u t·ªïng qu√°t**
$$\min_x f(x) \quad \text{s.t.} \quad h_i(x) \le 0, \quad l_j(x) = 0$$

v·ªõi $$i = 1,\ldots,m$$ v√† $$j = 1,\ldots,r$$

#### **B·ªën ƒëi·ªÅu ki·ªán KKT**
Cho nghi·ªám $$x^*, \lambda^*, \nu^*$$:

1. **Stationarity (T√≠nh d·ª´ng):**
   $$0 \in \partial \left( f(x^*) + \sum_{i=1}^m \lambda_i^* h_i(x^*) + \sum_{j=1}^r \nu_j^* l_j(x^*) \right)$$

2. **Complementary Slackness (B√π y·∫øu):**
   $$\lambda_i^* \cdot h_i(x^*) = 0 \quad \forall i$$

3. **Primal Feasibility (T√≠nh kh·∫£ thi nguy√™n th·ªßy):**
   $$h_i(x^*) \le 0, \quad l_j(x^*) = 0 \quad \forall i,j$$

4. **Dual Feasibility (T√≠nh kh·∫£ thi ƒë·ªëi ng·∫´u):**
   $$\lambda_i^* \ge 0 \quad \forall i$$

#### **√ù nghƒ©a c√°c ƒëi·ªÅu ki·ªán**
- **Stationarity:** Gradient c·ªßa Lagrangian b·∫±ng 0
- **Complementary slackness:** Ho·∫∑c constraint active ($$h_i = 0$$) ho·∫∑c dual variable = 0 ($$\lambda_i = 0$$)
- **Primal feasibility:** Th·ªèa m√£n t·∫•t c·∫£ constraints c·ªßa b√†i to√°n g·ªëc
- **Dual feasibility:** Dual variables cho inequality constraints ph·∫£i non-negative

### üìä **T√≠nh ƒê·ªß v√† T√≠nh C·∫ßn Thi·∫øt**

#### **T√≠nh ƒë·ªß (Sufficiency)**
**N·∫øu** $$x^*, \lambda^*, \nu^*$$ th·ªèa m√£n KKT conditions v√† b√†i to√°n **convex**, **th√¨** ch√∫ng l√† optimal solutions.

**Ch·ª©ng minh:**
$$g(\lambda^*, \nu^*) = \min_x L(x, \lambda^*, \nu^*) = L(x^*, \lambda^*, \nu^*) = f(x^*)$$

Do ƒë√≥: $$g(\lambda^*, \nu^*) = f(x^*)$$ ‚üπ duality gap = 0 ‚üπ optimal

#### **T√≠nh c·∫ßn thi·∫øt (Necessity)**
**N·∫øu** $$x^*, \lambda^*, \nu^*$$ l√† optimal solutions v·ªõi **strong duality**, **th√¨** ch√∫ng th·ªèa m√£n KKT conditions.

**ƒêi·ªÅu ki·ªán:** Strong duality (v√≠ d·ª•: Slater's condition)

#### **T·ªïng h·ª£p**
Cho convex problems v·ªõi strong duality:
$$x^*, \lambda^*, \nu^* \text{ optimal} \Leftrightarrow x^*, \lambda^*, \nu^* \text{ satisfy KKT}$$

### üîÑ **V√≠ D·ª•: Quadratic Programming v·ªõi Equality Constraints**

#### **B√†i to√°n**
$$\min_x \frac{1}{2}x^T P x + q^T x + r \quad \text{s.t.} \quad Ax = b$$

v·ªõi $$P \in \mathbb{S}_+^n$$ (positive semidefinite)

#### **KKT conditions**
- **Stationarity:** $$Px^* + q + A^T \nu^* = 0$$
- **Primal feasibility:** $$Ax^* = b$$
- **Complementary slackness:** Kh√¥ng c√≥ (no inequality constraints)
- **Dual feasibility:** Kh√¥ng c√≥ (no inequality constraints)

#### **H·ªá Ma Tr·∫≠n KKT**
$$\begin{bmatrix} P & A^T \\ A & 0 \end{bmatrix} \begin{bmatrix} x^* \\ \nu^* \end{bmatrix} = \begin{bmatrix} -q \\ b \end{bmatrix}$$

**√ù nghƒ©a:** ƒê√¢y ch√≠nh l√† **Newton step** cho constrained optimization!

### üåä **V√≠ D·ª•: Water-Filling Algorithm**

#### **B√†i to√°n**
$$\min_x -\sum_{i=1}^n \log(\alpha_i + x_i) \quad \text{s.t.} \quad x \succeq 0, \quad \mathbf{1}^T x = 1$$

v·ªõi $$\alpha_i > 0$$

#### **KKT conditions**
- **Stationarity:** $$-\frac{1}{\alpha_i + x_i^*} - \lambda_i^* + \nu^* = 0$$
- **Complementary slackness:** $$\lambda_i^* x_i^* = 0$$
- **Primal feasibility:** $$x^* \succeq 0, \mathbf{1}^T x^* = 1$$
- **Dual feasibility:** $$\lambda^* \succeq 0$$

#### **Analytical solution**
$$x_i^* = \max\left\{0, \frac{1}{\nu^*} - \alpha_i\right\}$$

v·ªõi $$\nu^*$$ ƒë∆∞·ª£c x√°c ƒë·ªãnh t·ª´: $$\sum_{i=1}^n \max\left\{0, \frac{1}{\nu^*} - \alpha_i\right\} = 1$$

#### **Water-filling interpretation**
- $$\alpha_i$$: "Ground level" c·ªßa channel $$i$$
- $$\frac{1}{\nu^*}$$: "Water level" chung
- $$x_i^*$$: "Water depth" trong channel $$i$$
- **Thu·∫≠t to√°n:** ƒê·ªï n∆∞·ªõc cho ƒë·∫øn khi t·ªïng volume = 1

### üéØ **V√≠ D·ª•: Support Vector Machine (SVM)**

#### **Primal problem**
$$\min_{\beta,\beta_0,\xi} \frac{1}{2}\|\beta\|_2^2 + C\sum_{i=1}^n \xi_i$$
$$\text{s.t.} \quad \xi_i \ge 0, \quad y_i(x_i^T\beta + \beta_0) \ge 1 - \xi_i$$

#### **KKT conditions**
- **Stationarity:**
  - $$\beta^* = \sum_{i=1}^n w_i^* y_i x_i$$
  - $$\sum_{i=1}^n w_i^* y_i = 0$$
  - $$w^* = C\mathbf{1} - v^*$$

- **Complementary slackness:**
  - $$v_i^* \xi_i^* = 0$$
  - $$w_i^* (1 - \xi_i^* - y_i(x_i^T\beta^* + \beta_0^*)) = 0$$

#### **Support vectors**
**ƒêi·ªÉm $$i$$ l√† support vector** ‚ü∫ $$w_i^* > 0$$

**Hai lo·∫°i support vectors:**
- **On margin:** $$\xi_i^* = 0$$, $$w_i^* \in (0, C]$$
- **Inside margin:** $$\xi_i^* > 0$$, $$w_i^* = C$$

#### **Practical implications**
- **Sparsity:** Ch·ªâ support vectors c√≥ $$w_i^* > 0$$
- **Efficiency:** C√≥ th·ªÉ filter non-support points tr∆∞·ªõc khi optimize
- **Interpretation:** KKT conditions gi·∫£i th√≠ch structure c·ªßa SVM solution

### üîÑ **Constrained Form vs Lagrangian Form**

#### **Constrained form (C)**
$$\min_x f(x) \quad \text{s.t.} \quad h(x) \le t$$

#### **Lagrangian form (L)**
$$\min_x f(x) + \lambda h(x)$$

#### **Equivalence conditions**
**Khi n√†o (C) v√† (L) equivalent?**

1. **(C) ‚Üí (L):** N·∫øu (C) th·ªèa m√£n Slater + strong duality, t·ªìn t·∫°i $$\lambda^* \ge 0$$ sao cho solution c·ªßa (C) c≈©ng l√† solution c·ªßa (L)

2. **(L) ‚Üí (C):** N·∫øu $$x^*$$ solve (L) v√† KKT conditions hold, th√¨ $$x^*$$ c≈©ng solve (C) v·ªõi $$t = h(x^*)$$

#### **Perfect equivalence**
**Khi:** $$h(x) \ge 0$$ (nh∆∞ norm), $$t = 0$$, $$\lambda = \infty$$

**K·∫øt qu·∫£:** C·∫£ hai ƒë·ªÅu enforce $$h(x) = 0$$

### üõ†Ô∏è **K·ªπ Thu·∫≠t Th·ª±c H√†nh**

#### **Ki·ªÉm tra KKT conditions:**
1. **Verify stationarity:** $$\nabla_x L(x^*, \lambda^*, \nu^*) = 0$$
2. **Check complementary slackness:** $$\lambda_i^* h_i(x^*) = 0 \quad \forall i$$
3. **Verify feasibility:** Primal v√† dual constraints
4. **Confirm optimality:** N·∫øu convex + KKT ‚üπ optimal

#### **Analytical solution strategy:**
1. **Write KKT conditions** cho specific problem
2. **Use complementary slackness** ƒë·ªÉ identify active constraints
3. **Solve system of equations** t·ª´ stationarity + feasibility
4. **Verify solution** th·ªèa m√£n t·∫•t c·∫£ KKT conditions

#### **Computational applications:**
- **Active set methods:** Identify active constraints iteratively
- **Interior point methods:** Follow central path satisfying KKT
- **Primal-dual methods:** Update primal v√† dual simultaneously

### üí° **V√≠ D·ª• Minh H·ªça**

#### **B√†i to√°n ƒë∆°n gi·∫£n:**
$$\min_x x^2 + y^2 \quad \text{s.t.} \quad x + y = 1, \quad x \ge 0$$

**KKT conditions:**
- **Stationarity:** $$2x^* - \lambda^* + \nu^* = 0$$, $$2y^* + \nu^* = 0$$
- **Complementary slackness:** $$\lambda^* x^* = 0$$
- **Primal feasibility:** $$x^* + y^* = 1$$, $$x^* \ge 0$$
- **Dual feasibility:** $$\lambda^* \ge 0$$

**Case analysis:**
- **Case 1:** $$x^* > 0$$ ‚üπ $$\lambda^* = 0$$ ‚üπ $$x^* = y^* = 1/2$$
- **Case 2:** $$x^* = 0$$ ‚üπ $$y^* = 1$$ ‚üπ $$\lambda^* = 2$$

**Optimal solution:** $$x^* = 1/2, y^* = 1/2$$ (Case 1 gives smaller objective)

### üéØ **K·∫øt N·ªëi V·ªõi C√°c Ch∆∞∆°ng**

#### **T·ª´ ch∆∞∆°ng tr∆∞·ªõc:**
- **Ch∆∞∆°ng 11:** General duality theory - KKT l√† direct consequence
- **Ch∆∞∆°ng 10:** LP duality - KKT generalizes optimality conditions
- **Ch∆∞∆°ng 04:** First-order optimality conditions - KKT extends to constrained

#### **T·∫ßm quan tr·ªçng c·ªßa KKT:**
- **Optimality characterization:** Necessary v√† sufficient conditions
- **Algorithm design:** Active set, interior point, SQP methods
- **Theoretical analysis:** Sensitivity, perturbation theory
- **Machine learning:** SVM, regularization, constrained learning

#### **H∆∞·ªõng ph√°t tri·ªÉn:**
- **Second-order conditions:** Bordered Hessian, LICQ, MFCQ
- **Nonlinear programming:** SQP, trust region methods
- **Variational inequalities:** Complementarity problems
- **Optimal control:** Pontryagin maximum principle

### üåü **√ù Nghƒ©a L√Ω Thuy·∫øt**

#### **KKT nh∆∞ universal optimality conditions:**
- **Unifies:** Unconstrained ($$\nabla f = 0$$) v√† constrained optimization
- **Characterizes:** Exactly when point is optimal
- **Enables:** Systematic algorithm design
- **Connects:** Primal v√† dual perspectives

#### **Geometric interpretation:**
- **Stationarity:** Gradient orthogonal to feasible directions
- **Complementary slackness:** Either constraint active ho·∫∑c multiplier zero
- **Feasibility:** Point lies in feasible region
- **Non-negativity:** Consistent v·ªõi constraint directions

#### **Computational significance:**
- **Algorithm foundation:** Most constrained optimization algorithms
- **Convergence criteria:** KKT residual nh∆∞ stopping condition
- **Sensitivity analysis:** Dual variables nh∆∞ shadow prices
- **Problem structure:** Active set identification

### üí° **M·∫πo Th·ª±c H√†nh**

#### **Khi n√†o s·ª≠ d·ª•ng KKT:**
1. **Analytical solutions:** Small problems v·ªõi closed-form solutions
2. **Algorithm design:** Foundation cho numerical methods
3. **Optimality verification:** Check if candidate point optimal
4. **Sensitivity analysis:** Understand parameter changes

#### **Common pitfalls:**
- **Forget constraint qualifications:** LICQ, MFCQ for necessity
- **Wrong complementary slackness:** $$\lambda_i h_i = 0$$, not $$\lambda_i = 0$$ or $$h_i = 0$$
- **Non-convex problems:** KKT necessary but not sufficient
- **Numerical issues:** KKT matrix c√≥ th·ªÉ ill-conditioned

#### **Debugging strategies:**
- **Check each condition separately:** Stationarity, slackness, feasibility
- **Verify constraint qualifications:** For necessity
- **Use geometric intuition:** Gradient orthogonality
- **Compare v·ªõi known solutions:** Simple test cases

### üî¨ **Advanced Topics**

#### **Constraint qualifications:**
- **LICQ:** Linear Independence Constraint Qualification
- **MFCQ:** Mangasarian-Fromovitz Constraint Qualification
- **CPLD:** Constant Positive Linear Dependence
- **Applications:** When KKT conditions are necessary

#### **Second-order conditions:**
- **SOSC:** Second-Order Sufficient Conditions
- **Bordered Hessian:** For equality-constrained problems
- **Critical cone:** Directions of potential descent
- **Applications:** Algorithm convergence rates

#### **Variational inequalities:**
- **Complementarity problems:** Generalize KKT conditions
- **Nash equilibria:** Game theory applications
- **Contact mechanics:** Engineering applications

### üìà **·ª®ng D·ª•ng Th·ª±c T·∫ø**

#### **Machine Learning:**
- **SVM:** Dual formulation v√† support vector identification
- **Regularization:** L1, L2 penalties via constrained formulation
- **Neural networks:** Constrained training, fairness constraints

#### **Engineering:**
- **Optimal control:** Pontryagin maximum principle
- **Signal processing:** Filter design, beamforming
- **Structural optimization:** Weight minimization v·ªõi stress constraints

#### **Economics v√† Finance:**
- **Portfolio optimization:** Risk-return tradeoffs
- **Mechanism design:** Incentive compatibility
- **Resource allocation:** Utility maximization

#### **Operations Research:**
- **Production planning:** Capacity constraints
- **Supply chain:** Inventory optimization
- **Transportation:** Network flow problems

---

üí° **M·∫πo:** KKT conditions l√† **crown jewel** c·ªßa optimization theory - ch√∫ng provide exact characterization c·ªßa optimality cho constrained problems v√† l√† foundation cho h·∫ßu h·∫øt modern optimization algorithms!

---

<script>
window.MathJax = {
  tex: {
    inlineMath: [['\\(', '\\)']],
    displayMath: [['\\[', '\\]'], ['$$', '$$']],
    processEscapes: true,
    processEnvironments: true
  },
  options: {
    ignoreHtmlClass: ".*|",
    processHtmlClass: "arithmatex"
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<style>
/* S·ª≠a l·ªói alignment cho MathJax inline math */
.MathJax {
    vertical-align: baseline !important;
}

mjx-container[jax="CHTML"][display="false"] {
    vertical-align: baseline !important;
    display: inline !important;
}

/* ƒê·∫£m b·∫£o c√°c label trong quiz c√≥ alignment t·ªët */
.options label {
    display: flex;
    align-items: center;
    margin: 8px 0;
    padding: 8px;
    border-radius: 4px;
    transition: background-color 0.2s;
}

.options label:hover {
    background-color: #f0f0f0;
}

.options input[type="radio"] {
    margin-right: 8px;
    flex-shrink: 0;
}

/* Styling cho quiz container */
#quiz-container {
    max-width: 800px;
    margin: 0 auto;
    padding: 20px;
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}

.question {
    background: #f8f9fa;
    border-left: 4px solid #007bff;
    padding: 20px;
    margin: 20px 0;
    border-radius: 8px;
}

.question h3 {
    color: #2c3e50;
    margin-bottom: 15px;
}

.explanation {
    background: #e8f5e8;
    border: 1px solid #28a745;
    padding: 15px;
    margin-top: 15px;
    border-radius: 6px;
}

.quiz-controls {
    text-align: center;
    margin: 30px 0;
}

.quiz-controls button {
    background: #007bff;
    color: white;
    border: none;
    padding: 12px 24px;
    margin: 0 10px;
    border-radius: 6px;
    cursor: pointer;
    font-size: 16px;
    transition: background-color 0.3s;
}

.quiz-controls button:hover {
    background: #0056b3;
}

.quiz-controls button:disabled {
    background: #6c757d;
    cursor: not-allowed;
}

.progress-bar {
    width: 100%;
    height: 8px;
    background: #e9ecef;
    border-radius: 4px;
    margin: 20px 0;
    overflow: hidden;
}

.progress-fill {
    height: 100%;
    background: linear-gradient(90deg, #007bff, #28a745);
    transition: width 0.3s ease;
}

.score-display {
    text-align: center;
    font-size: 18px;
    font-weight: bold;
    color: #2c3e50;
    margin: 20px 0;
}

.options label.selected {
    background-color: #e3f2fd;
    border: 2px solid #2196f3;
}

.final-score {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 30px;
    border-radius: 15px;
    text-align: center;
    margin: 30px 0;
}
</style>

B√†i t·∫≠p tr·∫Øc nghi·ªám n√†y ki·ªÉm tra hi·ªÉu bi·∫øt c·ªßa b·∫°n v·ªÅ ƒëi·ªÅu ki·ªán Karush-Kuhn-Tucker (KKT), bao g·ªìm c√°c v√≠ d·ª• th·ª±c t·∫ø nh∆∞ SVM, water-filling algorithm, quadratic programming v√† L1 penalized problems.

---

<div id="quiz-container">
    <div id="quiz-header">
        <h2>‚öñÔ∏è Quiz: ƒêi·ªÅu Ki·ªán KKT</h2>
        <div class="progress-bar">
            <div class="progress-fill" id="progress-fill" style="width: 5%"></div>
        </div>
        <div class="score-display" id="score-display">C√¢u h·ªèi: <span id="current-q">1</span> / <span id="total-q">20</span></div>
    </div>

    <div id="quiz-content">
        <!-- C√¢u h·ªèi 1: KKT conditions components -->
        <div class="question" id="q1" style="display: block;">
            <h3>C√¢u 1: ƒêi·ªÅu ki·ªán KKT bao g·ªìm nh·ªØng th√†nh ph·∫ßn n√†o?</h3>
            <div class="options">
                <label><input type="radio" name="q1" value="a"> A) Ch·ªâ stationarity v√† complementary slackness</label>
                <label><input type="radio" name="q1" value="b"> B) Stationarity, complementary slackness, primal feasibility, dual feasibility</label>
                <label><input type="radio" name="q1" value="c"> C) Ch·ªâ primal v√† dual feasibility</label>
                <label><input type="radio" name="q1" value="d"> D) Ch·ªâ stationarity</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: B) Stationarity, complementary slackness, primal feasibility, dual feasibility</strong><br>
                KKT conditions g·ªìm 4 th√†nh ph·∫ßn: (1) Stationarity, (2) Complementary slackness, (3) Primal feasibility, (4) Dual feasibility.
            </div>
        </div>

        <!-- C√¢u h·ªèi 2: Stationarity condition -->
        <div class="question" id="q2" style="display: none;">
            <h3>C√¢u 2: Stationarity condition trong KKT c√≥ d·∫°ng:</h3>
            <div class="options">
                <label><input type="radio" name="q2" value="a"> A) \(\nabla f(x^*) = 0\)</label>
                <label><input type="radio" name="q2" value="b"> B) \(\nabla f(x^*) + \sum \lambda_i \nabla h_i(x^*) + \sum \nu_j \nabla l_j(x^*) = 0\)</label>
                <label><input type="radio" name="q2" value="c"> C) \(\lambda_i h_i(x^*) = 0\)</label>
                <label><input type="radio" name="q2" value="d"> D) \(h_i(x^*) \leq 0\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: B) $$\nabla f(x^*) + \sum \lambda_i \nabla h_i(x^*) + \sum \nu_j \nabla l_j(x^*) = 0$$</strong><br>
                Stationarity: gradient c·ªßa Lagrangian theo $$x$$ b·∫±ng 0, t·ª©c l√† gradient c·ªßa objective c√¢n b·∫±ng v·ªõi t·ªï h·ª£p tuy·∫øn t√≠nh c·ªßa gradients c·ªßa constraints.
            </div>
        </div>

        <!-- C√¢u h·ªèi 3: Complementary slackness -->
        <div class="question" id="q3" style="display: none;">
            <h3>C√¢u 3: Complementary slackness condition ph√°t bi·ªÉu r·∫±ng:</h3>
            <div class="options">
                <label><input type="radio" name="q3" value="a"> A) \(\lambda_i h_i(x^*) = 0\) v·ªõi m·ªçi \(i\)</label>
                <label><input type="radio" name="q3" value="b"> B) \(\lambda_i = 0\) ho·∫∑c \(h_i(x^*) = 0\)</label>
                <label><input type="radio" name="q3" value="c"> C) N·∫øu \(h_i(x^*) < 0\) th√¨ \(\lambda_i = 0\)</label>
                <label><input type="radio" name="q3" value="d"> D) T·∫•t c·∫£ c√°c ƒëi·ªÅu tr√™n</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: D) T·∫•t c·∫£ c√°c ƒëi·ªÅu tr√™n</strong><br>
                Complementary slackness c√≥ th·ªÉ ph√°t bi·ªÉu theo nhi·ªÅu c√°ch t∆∞∆°ng ƒë∆∞∆°ng: $$\lambda_i h_i(x^*) = 0$$, ho·∫∑c $$\lambda_i = 0$$ ho·∫∑c $$h_i(x^*) = 0$$, ho·∫∑c inactive constraints c√≥ dual variable = 0.
            </div>
        </div>

        <!-- C√¢u h·ªèi 4: KKT sufficiency -->
        <div class="question" id="q4" style="display: none;">
            <h3>C√¢u 4: KKT conditions l√† ƒëi·ªÅu ki·ªán ƒë·ªß cho global optimality khi:</h3>
            <div class="options">
                <label><input type="radio" name="q4" value="a"> A) B√†i to√°n l√† convex</label>
                <label><input type="radio" name="q4" value="b"> B) B√†i to√°n l√† non-convex</label>
                <label><input type="radio" name="q4" value="c"> C) Lu√¥n lu√¥n</label>
                <label><input type="radio" name="q4" value="d"> D) Kh√¥ng bao gi·ªù</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) B√†i to√°n l√† convex</strong><br>
                KKT conditions l√† necessary (v·ªõi constraint qualification) cho m·ªçi b√†i to√°n, nh∆∞ng ch·ªâ sufficient cho global optimality khi b√†i to√°n convex.
            </div>
        </div>

        <!-- C√¢u h·ªèi 5: Active constraints -->
        <div class="question" id="q5" style="display: none;">
            <h3>C√¢u 5: Constraint \(h_i(x) \leq 0\) ƒë∆∞·ª£c g·ªçi l√† active t·∫°i \(x^*\) khi:</h3>
            <div class="options">
                <label><input type="radio" name="q5" value="a"> A) \(h_i(x^*) < 0\)</label>
                <label><input type="radio" name="q5" value="b"> B) \(h_i(x^*) = 0\)</label>
                <label><input type="radio" name="q5" value="c"> C) \(\lambda_i > 0\)</label>
                <label><input type="radio" name="q5" value="d"> D) \(\lambda_i = 0\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: B) $$h_i(x^*) = 0$$</strong><br>
                Constraint active c√≥ nghƒ©a l√† n√≥ ƒë∆∞·ª£c th·ªèa m√£n v·ªõi d·∫•u b·∫±ng t·∫°i optimal point.
            </div>
        </div>

        <!-- C√¢u h·ªèi 6: Quadratic programming KKT -->
        <div class="question" id="q6" style="display: none;">
            <h3>C√¢u 6: Trong quadratic programming \(\min \frac{1}{2}x^T Q x + c^T x\) s.t. \(Ax = b\), stationarity condition l√†:</h3>
            <div class="options">
                <label><input type="radio" name="q6" value="a"> A) \(Qx^* + c = 0\)</label>
                <label><input type="radio" name="q6" value="b"> B) \(Qx^* + c + A^T \nu^* = 0\)</label>
                <label><input type="radio" name="q6" value="c"> C) \(Ax^* = b\)</label>
                <label><input type="radio" name="q6" value="d"> D) \(\nu^* = 0\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: B) $$Qx^* + c + A^T \nu^* = 0$$</strong><br>
                Stationarity: $$\nabla f(x^*) + A^T \nu^* = Qx^* + c + A^T \nu^* = 0$$.
            </div>
        </div>

        <!-- C√¢u h·ªèi 7: Water-filling problem -->
        <div class="question" id="q7" style="display: none;">
            <h3>C√¢u 7: Trong water-filling algorithm, b√†i to√°n t·ªëi ∆∞u c√≥ d·∫°ng:</h3>
            <div class="options">
                <label><input type="radio" name="q7" value="a"> A) \(\max \sum \log(\alpha_i + x_i)\) s.t. \(\sum x_i = P, x_i \geq 0\)</label>
                <label><input type="radio" name="q7" value="b"> B) \(\min \sum \log(\alpha_i + x_i)\) s.t. \(\sum x_i = P, x_i \geq 0\)</label>
                <label><input type="radio" name="q7" value="c"> C) \(\max \sum x_i^2\) s.t. \(\sum x_i = P\)</label>
                <label><input type="radio" name="q7" value="d"> D) \(\min \sum x_i^2\) s.t. \(\sum x_i = P\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) $$\max \sum \log(\alpha_i + x_i)$$ s.t. $$\sum x_i = P, x_i \geq 0$$</strong><br>
                Water-filling maximizes sum of log capacities subject to total power constraint v√† non-negativity.
            </div>
        </div>

        <!-- C√¢u h·ªèi 8: Water-filling solution -->
        <div class="question" id="q8" style="display: none;">
            <h3>C√¢u 8: Nghi·ªám c·ªßa water-filling algorithm c√≥ d·∫°ng:</h3>
            <div class="options">
                <label><input type="radio" name="q8" value="a"> A) \(x_i^* = \max(0, \mu - \alpha_i)\)</label>
                <label><input type="radio" name="q8" value="b"> B) \(x_i^* = \max(0, \alpha_i - \mu)\)</label>
                <label><input type="radio" name="q8" value="c"> C) \(x_i^* = \mu - \alpha_i\)</label>
                <label><input type="radio" name="q8" value="d"> D) \(x_i^* = \alpha_i + \mu\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) $$x_i^* = \max(0, \mu - \alpha_i)$$</strong><br>
                Water-filling solution: allocate power $$\mu - \alpha_i$$ to channel $$i$$ if $$\mu > \alpha_i$$, otherwise allocate 0.
            </div>
        </div>

        <!-- C√¢u h·ªèi 9: SVM primal problem -->
        <div class="question" id="q9" style="display: none;">
            <h3>C√¢u 9: SVM primal problem c√≥ d·∫°ng:</h3>
            <div class="options">
                <label><input type="radio" name="q9" value="a"> A) \(\min \frac{1}{2}\|w\|^2\) s.t. \(y_i(w^T x_i + b) \geq 1\)</label>
                <label><input type="radio" name="q9" value="b"> B) \(\max \frac{1}{2}\|w\|^2\) s.t. \(y_i(w^T x_i + b) \geq 1\)</label>
                <label><input type="radio" name="q9" value="c"> C) \(\min \sum \alpha_i\) s.t. \(\sum \alpha_i y_i = 0\)</label>
                <label><input type="radio" name="q9" value="d"> D) \(\max \sum \alpha_i\) s.t. \(\sum \alpha_i y_i = 0\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) $$\min \frac{1}{2}\|w\|^2$$ s.t. $$y_i(w^T x_i + b) \geq 1$$</strong><br>
                SVM primal: minimize margin width subject to classification constraints.
            </div>
        </div>

        <!-- C√¢u h·ªèi 10: SVM dual problem -->
        <div class="question" id="q10" style="display: none;">
            <h3>C√¢u 10: SVM dual problem c√≥ d·∫°ng:</h3>
            <div class="options">
                <label><input type="radio" name="q10" value="a"> A) \(\min \sum \alpha_i - \frac{1}{2}\sum \alpha_i \alpha_j y_i y_j x_i^T x_j\)</label>
                <label><input type="radio" name="q10" value="b"> B) \(\max \sum \alpha_i - \frac{1}{2}\sum \alpha_i \alpha_j y_i y_j x_i^T x_j\)</label>
                <label><input type="radio" name="q10" value="c"> C) \(\min \frac{1}{2}\|w\|^2 + C\sum \xi_i\)</label>
                <label><input type="radio" name="q10" value="d"> D) \(\max \frac{1}{2}\|w\|^2\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: B) $$\max \sum \alpha_i - \frac{1}{2}\sum \alpha_i \alpha_j y_i y_j x_i^T x_j$$</strong><br>
                SVM dual maximizes linear term minus quadratic term subject to constraints $$\sum \alpha_i y_i = 0, \alpha_i \geq 0$$.
            </div>
        </div>

        <!-- C√¢u h·ªèi 11: Support vectors -->
        <div class="question" id="q11" style="display: none;">
            <h3>C√¢u 11: Support vectors trong SVM l√† nh·ªØng ƒëi·ªÉm c√≥:</h3>
            <div class="options">
                <label><input type="radio" name="q11" value="a"> A) \(\alpha_i = 0\)</label>
                <label><input type="radio" name="q11" value="b"> B) \(\alpha_i > 0\)</label>
                <label><input type="radio" name="q11" value="c"> C) \(y_i(w^T x_i + b) > 1\)</label>
                <label><input type="radio" name="q11" value="d"> D) \(y_i(w^T x_i + b) < 1\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: B) $$\alpha_i > 0$$</strong><br>
                Support vectors c√≥ dual variables $$\alpha_i > 0$$ v√† n·∫±m tr√™n margin boundary: $$y_i(w^T x_i + b) = 1$$.
            </div>
        </div>

        <!-- C√¢u h·ªèi 12: LICQ condition -->
        <div class="question" id="q12" style="display: none;">
            <h3>C√¢u 12: Linear Independence Constraint Qualification (LICQ) y√™u c·∫ßu:</h3>
            <div class="options">
                <label><input type="radio" name="q12" value="a"> A) T·∫•t c·∫£ constraints ƒë·ªÅu active</label>
                <label><input type="radio" name="q12" value="b"> B) Gradients c·ªßa active constraints ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh</label>
                <label><input type="radio" name="q12" value="c"> C) T·∫•t c·∫£ constraints ƒë·ªÅu inactive</label>
                <label><input type="radio" name="q12" value="d"> D) Objective function kh·∫£ vi</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: B) Gradients c·ªßa active constraints ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh</strong><br>
                LICQ ƒë·∫£m b·∫£o gradients c·ªßa active constraints t·∫°i optimal point ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh, guarantee KKT necessity.
            </div>
        </div>

        <!-- C√¢u h·ªèi 13: L1 penalized problem -->
        <div class="question" id="q13" style="display: none;">
            <h3>C√¢u 13: Trong L1 penalized problem \(\min f(x) + \lambda\|x\|_1\), ƒëi·ªÅu ki·ªán KKT cho th√†nh ph·∫ßn \(x_i\) l√†:</h3>
            <div class="options">
                <label><input type="radio" name="q13" value="a"> A) \(\frac{\partial f}{\partial x_i} + \lambda \text{sign}(x_i) = 0\) n·∫øu \(x_i \neq 0\)</label>
                <label><input type="radio" name="q13" value="b"> B) \(\frac{\partial f}{\partial x_i} + \lambda = 0\)</label>
                <label><input type="radio" name="q13" value="c"> C) \(\frac{\partial f}{\partial x_i} = 0\)</label>
                <label><input type="radio" name="q13" value="d"> D) \(x_i = 0\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) $$\frac{\partial f}{\partial x_i} + \lambda \text{sign}(x_i) = 0$$ n·∫øu $$x_i \neq 0$$</strong><br>
                Khi $$x_i \neq 0$$, subgradient c·ªßa $$|x_i|$$ l√† $$\text{sign}(x_i)$$. Khi $$x_i = 0$$, subgradient l√† $$[-1,1]$$.
            </div>
        </div>

        <!-- C√¢u h·ªèi 14: Uniqueness in L1 -->
        <div class="question" id="q14" style="display: none;">
            <h3>C√¢u 14: Trong L1 regularization, nghi·ªám duy nh·∫•t khi:</h3>
            <div class="options">
                <label><input type="radio" name="q14" value="a"> A) \(f\) l√† strictly convex</label>
                <label><input type="radio" name="q14" value="b"> B) \(\lambda\) ƒë·ªß l·ªõn</label>
                <label><input type="radio" name="q14" value="c"> C) Active set ƒë∆∞·ª£c x√°c ƒë·ªãnh duy nh·∫•t</label>
                <label><input type="radio" name="q14" value="d"> D) T·∫•t c·∫£ c√°c ƒëi·ªÅu tr√™n</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) $$f$$ l√† strictly convex</strong><br>
                Strict convexity c·ªßa $$f$$ ƒë·∫£m b·∫£o uniqueness c·ªßa nghi·ªám, ngay c·∫£ khi L1 term kh√¥ng strictly convex.
            </div>
        </div>

        <!-- C√¢u h·ªèi 15: KKT matrix system -->
        <div class="question" id="q15" style="display: none;">
            <h3>C√¢u 15: H·ªá ph∆∞∆°ng tr√¨nh KKT cho equality constrained QP c√≥ th·ªÉ vi·∫øt d∆∞·ªõi d·∫°ng ma tr·∫≠n:</h3>
            <div class="options">
                <label><input type="radio" name="q15" value="a"> A) \(\begin{bmatrix} Q & A^T \\ A & 0 \end{bmatrix} \begin{bmatrix} x \\ \nu \end{bmatrix} = \begin{bmatrix} -c \\ b \end{bmatrix}\)</label>
                <label><input type="radio" name="q15" value="b"> B) \(\begin{bmatrix} Q & A \\ A^T & 0 \end{bmatrix} \begin{bmatrix} x \\ \nu \end{bmatrix} = \begin{bmatrix} -c \\ b \end{bmatrix}\)</label>
                <label><input type="radio" name="q15" value="c"> C) \(Qx = -c\)</label>
                <label><input type="radio" name="q15" value="d"> D) \(Ax = b\)</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) $$\begin{bmatrix} Q & A^T \\ A & 0 \end{bmatrix} \begin{bmatrix} x \\ \nu \end{bmatrix} = \begin{bmatrix} -c \\ b \end{bmatrix}$$</strong><br>
                KKT system k·∫øt h·ª£p stationarity $$Qx + c + A^T\nu = 0$$ v√† feasibility $$Ax = b$$.
            </div>
        </div>

        <!-- C√¢u h·ªèi 16: Constraint qualification -->
        <div class="question" id="q16" style="display: none;">
            <h3>C√¢u 16: Constraint qualification c·∫ßn thi·∫øt ƒë·ªÉ:</h3>
            <div class="options">
                <label><input type="radio" name="q16" value="a"> A) ƒê·∫£m b·∫£o KKT conditions sufficient</label>
                <label><input type="radio" name="q16" value="b"> B) ƒê·∫£m b·∫£o KKT conditions necessary</label>
                <label><input type="radio" name="q16" value="c"> C) ƒê·∫£m b·∫£o strong duality</label>
                <label><input type="radio" name="q16" value="d"> D) ƒê·∫£m b·∫£o convexity</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: B) ƒê·∫£m b·∫£o KKT conditions necessary</strong><br>
                Constraint qualification (LICQ, MFCQ, etc.) ƒë·∫£m b·∫£o KKT conditions l√† necessary cho local optimality.
            </div>
        </div>

        <!-- C√¢u h·ªèi 17: Second-order conditions -->
        <div class="question" id="q17" style="display: none;">
            <h3>C√¢u 17: Second-order sufficient condition y√™u c·∫ßu Hessian c·ªßa Lagrangian:</h3>
            <div class="options">
                <label><input type="radio" name="q17" value="a"> A) Positive definite tr√™n to√†n kh√¥ng gian</label>
                <label><input type="radio" name="q17" value="b"> B) Positive definite tr√™n tangent space c·ªßa active constraints</label>
                <label><input type="radio" name="q17" value="c"> C) Negative definite</label>
                <label><input type="radio" name="q17" value="d"> D) Singular</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: B) Positive definite tr√™n tangent space c·ªßa active constraints</strong><br>
                SOSC: Hessian c·ªßa Lagrangian positive definite tr√™n tangent space, ƒë·∫£m b·∫£o local minimum.
            </div>
        </div>

        <!-- C√¢u h·ªèi 18: Penalty method connection -->
        <div class="question" id="q18" style="display: none;">
            <h3>C√¢u 18: M·ªëi li√™n h·ªá gi·ªØa KKT multipliers v√† penalty methods:</h3>
            <div class="options">
                <label><input type="radio" name="q18" value="a"> A) KKT multipliers l√† gi·ªõi h·∫°n c·ªßa penalty parameters</label>
                <label><input type="radio" name="q18" value="b"> B) Penalty parameters l√† gi·ªõi h·∫°n c·ªßa KKT multipliers</label>
                <label><input type="radio" name="q18" value="c"> C) Kh√¥ng c√≥ m·ªëi li√™n h·ªá</label>
                <label><input type="radio" name="q18" value="d"> D) Ch√∫ng lu√¥n b·∫±ng nhau</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) KKT multipliers l√† gi·ªõi h·∫°n c·ªßa penalty parameters</strong><br>
                Khi penalty parameter $$\to \infty$$, nghi·ªám c·ªßa penalized problem h·ªôi t·ª• v√† multipliers h·ªôi t·ª• ƒë·∫øn KKT multipliers.
            </div>
        </div>

        <!-- C√¢u h·ªèi 19: Sensitivity analysis -->
        <div class="question" id="q19" style="display: none;">
            <h3>C√¢u 19: KKT multipliers cung c·∫•p th√¥ng tin v·ªÅ:</h3>
            <div class="options">
                <label><input type="radio" name="q19" value="a"> A) Sensitivity c·ªßa optimal value ƒë·ªëi v·ªõi thay ƒë·ªïi constraints</label>
                <label><input type="radio" name="q19" value="b"> B) T·ªëc ƒë·ªô h·ªôi t·ª• c·ªßa algorithm</label>
                <label><input type="radio" name="q19" value="c"> C) Condition number c·ªßa problem</label>
                <label><input type="radio" name="q19" value="d"> D) S·ªë l∆∞·ª£ng iterations c·∫ßn thi·∫øt</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) Sensitivity c·ªßa optimal value ƒë·ªëi v·ªõi thay ƒë·ªïi constraints</strong><br>
                KKT multipliers l√† shadow prices: cho bi·∫øt optimal value thay ƒë·ªïi bao nhi√™u khi constraint bounds thay ƒë·ªïi.
            </div>
        </div>

        <!-- C√¢u h·ªèi 20: Practical applications -->
        <div class="question" id="q20" style="display: none;">
            <h3>C√¢u 20: KKT conditions ƒë∆∞·ª£c ·ª©ng d·ª•ng trong:</h3>
            <div class="options">
                <label><input type="radio" name="q20" value="a"> A) Machine learning (SVM, neural networks)</label>
                <label><input type="radio" name="q20" value="b"> B) Signal processing (water-filling, beamforming)</label>
                <label><input type="radio" name="q20" value="c"> C) Economics (utility maximization, portfolio optimization)</label>
                <label><input type="radio" name="q20" value="d"> D) T·∫•t c·∫£ c√°c lƒ©nh v·ª±c tr√™n</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: D) T·∫•t c·∫£ c√°c lƒ©nh v·ª±c tr√™n</strong><br>
                KKT conditions l√† c√¥ng c·ª• fundamental trong constrained optimization v·ªõi ·ª©ng d·ª•ng r·ªông r√£i trong ML, signal processing, economics v√† nhi·ªÅu lƒ©nh v·ª±c kh√°c.
            </div>
        </div>
        <!-- C√¢u h·ªèi 21: Th·ª±c h√†nh -->
        <div class="question" id="q21" style="display: none;">
            <h3>C√¢u 21: ƒêi·ªÅu ki·ªán KKT bao g·ªìm:</h3>
            <div class="options">
                <label><input type="radio" name="q21" value="a"> A) Stationarity, primal feasibility, dual feasibility, complementary slackness</label>
                <label><input type="radio" name="q21" value="b"> B) Ch·ªâ stationarity</label>
                <label><input type="radio" name="q21" value="c"> C) Ch·ªâ feasibility</label>
                <label><input type="radio" name="q21" value="d"> D) Ch·ªâ complementary slackness</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) Stationarity, primal feasibility, dual feasibility, complementary slackness</strong><br>
                KKT g·ªìm 4 ƒëi·ªÅu ki·ªán: $$\nabla f + \sum \lambda_i \nabla g_i + \sum \nu_j \nabla h_j = 0$$, $$g_i(x) \leq 0$$, $$\lambda_i \geq 0$$, $$\lambda_i g_i(x) = 0$$.
            </div>
        </div>

        <!-- C√¢u h·ªèi 22: Th·ª±c h√†nh -->
        <div class="question" id="q22" style="display: none;">
            <h3>C√¢u 22: ƒêi·ªÅu ki·ªán complementary slackness c√≥ nghƒ©a:</h3>
            <div class="options">
                <label><input type="radio" name="q22" value="a"> A) $$\lambda_i g_i(x) = 0$$ cho m·ªçi $$i$$</label>
                <label><input type="radio" name="q22" value="b"> B) $$\lambda_i + g_i(x) = 0$$</label>
                <label><input type="radio" name="q22" value="c"> C) $$\lambda_i = g_i(x)$$</label>
                <label><input type="radio" name="q22" value="d"> D) $$\lambda_i \cdot g_i(x) = 1$$</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) $$\lambda_i g_i(x) = 0$$ cho m·ªçi $$i$$</strong><br>
                Complementary slackness: ho·∫∑c $$\lambda_i = 0$$ ho·∫∑c $$g_i(x) = 0$$ (r√†ng bu·ªôc t√≠ch c·ª±c).
            </div>
        </div>

        <!-- C√¢u h·ªèi 23: Th·ª±c h√†nh -->
        <div class="question" id="q23" style="display: none;">
            <h3>C√¢u 23: Cho b√†i to√°n $$\min x^2$$ v·ªõi $$x \geq 1$$. ƒêi·ªÅu ki·ªán KKT t·∫°i nghi·ªám $$x^* = 1$$:</h3>
            <div class="options">
                <label><input type="radio" name="q23" value="a"> A) $$2x - \lambda = 0, \lambda \geq 0, \lambda(1-x) = 0$$</label>
                <label><input type="radio" name="q23" value="b"> B) $$2x = 0$$</label>
                <label><input type="radio" name="q23" value="c"> C) $$x = 1$$</label>
                <label><input type="radio" name="q23" value="d"> D) $$\lambda = 1$$</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) $$2x - \lambda = 0, \lambda \geq 0, \lambda(1-x) = 0$$</strong><br>
                Stationarity: $$2x - \lambda = 0$$. T·∫°i $$x^* = 1$$: $$\lambda = 2$$, th·ªèa m√£n complementary slackness.
            </div>
        </div>

        <!-- C√¢u h·ªèi 24: Th·ª±c h√†nh -->
        <div class="question" id="q24" style="display: none;">
            <h3>C√¢u 24: LICQ (Linear Independence Constraint Qualification) y√™u c·∫ßu:</h3>
            <div class="options">
                <label><input type="radio" name="q24" value="a"> A) Gradient c·ªßa c√°c r√†ng bu·ªôc t√≠ch c·ª±c ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh</label>
                <label><input type="radio" name="q24" value="b"> B) T·∫•t c·∫£ r√†ng bu·ªôc tuy·∫øn t√≠nh</label>
                <label><input type="radio" name="q24" value="c"> C) H√†m m·ª•c ti√™u tuy·∫øn t√≠nh</label>
                <label><input type="radio" name="q24" value="d"> D) Ma tr·∫≠n Hessian kh·∫£ ngh·ªãch</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) Gradient c·ªßa c√°c r√†ng bu·ªôc t√≠ch c·ª±c ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh</strong><br>
                LICQ: c√°c gradient $$\nabla g_i(x^*), \nabla h_j(x^*)$$ c·ªßa r√†ng bu·ªôc t√≠ch c·ª±c ph·∫£i ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh.
            </div>
        </div>

        <!-- C√¢u h·ªèi 25: Th·ª±c h√†nh -->
        <div class="question" id="q25" style="display: none;">
            <h3>C√¢u 25: Trong b√†i to√°n QP v·ªõi KKT, ma tr·∫≠n h·ªá ph∆∞∆°ng tr√¨nh c√≥ d·∫°ng:</h3>
            <div class="options">
                <label><input type="radio" name="q25" value="a"> A) $$\begin{pmatrix} H & A^T \\ A & 0 \end{pmatrix}$$</label>
                <label><input type="radio" name="q25" value="b"> B) $$\begin{pmatrix} H & 0 \\ 0 & A \end{pmatrix}$$</label>
                <label><input type="radio" name="q25" value="c"> C) $$H + A^T A$$</label>
                <label><input type="radio" name="q25" value="d"> D) $$H - A^T A$$</label>
            </div>
            <div class="explanation" style="display: none;">
                <strong>ƒê√°p √°n ƒë√∫ng: A) $$\begin{pmatrix} H & A^T \\ A & 0 \end{pmatrix}$$</strong><br>
                H·ªá KKT cho QP c√≥ d·∫°ng ma tr·∫≠n kh·ªëi v·ªõi Hessian $$H$$ v√† ma tr·∫≠n r√†ng bu·ªôc $$A$$.
            </div>
        </div>

    </div>

    <div class="quiz-controls">
        <button onclick="previousQuestion()" id="prev-btn" disabled>‚Üê C√¢u tr∆∞·ªõc</button>
        <button onclick="nextQuestion()" id="next-btn">C√¢u ti·∫øp ‚Üí</button>
        <button onclick="submitQuiz()" id="submit-btn" style="display: none;">N·ªôp b√†i</button>
        <button onclick="resetQuiz()" id="reset-btn" style="display: none;">L√†m l·∫°i</button>
    </div>

    <div id="final-result" style="display: none;" class="final-score">
        <h2>üéâ Ho√†n th√†nh Quiz!</h2>
        <p>ƒêi·ªÉm s·ªë c·ªßa b·∫°n: <span id="final-score-text"></span></p>
        <p id="performance-message"></p>
    </div>
</div>

<script>
let currentQuestion = 1;
const totalQuestions = 25;
let userAnswers = {};
let quizSubmitted = false;

// ƒê√°p √°n ƒë√∫ng
const correctAnswers = {
    q1: 'b', q2: 'b', q3: 'd', q4: 'a', q5: 'b',
    q6: 'b', q7: 'a', q8: 'a', q9: 'a', q10: 'b',
    q11: 'b', q12: 'b', q13: 'a', q14: 'a', q15: 'a',
    q16: 'b', q17: 'b', q18: 'a', q19: 'a', q20: 'd'
,
    q21: 'a', q22: 'a', q23: 'a', q24: 'a', q25: 'a'};

function showQuestion(n) {
    // ·∫®n t·∫•t c·∫£ c√¢u h·ªèi
    for (let i = 1; i <= totalQuestions; i++) {
        document.getElementById(`q${i}`).style.display = 'none';
    }
    
    // Hi·ªÉn th·ªã c√¢u h·ªèi hi·ªán t·∫°i
    document.getElementById(`q${n}`).style.display = 'block';
    
    // C·∫≠p nh·∫≠t progress bar
    const progress = (n / totalQuestions) * 100;
    document.getElementById('progress-fill').style.width = progress + '%';
    
    // C·∫≠p nh·∫≠t s·ªë c√¢u h·ªèi
    document.getElementById('current-q').textContent = n;
    
    // C·∫≠p nh·∫≠t n√∫t ƒëi·ªÅu h∆∞·ªõng
    document.getElementById('prev-btn').disabled = (n === 1);
    document.getElementById('next-btn').style.display = (n === totalQuestions) ? 'none' : 'inline-block';
    document.getElementById('submit-btn').style.display = (n === totalQuestions) ? 'inline-block' : 'none';
    
    currentQuestion = n;
}

function nextQuestion() {
    if (currentQuestion < totalQuestions) {
        showQuestion(currentQuestion + 1);
    }
}

function previousQuestion() {
    if (currentQuestion > 1) {
        showQuestion(currentQuestion - 1);
    }
}

function saveAnswer(questionId, answer) {
    userAnswers[questionId] = answer;
    
    // Highlight selected option
    const questionDiv = document.getElementById(questionId);
    const labels = questionDiv.querySelectorAll('.options label');
    labels.forEach(label => {
        label.classList.remove('selected');
        const input = label.querySelector('input[type="radio"]');
        if (input.checked) {
            label.classList.add('selected');
        }
    });
}

function calculateScore() {
    let correct = 0;
    for (let q in correctAnswers) {
        if (userAnswers[q] === correctAnswers[q]) {
            correct++;
        }
    }
    return correct;
}

function submitQuiz() {
    quizSubmitted = true;
    const score = calculateScore();
    const percentage = Math.round((score / totalQuestions) * 100);
    
    // Hi·ªÉn th·ªã t·∫•t c·∫£ gi·∫£i th√≠ch
    for (let i = 1; i <= totalQuestions; i++) {
        const explanation = document.querySelector(`#q${i} .explanation`);
        explanation.style.display = 'block';
        
        // Highlight ƒë√°p √°n ƒë√∫ng v√† sai
        const questionDiv = document.getElementById(`q${i}`);
        const labels = questionDiv.querySelectorAll('.options label');
        labels.forEach(label => {
            const input = label.querySelector('input[type="radio"]');
            const value = input.value;
            
            if (value === correctAnswers[`q${i}`]) {
                label.style.backgroundColor = '#d4edda';
                label.style.border = '2px solid #28a745';
            } else if (value === userAnswers[`q${i}`] && value !== correctAnswers[`q${i}`]) {
                label.style.backgroundColor = '#f8d7da';
                label.style.border = '2px solid #dc3545';
            }
        });
    }
    
    // Hi·ªÉn th·ªã k·∫øt qu·∫£ cu·ªëi
    document.getElementById('final-result').style.display = 'block';
    document.getElementById('final-score-text').textContent = `${score}/${totalQuestions} (${percentage}%)`;
    
    let message = '';
    if (percentage >= 90) {
        message = 'üåü Xu·∫•t s·∫Øc! B·∫°n ƒë√£ th√†nh th·∫°o KKT conditions v√† applications!';
    } else if (percentage >= 80) {
        message = 'üëç R·∫•t t·ªët! B·∫°n hi·ªÉu t·ªët v·ªÅ optimality conditions v√† practical examples.';
    } else if (percentage >= 70) {
        message = 'üìö Kh√° ·ªïn! H√£y xem l·∫°i complementary slackness v√† constraint qualification.';
    } else if (percentage >= 60) {
        message = 'üí™ C·∫ßn c·∫£i thi·ªán! √în l·∫°i KKT conditions v√† stationarity.';
    } else {
        message = 'üìñ H√£y h·ªçc l·∫°i t·ª´ ƒë·∫ßu v·ªÅ KKT theory nh√©!';
    }
    
    document.getElementById('performance-message').textContent = message;
    
    // ·∫®n n√∫t submit, hi·ªán n√∫t reset
    document.getElementById('submit-btn').style.display = 'none';
    document.getElementById('reset-btn').style.display = 'inline-block';
    
    // Cu·ªôn ƒë·∫øn k·∫øt qu·∫£
    document.getElementById('final-result').scrollIntoView({ behavior: 'smooth' });
}

function resetQuiz() {
    // Reset tr·∫°ng th√°i
    currentQuestion = 1;
    userAnswers = {};
    quizSubmitted = false;
    
    // ·∫®n t·∫•t c·∫£ gi·∫£i th√≠ch
    document.querySelectorAll('.explanation').forEach(exp => {
        exp.style.display = 'none';
    });
    
    // Reset style c·ªßa labels
    document.querySelectorAll('.options label').forEach(label => {
        label.style.backgroundColor = '';
        label.style.border = '';
        label.classList.remove('selected');
    });
    
    // Uncheck t·∫•t c·∫£ radio buttons
    document.querySelectorAll('input[type="radio"]').forEach(input => {
        input.checked = false;
    });
    
    document.querySelectorAll('.options label').forEach(label => {
        label.classList.remove('selected');
    });
    
    // Hi·ªÉn th·ªã c√¢u h·ªèi ƒë·∫ßu ti√™n
    showQuestion(1);
    
    // Cu·ªôn l√™n ƒë·∫ßu
    document.getElementById('quiz-header').scrollIntoView({ behavior: 'smooth' });
    
    // ·∫®n k·∫øt qu·∫£ cu·ªëi v√† reset button
    document.getElementById('final-result').style.display = 'none';
    document.getElementById('reset-btn').style.display = 'none';
}

// Kh·ªüi t·∫°o b√†i t·∫≠p khi trang ƒë∆∞·ª£c t·∫£i
document.addEventListener('DOMContentLoaded', function() {
    showQuestion(1);
    
    // Th√™m event listener cho t·∫•t c·∫£ radio button
    document.querySelectorAll('input[type="radio"]').forEach(input => {
        input.addEventListener('change', function() {
            const questionId = this.name;
            const answer = this.value;
            saveAnswer(questionId, answer);
        });
    });
    
    // Render MathJax sau khi DOM ƒë∆∞·ª£c t·∫£i
    if (window.MathJax) {
        MathJax.typesetPromise();
    }
});

// X·ª≠ l√Ω ph√≠m t·∫Øt
document.addEventListener('keydown', function(event) {
    if (quizSubmitted) return;
    
    switch(event.key) {
        case 'ArrowLeft':
            if (currentQuestion > 1) previousQuestion();
            break;
        case 'ArrowRight':
            if (currentQuestion < totalQuestions) nextQuestion();
            break;
        case 'Enter':
            if (currentQuestion === totalQuestions) submitQuiz();
            break;
    }
});
</script>
