---
layout: post
title: 12-04 VÃ­ dá»¥ MÃ¡y Vector Há»— Trá»£ (Support Vector Machines - SVM)
chapter: '12'
order: 5
owner: Wontak Ryu
categories:
- chapter12
lang: vi
lesson_type: required
---

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
});
</script>

# MÃ¡y Vector Há»— Trá»£ (Support Vector Machines - SVM)

## 1. Giá»›i thiá»‡u

**Support Vector Machine (SVM)** lÃ  má»™t thuáº­t toÃ¡n phÃ¢n loáº¡i máº¡nh máº½, tÃ¬m siÃªu pháº³ng tá»‘i Æ°u Ä‘á»ƒ phÃ¢n tÃ¡ch cÃ¡c lá»›p dá»¯ liá»‡u vá»›i **margin lá»›n nháº¥t**.

### 1.1. Khoáº£ng cÃ¡ch tá»« má»™t Ä‘iá»ƒm tá»›i siÃªu máº·t pháº³ng

TrÆ°á»›c khi Ä‘i vÃ o chi tiáº¿t, hÃ£y nháº¯c láº¡i kiáº¿n thá»©c vá» hÃ¬nh há»c giáº£i tÃ­ch:

**KhÃ´ng gian 2 chiá»u:**  
Khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm $$(x_0, y_0)$$ tá»›i Ä‘Æ°á»ng tháº³ng $$w_1x + w_2y + b = 0$$ lÃ :
$$
\frac{\lvert w_1x_0 + w_2y_0 + b\rvert}{\sqrt{w_1^2 + w_2^2}}
$$

**KhÃ´ng gian 3 chiá»u:**  
Khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm $$(x_0, y_0, z_0)$$ tá»›i máº·t pháº³ng $$w_1x + w_2y + w_3z + b = 0$$ lÃ :
$$
\frac{\lvert w_1x_0 + w_2y_0 + w_3z_0 + b\rvert}{\sqrt{w_1^2 + w_2^2 + w_3^2}}
$$

**Tá»•ng quÃ¡t - KhÃ´ng gian nhiá»u chiá»u:**  
Khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm (vector) $$\mathbf{x}_0$$ tá»›i **siÃªu máº·t pháº³ng** $$\mathbf{w}^T\mathbf{x} + b = 0$$ lÃ :
$$
\frac{\lvert\mathbf{w}^T\mathbf{x}_0 + b\rvert}{\|\mathbf{w}\|_2}
$$

**LÆ°u Ã½ quan trá»ng:**  
- Náº¿u bá» dáº¥u giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i, ta xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c Ä‘iá»ƒm náº±m vá» phÃ­a nÃ o cá»§a siÃªu pháº³ng
- Biá»ƒu thá»©c dÆ°Æ¡ng: Ä‘iá»ƒm á»Ÿ **phÃ­a dÆ°Æ¡ng** cá»§a siÃªu pháº³ng
- Biá»ƒu thá»©c Ã¢m: Ä‘iá»ƒm á»Ÿ **phÃ­a Ã¢m** cá»§a siÃªu pháº³ng
- Biá»ƒu thá»©c báº±ng 0: Ä‘iá»ƒm náº±m trÃªn siÃªu pháº³ng

### 1.2. Ã tÆ°á»Ÿng cá»‘t lÃµi

- **SiÃªu pháº³ng**: $$\beta^T x + \beta_0 = 0$$ phÃ¢n tÃ¡ch hai lá»›p
- **Margin**: Khoáº£ng cÃ¡ch tá»« siÃªu pháº³ng Ä‘áº¿n Ä‘iá»ƒm gáº§n nháº¥t = $$\frac{2}{\|\beta\|}$$
- **Má»¥c tiÃªu**: Maximize margin $$\Leftrightarrow$$ Minimize $$\|\beta\|$$

### 1.3. Minh há»a trá»±c quan: Khoáº£ng cÃ¡ch vÃ  phÃ¢n loáº¡i

<div id="distance-demo" style="margin: 20px 0;">
    <canvas id="distanceCanvas" width="600" height="400" style="border: 1px solid #ccc; display: block; margin: 0 auto;"></canvas>
    <div style="text-align: center; margin-top: 15px;">
        <p style="font-size: 14px; color: #666;">
            <strong>HÆ°á»›ng dáº«n:</strong> Di chuyá»ƒn chuá»™t trÃªn canvas Ä‘á»ƒ xem khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm Ä‘áº¿n Ä‘Æ°á»ng tháº³ng
        </p>
        <p id="distanceInfo" style="font-size: 16px; font-weight: bold; color: #333;">
            Khoáº£ng cÃ¡ch: 0
        </p>
    </div>
</div>

<script>
(function() {
    const canvas = document.getElementById('distanceCanvas');
    if (!canvas) return;
    
    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;
    
    // Tham sá»‘ Ä‘Æ°á»ng tháº³ng: w1*x + w2*y + b = 0
    // Chá»n Ä‘Æ°á»ng tháº³ng Ä‘i qua giá»¯a canvas vá»›i gÃ³c nghiÃªng
    const w1 = 1;
    const w2 = 0.5;
    const b = -200;
    const norm = Math.sqrt(w1*w1 + w2*w2);
    
    let mouseX = width / 2;
    let mouseY = height / 2;
    
    function draw() {
        // Clear canvas
        ctx.clearRect(0, 0, width, height);
        
        // Váº½ lÆ°á»›i ná»n
        ctx.strokeStyle = '#f0f0f0';
        ctx.lineWidth = 1;
        for (let x = 0; x < width; x += 50) {
            ctx.beginPath();
            ctx.moveTo(x, 0);
            ctx.lineTo(x, height);
            ctx.stroke();
        }
        for (let y = 0; y < height; y += 50) {
            ctx.beginPath();
            ctx.moveTo(0, y);
            ctx.lineTo(width, y);
            ctx.stroke();
        }
        
        // Váº½ Ä‘Æ°á»ng tháº³ng w1*x + w2*y + b = 0
        ctx.strokeStyle = '#2c3e50';
        ctx.lineWidth = 3;
        ctx.beginPath();
        
        // TÃ­nh y cho x = 0 vÃ  x = width
        const y0 = -(w1 * 0 + b) / w2;
        const y1 = -(w1 * width + b) / w2;
        
        ctx.moveTo(0, y0);
        ctx.lineTo(width, y1);
        ctx.stroke();
        
        // Váº½ label cho Ä‘Æ°á»ng tháº³ng
        ctx.fillStyle = '#2c3e50';
        ctx.font = '14px Arial';
        ctx.fillText('wâ‚x + wâ‚‚y + b = 0', width - 150, y1 + 20);
        
        // TÃ­nh khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm chuá»™t Ä‘áº¿n Ä‘Æ°á»ng tháº³ng
        const distance = Math.abs(w1 * mouseX + w2 * mouseY + b) / norm;
        const signedDist = (w1 * mouseX + w2 * mouseY + b) / norm;
        
        // TÃ¬m Ä‘iá»ƒm chiáº¿u vuÃ´ng gÃ³c
        const t = -(w1 * mouseX + w2 * mouseY + b) / (w1*w1 + w2*w2);
        const projX = mouseX + t * w1;
        const projY = mouseY + t * w2;
        
        // Váº½ Ä‘Æ°á»ng vuÃ´ng gÃ³c
        ctx.strokeStyle = '#e74c3c';
        ctx.lineWidth = 2;
        ctx.setLineDash([5, 5]);
        ctx.beginPath();
        ctx.moveTo(mouseX, mouseY);
        ctx.lineTo(projX, projY);
        ctx.stroke();
        ctx.setLineDash([]);
        
        // Váº½ Ä‘iá»ƒm chuá»™t
        ctx.fillStyle = signedDist > 0 ? '#3498db' : '#e74c3c';
        ctx.beginPath();
        ctx.arc(mouseX, mouseY, 8, 0, 2 * Math.PI);
        ctx.fill();
        
        // Váº½ Ä‘iá»ƒm chiáº¿u
        ctx.fillStyle = '#95a5a6';
        ctx.beginPath();
        ctx.arc(projX, projY, 5, 0, 2 * Math.PI);
        ctx.fill();
        
        // Hiá»ƒn thá»‹ khoáº£ng cÃ¡ch
        const distInfo = document.getElementById('distanceInfo');
        if (distInfo) {
            const side = signedDist > 0 ? '(PhÃ­a dÆ°Æ¡ng)' : '(PhÃ­a Ã¢m)';
            distInfo.innerHTML = `Khoáº£ng cÃ¡ch: <span style="color: ${signedDist > 0 ? '#3498db' : '#e74c3c'}">${distance.toFixed(2)}</span> ${side}`;
        }
        
        // Váº½ text thÃ´ng tin
        ctx.fillStyle = '#34495e';
        ctx.font = '12px Arial';
        ctx.fillText(`Äiá»ƒm: (${mouseX.toFixed(0)}, ${mouseY.toFixed(0)})`, mouseX + 15, mouseY - 15);
    }
    
    // Event listeners
    canvas.addEventListener('mousemove', function(e) {
        const rect = canvas.getBoundingClientRect();
        mouseX = e.clientX - rect.left;
        mouseY = e.clientY - rect.top;
        draw();
    });
    
    // Initial draw
    draw();
})();
</script>

---

## 2. Nháº¯c láº¡i bÃ i toÃ¡n phÃ¢n chia hai classes

Giáº£ sá»­ ráº±ng cÃ³ hai class khÃ¡c nhau Ä‘Æ°á»£c mÃ´ táº£ bá»Ÿi cÃ¡c Ä‘iá»ƒm trong khÃ´ng gian nhiá»u chiá»u, hai classes nÃ y **linearly separable**, tá»©c tá»“n táº¡i má»™t siÃªu pháº³ng phÃ¢n chia chÃ­nh xÃ¡c hai classes Ä‘Ã³. 

**Má»¥c tiÃªu**: TÃ¬m má»™t siÃªu máº·t pháº³ng phÃ¢n chia hai classes, tá»©c táº¥t cáº£ cÃ¡c Ä‘iá»ƒm thuá»™c má»™t class náº±m vá» cÃ¹ng má»™t phÃ­a cá»§a siÃªu máº·t pháº³ng Ä‘Ã³ vÃ  ngÆ°á»£c phÃ­a vá»›i toÃ n bá»™ cÃ¡c Ä‘iá»ƒm thuá»™c class cÃ²n láº¡i.

ChÃºng ta cÃ³ **vÃ´ sá»‘ nghiá»‡m** nhÆ° minh há»a dÆ°á»›i Ä‘Ã¢y:

<figure class="image" style="align: center;">
<p align="center">
 <img src="https://machinelearningcoban.com/assets/19_svm/svm1.png" alt="" width="60%" height="60%">
 <figcaption style="text-align: center;">$$ \text{[HÃ¬nh 2] CÃ¡c máº·t phÃ¢n cÃ¡ch kháº£ dÄ© cho hai classes linearly separable}$$ </figcaption>
</p>
</figure>

**CÃ¢u há»i Ä‘áº·t ra**: Trong vÃ´ sá»‘ cÃ¡c máº·t phÃ¢n chia Ä‘Ã³, **Ä‘Ã¢u lÃ  máº·t phÃ¢n chia tá»‘t nháº¥t** theo má»™t tiÃªu chuáº©n nÃ o Ä‘Ã³? 

Trong hÃ¬nh minh há»a phÃ­a trÃªn, cÃ³ hai Ä‘Æ°á»ng tháº³ng khÃ¡ lá»‡ch vá» phÃ­a class hÃ¬nh trÃ²n Ä‘á», trong khi Ä‘Æ°á»ng tháº³ng cÃ²n láº¡i gáº§n nhÆ° náº±m á»Ÿ giá»¯a hai classes. Ta cáº§n má»™t tiÃªu chuáº©n khÃ¡ch quan Ä‘á»ƒ chá»n ra Ä‘Æ°á»ng phÃ¢n chia tá»‘i Æ°u.

### TiÃªu chuáº©n: Maximum Margin

Trong vÃ´ sá»‘ cÃ¡c máº·t phÃ¢n cÃ¡ch kháº£ dÄ©, chÃºng ta cáº§n má»™t tiÃªu chuáº©n Ä‘á»ƒ chá»n ra máº·t phÃ¢n cÃ¡ch **tá»‘t nháº¥t**.

<figure class="image" style="align: center;">
<p align="center">
 <img src="https://machinelearningcoban.com/assets/19_svm/svm2.png" alt="" width="70%" height="70%">
 <figcaption style="text-align: center;">$$ \text{[HÃ¬nh 3] So sÃ¡nh cÃ¡c máº·t phÃ¢n cÃ¡ch vá»›i margin khÃ¡c nhau}$$ </figcaption>
</p>
</figure>

**Äá»‹nh nghÄ©a Margin**: Khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm gáº§n nháº¥t cá»§a má»—i class Ä‘áº¿n máº·t phÃ¢n cÃ¡ch Ä‘Æ°á»£c gá»i lÃ  **margin** (lá»).

**TiÃªu chuáº©n tá»‘i Æ°u**: Máº·t phÃ¢n cÃ¡ch tá»‘t nháº¥t thá»a mÃ£n hai Ä‘iá»u kiá»‡n:
1. **Äá»‘i xá»©ng**: Margin tá»« máº·t phÃ¢n cÃ¡ch Ä‘áº¿n má»—i class pháº£i **báº±ng nhau**
2. **Tá»‘i Ä‘a**: Margin Ä‘Ã³ pháº£i lÃ  **lá»›n nháº¥t** cÃ³ thá»ƒ

**Ã nghÄ©a**: 
- Margin lá»›n â†’ sá»± phÃ¢n chia giá»¯a hai classes **ráº¡ch rÃ²i** hÆ¡n
- TÄƒng kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a (generalization) cho dá»¯ liá»‡u má»›i
- Giáº£m Ä‘á»™ nháº¡y cáº£m vá»›i nhiá»…u (noise) trong dá»¯ liá»‡u

**Káº¿t luáº­n**: BÃ i toÃ¡n SVM chÃ­nh lÃ  bÃ i toÃ¡n tÃ¬m máº·t phÃ¢n cÃ¡ch cÃ³ **margin lá»›n nháº¥t**. ÄÃ¢y lÃ  lÃ½ do SVM cÃ²n Ä‘Æ°á»£c gá»i lÃ  **Maximum Margin Classifier**.

---

## 3. XÃ¢y dá»±ng bÃ i toÃ¡n tá»‘i Æ°u cho SVM

### 3.1. Thiáº¿t láº­p bÃ i toÃ¡n

**Giáº£ sá»­**: CÃ¡c cáº·p dá»¯ liá»‡u cá»§a training set lÃ  $$(x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N)$$ vá»›i:
- Vector $$x_i \in \mathbb{R}^d$$: Ä‘áº§u vÃ o cá»§a má»™t Ä‘iá»ƒm dá»¯ liá»‡u
- $$y_i \in \{-1, +1\}$$: nhÃ£n cá»§a Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Ã³
- $$d$$: sá»‘ chiá»u cá»§a dá»¯ liá»‡u
- $$N$$: sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u

**LÆ°u Ã½**: Äá»ƒ dá»… hÃ¬nh dung, chÃºng ta xÃ©t trÆ°á»ng há»£p khÃ´ng gian hai chiá»u. CÃ¡c phÃ©p toÃ¡n hoÃ n toÃ n cÃ³ thá»ƒ Ä‘Æ°á»£c tá»•ng quÃ¡t lÃªn khÃ´ng gian nhiá»u chiá»u.

<figure class="image" style="align: center;">
<p align="center">
 <img src="https://machinelearningcoban.com/assets/19_svm/svm6.png" alt="" width="70%" height="70%">
 <figcaption style="text-align: center;">$$ \text{[HÃ¬nh 4] PhÃ¢n tÃ­ch bÃ i toÃ¡n SVM}$$ </figcaption>
</p>
</figure>

**Giáº£ sá»­**:
- CÃ¡c Ä‘iá»ƒm vuÃ´ng xanh thuá»™c class +1
- CÃ¡c Ä‘iá»ƒm trÃ²n Ä‘á» thuá»™c class -1
- Máº·t $$w^T x + b = w_1 x_1 + w_2 x_2 + b = 0$$ lÃ  máº·t phÃ¢n chia
- Class +1 náº±m vá» **phÃ­a dÆ°Æ¡ng**, class -1 náº±m vá» **phÃ­a Ã¢m**

### 3.2. CÃ´ng thá»©c khoáº£ng cÃ¡ch

**Quan sÃ¡t quan trá»ng**: Vá»›i cáº·p dá»¯ liá»‡u $$(x_n, y_n)$$ báº¥t ká»³, khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm Ä‘Ã³ tá»›i máº·t phÃ¢n chia lÃ :

$$
\frac{y_n(w^T x_n + b)}{\|w\|_2}
$$

**Giáº£i thÃ­ch**: Äiá»u nÃ y dá»… nháº­n tháº¥y vÃ¬ theo giáº£ sá»­, $$y_n$$ luÃ´n cÃ¹ng dáº¥u vá»›i phÃ­a cá»§a $$x_n$$. Tá»« Ä‘Ã³ suy ra $$y_n$$ cÃ¹ng dáº¥u vá»›i $$(w^T x_n + b)$$, vÃ  tá»­ sá»‘ luÃ´n lÃ  má»™t sá»‘ khÃ´ng Ã¢m.

### 3.3. Äá»‹nh nghÄ©a Margin

Vá»›i máº·t phÃ¢n chia nhÆ° trÃªn, **margin** Ä‘Æ°á»£c tÃ­nh lÃ  khoáº£ng cÃ¡ch gáº§n nháº¥t tá»« má»™t Ä‘iá»ƒm tá»›i máº·t Ä‘Ã³ (báº¥t ká»ƒ Ä‘iá»ƒm nÃ o trong hai classes):

$$
\text{margin} = \min_n \frac{y_n(w^T x_n + b)}{\|w\|_2}
$$

### 3.4. BÃ i toÃ¡n tá»‘i Æ°u ban Ä‘áº§u

BÃ i toÃ¡n tá»‘i Æ°u trong SVM chÃ­nh lÃ  bÃ i toÃ¡n tÃ¬m $$w$$ vÃ  $$b$$ sao cho margin nÃ y Ä‘áº¡t giÃ¡ trá»‹ **lá»›n nháº¥t**:

$$
\begin{align}
(w, b) &= \arg\max_{w,b} \left\{ \min_n \frac{y_n(w^T x_n + b)}{\|w\|_2} \right\} \\
&= \arg\max_{w,b} \left\{ \frac{1}{\|w\|_2} \min_n y_n(w^T x_n + b) \right\} \qquad (1)
\end{align}
$$

**Váº¥n Ä‘á»**: Viá»‡c giáº£i trá»±c tiáº¿p bÃ i toÃ¡n nÃ y sáº½ ráº¥t phá»©c táº¡p.

### 3.5. Biáº¿n Ä‘á»•i vá» bÃ i toÃ¡n Ä‘Æ¡n giáº£n

**Nháº­n xÃ©t quan trá»ng**: Náº¿u ta thay vector há»‡ sá»‘ $$w$$ bá»Ÿi $$kw$$ vÃ  $$b$$ bá»Ÿi $$kb$$ trong Ä‘Ã³ $$k$$ lÃ  má»™t háº±ng sá»‘ dÆ°Æ¡ng thÃ¬:
- Máº·t phÃ¢n chia **khÃ´ng thay Ä‘á»•i**
- Khoáº£ng cÃ¡ch tá»« tá»«ng Ä‘iá»ƒm Ä‘áº¿n máº·t phÃ¢n chia **khÃ´ng Ä‘á»•i**
- Margin **khÃ´ng Ä‘á»•i**

**Chuáº©n hÃ³a**: Dá»±a trÃªn tÃ­nh cháº¥t nÃ y, ta cÃ³ thá»ƒ giáº£ sá»­:

$$
y_n(w^T x_n + b) = 1
$$

vá»›i nhá»¯ng Ä‘iá»ƒm náº±m **gáº§n máº·t phÃ¢n chia nháº¥t** (cÃ¡c Ä‘iá»ƒm support vectors).

<figure class="image" style="align: center;">
<p align="center">
 <img src="https://machinelearningcoban.com/assets/19_svm/svm3.png" alt="" width="60%" height="60%">
 <figcaption style="text-align: center;">$$ \text{[HÃ¬nh 5] CÃ¡c Ä‘iá»ƒm gáº§n máº·t phÃ¢n cÃ¡ch nháº¥t Ä‘Æ°á»£c khoanh trÃ²n}$$ </figcaption>
</p>
</figure>

**Há»‡ quáº£**: Vá»›i má»i $$n$$, ta cÃ³:

$$
y_n(w^T x_n + b) \geq 1
$$

### 3.6. BÃ i toÃ¡n tá»‘i Æ°u cÃ³ rÃ ng buá»™c

Váº­y bÃ i toÃ¡n tá»‘i Æ°u $$(1)$$ cÃ³ thá»ƒ Ä‘Æ°a vá»:

$$
\begin{align}
(w, b) &= \arg\max_{w,b} \frac{1}{\|w\|_2} \\
\text{subject to: } & y_n(w^T x_n + b) \geq 1, \quad \forall n = 1,2,\ldots,N \qquad (2)
\end{align}
$$

### 3.7. BÃ i toÃ¡n tá»‘i Æ°u chuáº©n

Báº±ng biáº¿n Ä‘á»•i Ä‘Æ¡n giáº£n, ta cÃ³ thá»ƒ Ä‘Æ°a bÃ i toÃ¡n vá» dáº¡ng:

$$
\begin{align}
(w, b) &= \arg\min_{w,b} \frac{1}{2}\|w\|_2^2 \\
\text{subject to: } & 1 - y_n(w^T x_n + b) \leq 0, \quad \forall n = 1,2,\ldots,N \qquad (3)
\end{align}
$$

**Giáº£i thÃ­ch cÃ¡c biáº¿n Ä‘á»•i**:
1. Láº¥y **nghá»‹ch Ä‘áº£o** hÃ m má»¥c tiÃªu (max â†’ min)
2. **BÃ¬nh phÆ°Æ¡ng** Ä‘á»ƒ Ä‘Æ°á»£c hÃ m kháº£ vi
3. NhÃ¢n vá»›i $$\frac{1}{2}$$ Ä‘á»ƒ biá»ƒu thá»©c Ä‘áº¡o hÃ m Ä‘áº¹p hÆ¡n
4. Äá»•i dáº¥u rÃ ng buá»™c

### 3.8. TÃ­nh cháº¥t cá»§a bÃ i toÃ¡n

**Quan sÃ¡t quan trá»ng**:

1. **HÃ m má»¥c tiÃªu**: $$\frac{1}{2}\|w\|_2^2$$ lÃ  má»™t hÃ m **lá»“i** (norm bÃ¬nh phÆ°Æ¡ng)

2. **HÃ m rÃ ng buá»™c**: $$1 - y_n(w^T x_n + b)$$ lÃ  hÃ m **tuyáº¿n tÃ­nh** theo $$w$$ vÃ  $$b$$, nÃªn lÃ  hÃ m **lá»“i**

3. **Káº¿t luáº­n**: BÃ i toÃ¡n $$(3)$$ lÃ  má»™t **bÃ i toÃ¡n lá»“i** (convex optimization problem)

4. **HÆ¡n ná»¯a**: ÄÃ¢y lÃ  má»™t **Quadratic Programming (QP)** problem

5. **Strictly convex**: HÃ m má»¥c tiÃªu lÃ  strictly convex vÃ¬ $$\|w\|_2^2 = w^T I w$$ vÃ  $$I$$ lÃ  ma tráº­n Ä‘Æ¡n vá»‹ - má»™t ma tráº­n **xÃ¡c Ä‘á»‹nh dÆ°Æ¡ng**

6. **Nghiá»‡m duy nháº¥t**: Tá»« tÃ­nh strictly convex, suy ra nghiá»‡m cho SVM lÃ  **duy nháº¥t**


### 3.10. XÃ¡c Ä‘á»‹nh class cho Ä‘iá»ƒm má»›i

Sau khi tÃ¬m Ä‘Æ°á»£c máº·t phÃ¢n cÃ¡ch $$w^T x + b = 0$$, class cá»§a báº¥t ká»³ má»™t Ä‘iá»ƒm nÃ o sáº½ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh Ä‘Æ¡n giáº£n báº±ng:

$$
\text{class}(x) = \text{sgn}(w^T x + b)
$$

Trong Ä‘Ã³ hÃ m $$\text{sgn}$$ lÃ  hÃ m xÃ¡c Ä‘á»‹nh dáº¥u:
- Nháº­n giÃ¡ trá»‹ **+1** náº¿u Ä‘á»‘i sá»‘ lÃ  khÃ´ng Ã¢m
- Nháº­n giÃ¡ trá»‹ **-1** náº¿u ngÆ°á»£c láº¡i

---

## 4. Hard-Margin SVM (Dá»¯ liá»‡u tÃ¡ch Ä‘Æ°á»£c)

Khi dá»¯ liá»‡u **tÃ¡ch Ä‘Æ°á»£c tuyáº¿n tÃ­nh**, bÃ i toÃ¡n SVM cÃ³ dáº¡ng:

$$
\begin{align}
&\min_{\beta, \beta_0} &&{\frac{1}{2} \|\beta\|_2^2} \\
&\text{s.t.} && y_i (\beta^T x_i + \beta_0) \geq 1, \quad i = 1, \ldots, n
\end{align}
$$

**Giáº£i thÃ­ch:**
- HÃ m má»¥c tiÃªu: Minimize $$\|\beta\|$$ Ä‘á»ƒ maximize margin
- RÃ ng buá»™c: Má»i Ä‘iá»ƒm pháº£i cÃ¡ch siÃªu pháº³ng Ã­t nháº¥t 1 Ä‘Æ¡n vá»‹ (theo metric)

### 4.1. Minh há»a tÆ°Æ¡ng tÃ¡c: Hard-Margin SVM

<div id="hardmargin-demo" style="margin: 20px 0;">
    <canvas id="hardMarginCanvas" width="700" height="500" style="border: 1px solid #ccc; display: block; margin: 0 auto;"></canvas>
    <div style="text-align: center; margin-top: 15px;">
        <button id="resetData" style="padding: 10px 20px; font-size: 14px; cursor: pointer; background: #3498db; color: white; border: none; border-radius: 5px; margin: 5px;">
            ğŸ”„ Táº¡o dá»¯ liá»‡u má»›i
        </button>
        <button id="addPositive" style="padding: 10px 20px; font-size: 14px; cursor: pointer; background: #e74c3c; color: white; border: none; border-radius: 5px; margin: 5px;">
            â• ThÃªm Ä‘iá»ƒm dÆ°Æ¡ng (+1)
        </button>
        <button id="addNegative" style="padding: 10px 20px; font-size: 14px; cursor: pointer; background: #2ecc71; color: white; border: none; border-radius: 5px; margin: 5px;">
            â• ThÃªm Ä‘iá»ƒm Ã¢m (-1)
        </button>
        <p style="font-size: 14px; color: #666; margin-top: 10px;">
            <strong>HÆ°á»›ng dáº«n:</strong> Click vÃ o canvas Ä‘á»ƒ thÃªm Ä‘iá»ƒm má»›i. ÄÆ°á»ng Ä‘en Ä‘áº­m lÃ  siÃªu pháº³ng phÃ¢n cÃ¡ch, Ä‘Æ°á»ng Ä‘á»©t nÃ©t lÃ  margin boundaries.
        </p>
    </div>
</div>

<script>
(function() {
    const canvas = document.getElementById('hardMarginCanvas');
    if (!canvas) return;
    
    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;
    
    let addMode = 0; // 0: none, 1: positive, -1: negative
    
    // Dá»¯ liá»‡u Ä‘iá»ƒm
    let points = [
        // Class +1 (Ä‘á»)
        {x: 450, y: 150, label: 1},
        {x: 500, y: 100, label: 1},
        {x: 550, y: 200, label: 1},
        {x: 480, y: 250, label: 1},
        {x: 520, y: 180, label: 1},
        // Class -1 (xanh)
        {x: 150, y: 250, label: -1},
        {x: 200, y: 300, label: -1},
        {x: 250, y: 350, label: -1},
        {x: 180, y: 400, label: -1},
        {x: 220, y: 280, label: -1}
    ];
    
    function simpleSVM() {
        // Thuáº­t toÃ¡n Ä‘Æ¡n giáº£n Ä‘á»ƒ tÃ¬m hyperplane
        // TÃ¬m trung Ä‘iá»ƒm giá»¯a 2 classes
        let posPoints = points.filter(p => p.label === 1);
        let negPoints = points.filter(p => p.label === -1);
        
        if (posPoints.length === 0 || negPoints.length === 0) return null;
        
        // TÃ­nh centroid má»—i class
        let posCenter = {
            x: posPoints.reduce((sum, p) => sum + p.x, 0) / posPoints.length,
            y: posPoints.reduce((sum, p) => sum + p.y, 0) / posPoints.length
        };
        
        let negCenter = {
            x: negPoints.reduce((sum, p) => sum + p.x, 0) / negPoints.length,
            y: negPoints.reduce((sum, p) => sum + p.y, 0) / negPoints.length
        };
        
        // Vector káº¿t ná»‘i 2 centroids
        let dx = posCenter.x - negCenter.x;
        let dy = posCenter.y - negCenter.y;
        
        // Hyperplane vuÃ´ng gÃ³c vá»›i vector nÃ y, Ä‘i qua trung Ä‘iá»ƒm
        let midX = (posCenter.x + negCenter.x) / 2;
        let midY = (posCenter.y + negCenter.y) / 2;
        
        // w = (dx, dy), bias tÃ­nh tá»« Ä‘iá»ƒm mid
        let w = {x: dx, y: dy};
        let b = -(w.x * midX + w.y * midY);
        let norm = Math.sqrt(w.x * w.x + w.y * w.y);
        
        // Normalize
        w.x /= norm;
        w.y /= norm;
        b /= norm;
        
        // TÃ¬m margin: khoáº£ng cÃ¡ch gáº§n nháº¥t tá»« Ä‘iá»ƒm Ä‘áº¿n hyperplane
        let minDist = Infinity;
        points.forEach(p => {
            let dist = Math.abs(w.x * p.x + w.y * p.y + b);
            if (dist < minDist) minDist = dist;
        });
        
        // TÃ¬m support vectors
        let supportVectors = points.filter(p => {
            let dist = Math.abs(w.x * p.x + w.y * p.y + b);
            return dist < minDist + 5; // tolerance
        });
        
        return {w, b, margin: minDist, supportVectors};
    }
    
    function draw() {
        // Clear canvas
        ctx.clearRect(0, 0, width, height);
        
        // Background
        ctx.fillStyle = '#fafafa';
        ctx.fillRect(0, 0, width, height);
        
        // TÃ¬m SVM solution
        let svm = simpleSVM();
        
        if (svm) {
            // Váº½ margin boundaries (Ä‘Æ°á»ng Ä‘á»©t nÃ©t)
            ctx.strokeStyle = '#95a5a6';
            ctx.lineWidth = 2;
            ctx.setLineDash([5, 5]);
            
            // Margin boundary 1
            let b1 = svm.b + svm.margin;
            drawLine(svm.w, b1);
            
            // Margin boundary 2
            let b2 = svm.b - svm.margin;
            drawLine(svm.w, b2);
            
            ctx.setLineDash([]);
            
            // Váº½ hyperplane chÃ­nh (Ä‘Æ°á»ng Ä‘áº­m)
            ctx.strokeStyle = '#2c3e50';
            ctx.lineWidth = 3;
            drawLine(svm.w, svm.b);
            
            // Highlight support vectors
            ctx.strokeStyle = '#f39c12';
            ctx.lineWidth = 3;
            svm.supportVectors.forEach(sv => {
                ctx.beginPath();
                ctx.arc(sv.x, sv.y, 15, 0, 2 * Math.PI);
                ctx.stroke();
            });
            
            // Hiá»ƒn thá»‹ thÃ´ng tin
            ctx.fillStyle = '#2c3e50';
            ctx.font = 'bold 16px Arial';
            ctx.fillText(`Margin: ${(svm.margin * 2).toFixed(1)}`, 10, 30);
            ctx.fillText(`Support Vectors: ${svm.supportVectors.length}`, 10, 55);
        }
        
        // Váº½ cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u
        points.forEach(p => {
            ctx.fillStyle = p.label === 1 ? '#e74c3c' : '#2ecc71';
            ctx.beginPath();
            ctx.arc(p.x, p.y, 8, 0, 2 * Math.PI);
            ctx.fill();
            
            // Viá»n
            ctx.strokeStyle = '#34495e';
            ctx.lineWidth = 2;
            ctx.stroke();
        });
        
        // Legend
        ctx.fillStyle = '#e74c3c';
        ctx.beginPath();
        ctx.arc(630, 30, 8, 0, 2 * Math.PI);
        ctx.fill();
        ctx.fillStyle = '#34495e';
        ctx.font = '14px Arial';
        ctx.fillText('Class +1', 645, 35);
        
        ctx.fillStyle = '#2ecc71';
        ctx.beginPath();
        ctx.arc(630, 55, 8, 0, 2 * Math.PI);
        ctx.fill();
        ctx.fillStyle = '#34495e';
        ctx.fillText('Class -1', 645, 60);
        
        // Support vector legend
        ctx.strokeStyle = '#f39c12';
        ctx.lineWidth = 3;
        ctx.beginPath();
        ctx.arc(630, 80, 8, 0, 2 * Math.PI);
        ctx.stroke();
        ctx.fillStyle = '#34495e';
        ctx.fillText('Support Vector', 645, 85);
    }
    
    function drawLine(w, b) {
        // Váº½ Ä‘Æ°á»ng tháº³ng w.x * x + w.y * y + b = 0
        ctx.beginPath();
        
        if (Math.abs(w.y) > 0.01) {
            let y0 = -(w.x * 0 + b) / w.y;
            let y1 = -(w.x * width + b) / w.y;
            ctx.moveTo(0, y0);
            ctx.lineTo(width, y1);
        } else {
            let x = -b / w.x;
            ctx.moveTo(x, 0);
            ctx.lineTo(x, height);
        }
        
        ctx.stroke();
    }
    
    function generateRandomData() {
        points = [];
        // Class +1
        for (let i = 0; i < 5; i++) {
            points.push({
                x: 450 + Math.random() * 150,
                y: 100 + Math.random() * 200,
                label: 1
            });
        }
        // Class -1
        for (let i = 0; i < 5; i++) {
            points.push({
                x: 150 + Math.random() * 150,
                y: 250 + Math.random() * 200,
                label: -1
            });
        }
        draw();
    }
    
    // Event listeners
    canvas.addEventListener('click', function(e) {
        if (addMode !== 0) {
            const rect = canvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const y = e.clientY - rect.top;
            points.push({x, y, label: addMode});
            draw();
            addMode = 0;
            document.getElementById('addPositive').style.opacity = '1';
            document.getElementById('addNegative').style.opacity = '1';
        }
    });
    
    document.getElementById('resetData').addEventListener('click', generateRandomData);
    
    document.getElementById('addPositive').addEventListener('click', function() {
        addMode = 1;
        this.style.opacity = '0.6';
        document.getElementById('addNegative').style.opacity = '1';
    });
    
    document.getElementById('addNegative').addEventListener('click', function() {
        addMode = -1;
        this.style.opacity = '0.6';
        document.getElementById('addPositive').style.opacity = '1';
    });
    
    // Initial draw
    draw();
})();
</script>

---

## 5. Soft-Margin SVM (Dá»¯ liá»‡u khÃ´ng tÃ¡ch Ä‘Æ°á»£c)

Trong thá»±c táº¿, dá»¯ liá»‡u thÆ°á»ng **khÃ´ng tÃ¡ch Ä‘Æ°á»£c hoÃ n toÃ n**. Giá»›i thiá»‡u **slack variables** $$\xi_i \geq 0$$:

$$
\begin{align}
&\min_{\beta, \beta_0, \xi} &&{\frac{1}{2} \|\beta\|_2^2 + C\sum_{i=1}^n \xi_i} \\
&\text{s.t.} &&{\xi_i \geq 0, \quad i = 1, \ldots, n}\\
& && y_i (\beta^T x_i + \beta_0) \geq 1 - \xi_i, \quad i = 1, \ldots, n
\end{align}
$$

Vá»›i $$y \in \{-1, 1\}^n$$ vÃ  $$X \in \mathbb{R}^{n \times p}$$.

### Giáº£i thÃ­ch cÃ¡c thÃ nh pháº§n

**1) Slack variable $$\xi_i$$:**
- $$\xi_i = 0$$: Äiá»ƒm phÃ¢n loáº¡i Ä‘Ãºng, ngoÃ i margin
- $$0 < \xi_i < 1$$: Äiá»ƒm trong margin zone, váº«n Ä‘Ãºng phÃ­a
- $$\xi_i = 1$$: Äiá»ƒm náº±m trÃªn siÃªu pháº³ng
- $$\xi_i > 1$$: Äiá»ƒm bá»‹ phÃ¢n loáº¡i sai

**2) Tham sá»‘ $$C > 0$$:**
- $$C$$ lá»›n: Pháº¡t náº·ng vi pháº¡m â†’ margin nhá», Ã­t misclassify
- $$C$$ nhá»: Cho phÃ©p nhiá»u vi pháº¡m â†’ margin lá»›n
- **Trade-off**: Margin width vs. Training error

**3) HÃ m má»¥c tiÃªu:**
- $$\frac{1}{2}\|\beta\|_2^2$$: Maximize margin
- $$C\sum \xi_i$$: Minimize total violation

### 5.1. Minh há»a tÆ°Æ¡ng tÃ¡c: áº¢nh hÆ°á»Ÿng cá»§a tham sá»‘ C

<div id="softmargin-demo" style="margin: 20px 0;">
    <canvas id="softMarginCanvas" width="700" height="500" style="border: 1px solid #ccc; display: block; margin: 0 auto;"></canvas>
    <div style="text-align: center; margin-top: 15px;">
        <label for="cSlider" style="font-size: 16px; font-weight: bold;">Tham sá»‘ C: <span id="cValue">1.0</span></label><br>
        <input type="range" id="cSlider" min="0.01" max="10" step="0.1" value="1" style="width: 400px; margin: 10px;">
        <p style="font-size: 14px; color: #666; margin-top: 10px;">
            <strong>C nhá» (â†)</strong>: Margin rá»™ng, nhiá»u vi pháº¡m Ä‘Æ°á»£c cháº¥p nháº­n<br>
            <strong>C lá»›n (â†’)</strong>: Margin háº¹p, Ã­t vi pháº¡m, pháº¡t náº·ng
        </p>
        <div id="svmStats" style="margin-top: 10px; font-size: 14px;">
            <span style="color: #e74c3c; font-weight: bold;">â— Vi pháº¡m margin: 0</span> | 
            <span style="color: #f39c12; font-weight: bold;">â— Support vectors: 0</span>
        </div>
    </div>
</div>

<script>
(function() {
    const canvas = document.getElementById('softMarginCanvas');
    if (!canvas) return;
    
    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;
    
    // Dá»¯ liá»‡u vá»›i má»™t sá»‘ Ä‘iá»ƒm gÃ¢y overlap
    const points = [
        // Class +1
        {x: 480, y: 150, label: 1},
        {x: 520, y: 100, label: 1},
        {x: 550, y: 200, label: 1},
        {x: 500, y: 250, label: 1},
        {x: 530, y: 180, label: 1},
        // Outliers class +1
        {x: 350, y: 280, label: 1}, // Vi pháº¡m
        {x: 380, y: 320, label: 1}, // Vi pháº¡m
        // Class -1
        {x: 180, y: 250, label: -1},
        {x: 220, y: 300, label: -1},
        {x: 260, y: 350, label: -1},
        {x: 200, y: 400, label: -1},
        {x: 240, y: 280, label: -1},
        // Outliers class -1
        {x: 420, y: 180, label: -1}, // Vi pháº¡m
        {x: 400, y: 220, label: -1}  // Vi pháº¡m
    ];
    
    let C = 1.0;
    
    function softMarginSVM() {
        // Simplified soft-margin SVM
        let posPoints = points.filter(p => p.label === 1);
        let negPoints = points.filter(p => p.label === -1);
        
        if (posPoints.length === 0 || negPoints.length === 0) return null;
        
        // TÃ­nh centroid vá»›i trá»ng sá»‘ dá»±a trÃªn C
        // C lá»›n -> Ã­t bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers
        // C nhá» -> cháº¥p nháº­n outliers nhiá»u hÆ¡n
        
        let posCenter = {
            x: posPoints.reduce((sum, p) => sum + p.x, 0) / posPoints.length,
            y: posPoints.reduce((sum, p) => sum + p.y, 0) / posPoints.length
        };
        
        let negCenter = {
            x: negPoints.reduce((sum, p) => sum + p.x, 0) / negPoints.length,
            y: negPoints.reduce((sum, p) => sum + p.y, 0) / negPoints.length
        };
        
        // Äiá»u chá»‰nh hyperplane dá»±a trÃªn C
        let dx = posCenter.x - negCenter.x;
        let dy = posCenter.y - negCenter.y;
        
        // Vá»›i C nhá», cho phÃ©p hyperplane linh hoáº¡t hÆ¡n
        let flexibility = Math.max(0.1, 1 / C);
        
        let midX = (posCenter.x + negCenter.x) / 2;
        let midY = (posCenter.y + negCenter.y) / 2;
        
        let w = {x: dx, y: dy};
        let b = -(w.x * midX + w.y * midY);
        let norm = Math.sqrt(w.x * w.x + w.y * w.y);
        
        w.x /= norm;
        w.y /= norm;
        b /= norm;
        
        // TÃ­nh margin base
        let distances = points.map(p => ({
            point: p,
            dist: Math.abs(w.x * p.x + w.y * p.y + b),
            signedDist: (w.x * p.x + w.y * p.y + b) * p.label
        }));
        
        // Soft margin: margin Ä‘iá»u chá»‰nh theo C
        let baseMargin = 50;
        let margin = baseMargin / (1 + C * 0.5);
        
        // TÃ¬m violations vÃ  support vectors
        let violations = distances.filter(d => d.signedDist < margin);
        let supportVectors = distances.filter(d => 
            Math.abs(d.dist - margin) < 20 || d.signedDist < margin
        );
        
        return {
            w, b, margin,
            violations: violations.map(v => v.point),
            supportVectors: supportVectors.map(v => v.point),
            distances
        };
    }
    
    function draw() {
        ctx.clearRect(0, 0, width, height);
        
        // Background
        ctx.fillStyle = '#fafafa';
        ctx.fillRect(0, 0, width, height);
        
        let svm = softMarginSVM();
        
        if (svm) {
            // Váº½ margin region (vÃ¹ng mÃ u nháº¡t)
            ctx.fillStyle = 'rgba(52, 152, 219, 0.1)';
            ctx.fillRect(0, 0, width, height);
            
            // Váº½ margin boundaries
            ctx.strokeStyle = '#95a5a6';
            ctx.lineWidth = 2;
            ctx.setLineDash([5, 5]);
            
            let b1 = svm.b + svm.margin;
            let b2 = svm.b - svm.margin;
            drawLine(svm.w, b1);
            drawLine(svm.w, b2);
            
            ctx.setLineDash([]);
            
            // Váº½ hyperplane
            ctx.strokeStyle = '#2c3e50';
            ctx.lineWidth = 3;
            drawLine(svm.w, svm.b);
            
            // Highlight violations (slack variables)
            svm.violations.forEach(v => {
                ctx.strokeStyle = 'rgba(231, 76, 60, 0.5)';
                ctx.lineWidth = 20;
                ctx.beginPath();
                ctx.arc(v.x, v.y, 12, 0, 2 * Math.PI);
                ctx.stroke();
            });
            
            // Highlight support vectors
            svm.supportVectors.forEach(sv => {
                ctx.strokeStyle = '#f39c12';
                ctx.lineWidth = 3;
                ctx.beginPath();
                ctx.arc(sv.x, sv.y, 15, 0, 2 * Math.PI);
                ctx.stroke();
            });
            
            // Update stats
            const statsDiv = document.getElementById('svmStats');
            if (statsDiv) {
                statsDiv.innerHTML = `
                    <span style="color: #e74c3c; font-weight: bold;">â— Vi pháº¡m margin: ${svm.violations.length}</span> | 
                    <span style="color: #f39c12; font-weight: bold;">â— Support vectors: ${svm.supportVectors.length}</span> | 
                    <span style="color: #3498db; font-weight: bold;">Margin width: ${(svm.margin * 2).toFixed(1)}</span>
                `;
            }
        }
        
        // Váº½ Ä‘iá»ƒm dá»¯ liá»‡u
        points.forEach(p => {
            ctx.fillStyle = p.label === 1 ? '#e74c3c' : '#2ecc71';
            ctx.beginPath();
            ctx.arc(p.x, p.y, 8, 0, 2 * Math.PI);
            ctx.fill();
            
            ctx.strokeStyle = '#34495e';
            ctx.lineWidth = 2;
            ctx.stroke();
        });
        
        // Legend
        ctx.fillStyle = '#34495e';
        ctx.font = 'bold 14px Arial';
        ctx.fillText(`C = ${C.toFixed(2)}`, 10, 30);
        
        // Giáº£i thÃ­ch C
        if (C < 0.5) {
            ctx.fillText('Soft margin: Cháº¥p nháº­n nhiá»u vi pháº¡m', 10, 55);
        } else if (C > 5) {
            ctx.fillText('Hard margin: Pháº¡t náº·ng vi pháº¡m', 10, 55);
        } else {
            ctx.fillText('Balanced: Trade-off margin vs error', 10, 55);
        }
    }
    
    function drawLine(w, b) {
        ctx.beginPath();
        if (Math.abs(w.y) > 0.01) {
            let y0 = -(w.x * 0 + b) / w.y;
            let y1 = -(w.x * width + b) / w.y;
            ctx.moveTo(0, y0);
            ctx.lineTo(width, y1);
        } else {
            let x = -b / w.x;
            ctx.moveTo(x, 0);
            ctx.lineTo(x, height);
        }
        ctx.stroke();
    }
    
    // Slider event
    const slider = document.getElementById('cSlider');
    const cValue = document.getElementById('cValue');
    
    if (slider && cValue) {
        slider.addEventListener('input', function() {
            C = parseFloat(this.value);
            cValue.textContent = C.toFixed(2);
            draw();
        });
    }
    
    // Initial draw
    draw();
})();
</script>

---

## 6. Äiá»u kiá»‡n KKT cho SVM

### 6.1. HÃ m Lagrangian

Vá»›i nhÃ¢n tá»­ Lagrange $$v \geq 0$$ (cho $$\xi_i \geq 0$$) vÃ  $$w \geq 0$$ (cho rÃ ng buá»™c margin):

$$
\begin{align}
L(\beta, \beta_0, \xi, v, w) = &\frac{1}{2} \|\beta\|_2^2 + C\sum_{i=1}^n \xi_i - \sum_{i=1}^n v_i \xi_i \\
&+ \sum_{i=1}^n w_i (1 - \xi_i - y_i (\beta^T x_i + \beta_0))
\end{align}
$$

### 6.2. Äiá»u kiá»‡n Stationarity

**1) Äáº¡o hÃ m theo $$\beta$$:**
$$
\frac{\partial L}{\partial \beta} = \beta - \sum_{i=1}^n w_i y_i x_i = 0
$$

$$
\Rightarrow \boxed{\beta^\star = \sum_{i=1}^n w_i^\star y_i x_i}
$$

**Ã nghÄ©a quan trá»ng:** Nghiá»‡m tá»‘i Æ°u lÃ  tá»• há»£p tuyáº¿n tÃ­nh cá»§a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u!

**2) Äáº¡o hÃ m theo $$\beta_0$$:**
$$
\boxed{\sum_{i=1}^n w_i^\star y_i = 0}
$$

**3) Äáº¡o hÃ m theo $$\xi_i$$:**
$$
C - v_i - w_i = 0 \Rightarrow \boxed{v_i^\star = C - w_i^\star}
$$

**Suy ra:** $$0 \leq w_i^\star \leq C$$ (vÃ¬ $$v_i^\star \geq 0$$)

### 6.3. Complementary Slackness

**1) Cho $$\xi_i \geq 0$$:**
$$
v_i^\star \xi_i^\star = 0, \quad i = 1, \ldots, n
$$

**2) Cho rÃ ng buá»™c margin:**
$$
w_i^\star (1 - \xi_i^\star - y_i (\beta^{\star T} x_i + \beta_0^\star)) = 0, \quad i = 1, \ldots, n
$$

### 6.4. PhÃ¢n tÃ­ch cÃ¡c trÆ°á»ng há»£p

#### **TrÆ°á»ng há»£p 1: $$w_i^\star = 0$$ (Non-support vector)**

- Tá»« $$v_i^\star = C > 0$$ â†’ $$\xi_i^\star = 0$$ (CS 1)
- Tá»« CS 2: RÃ ng buá»™c margin khÃ´ng cháº·t
- **Káº¿t luáº­n:** $$y_i(\beta^{\star T} x_i + \beta_0^\star) > 1$$ 
- Äiá»ƒm náº±m **ngoÃ i margin**, phÃ¢n loáº¡i Ä‘Ãºng, khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n nghiá»‡m

#### **TrÆ°á»ng há»£p 2: $$0 < w_i^\star < C$$ (Support vector trÃªn margin)**

- Cáº£ $$v_i^\star$$ vÃ  $$w_i^\star$$ Ä‘á»u dÆ°Æ¡ng
- Tá»« CS: $$\xi_i^\star = 0$$ vÃ  $$y_i(\beta^{\star T} x_i + \beta_0^\star) = 1$$
- **Káº¿t luáº­n:** Äiá»ƒm náº±m **Ä‘Ãºng trÃªn margin boundary**
- Quan trá»ng nháº¥t trong xÃ¡c Ä‘á»‹nh siÃªu pháº³ng!

#### **TrÆ°á»ng há»£p 3: $$w_i^\star = C$$ (Support vector vi pháº¡m margin)**

- Tá»« $$v_i^\star = 0$$: khÃ´ng rÃ ng buá»™c $$\xi_i^\star$$
- Tá»« CS 2: $$y_i(\beta^{\star T} x_i + \beta_0^\star) = 1 - \xi_i^\star$$

**PhÃ¢n loáº¡i con:**
- $$\xi_i^\star = 0$$: TrÃªn margin (giá»‘ng trÆ°á»ng há»£p 2)
- $$0 < \xi_i^\star < 1$$: Trong margin zone, phÃ¢n loáº¡i Ä‘Ãºng
- $$\xi_i^\star \geq 1$$: Bá»‹ phÃ¢n loáº¡i sai (misclassified)

## 7. Support Vectors

### Äá»‹nh nghÄ©a

**Support vectors** lÃ  cÃ¡c Ä‘iá»ƒm cÃ³ $$w_i^\star > 0$$.

Tá»« Ä‘iá»u kiá»‡n stationarity:
$$
\beta^\star = \sum_{i: w_i^\star > 0} w_i^\star y_i x_i
$$

â†’ **Chá»‰ support vectors quyáº¿t Ä‘á»‹nh siÃªu pháº³ng!**

### PhÃ¢n loáº¡i Support Vectors

<figure class="image" style="align: center;">
<p align="center">
 <img src="{{ site.baseurl }}/img/chapter_img/chapter12/svm.png" alt="" width="70%" height="70%">
 <figcaption style="text-align: center;">$$ \text{[HÃ¬nh 1] Minh há»a cÃ¡c support vectors vá»›i } \xi^\star \neq 0 \text{ [3]}$$ </figcaption>
</p>
</figure>

**1) Support vectors trÃªn margin** ($$\xi_i^\star = 0$$, $$0 < w_i^\star \leq C$$):
- Náº±m Ä‘Ãºng trÃªn Ä‘Æ°á»ng biÃªn margin
- $$y_i(\beta^{\star T} x_i + \beta_0^\star) = 1$$
- Quan trá»ng nháº¥t trong xÃ¡c Ä‘á»‹nh siÃªu pháº³ng

**2) Support vectors trong margin** ($$0 < \xi_i^\star < 1$$, $$w_i^\star = C$$):
- Náº±m giá»¯a margin vÃ  siÃªu pháº³ng
- Váº«n phÃ¢n loáº¡i Ä‘Ãºng nhÆ°ng vi pháº¡m margin
- ThÆ°á»ng lÃ  outliers hoáº·c Ä‘iá»ƒm gáº§n biÃªn

**3) Support vectors bá»‹ misclassify** ($$\xi_i^\star \geq 1$$, $$w_i^\star = C$$):
- Náº±m sai phÃ­a siÃªu pháº³ng
- Bá»‹ phÃ¢n loáº¡i sai
- ÄÃ³ng gÃ³p nhiá»u vÃ o penalty $$C\sum \xi_i$$

### Ã nghÄ©a thá»±c tiá»…n

1. **Hiá»‡u quáº£ tÃ­nh toÃ¡n:**
   - Chá»‰ cáº§n lÆ°u trá»¯ $$s$$ support vectors (thÆ°á»ng $$s \ll n$$)
   - Prediction: $$\hat{y} = \text{sign}(\sum_{SV} w_i y_i \langle x_i, x \rangle + \beta_0)$$

2. **á»”n Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh:**
   - Chá»‰ phá»¥ thuá»™c support vectors
   - CÃ¡c Ä‘iá»ƒm xa margin khÃ´ng áº£nh hÆ°á»Ÿng
   - Robust vá»›i outliers (náº¿u $$C$$ phÃ¹ há»£p)

3. **Sparsity:**
   - Nhiá»u $$w_i = 0$$ (non-support vectors)
   - MÃ´ hÃ¬nh "sparse" vÃ  dá»… giáº£i thÃ­ch

## 8. VÃ­ dá»¥ Chi tiáº¿t

### VÃ­ dá»¥ 1D: Dá»¯ liá»‡u Ä‘Æ¡n giáº£n

**Dá»¯ liá»‡u:**
- Lá»›p $$+1$$: $$x_1 = 3, x_2 = 4$$
- Lá»›p $$-1$$: $$x_3 = 1, x_4 = 2$$

**BÃ i toÃ¡n hard-margin:**
$$
\begin{align}
\min_{\beta, \beta_0} \quad &\frac{1}{2}\beta^2 \\
\text{s.t.} \quad &3\beta + \beta_0 \geq 1, \quad 4\beta + \beta_0 \geq 1 \\
&-\beta - \beta_0 \geq 1, \quad -2\beta - \beta_0 \geq 1
\end{align}
$$

**Giáº£i phÃ¡p hÃ¬nh há»c:**
- SiÃªu pháº³ng tá»‘i Æ°u náº±m giá»¯a $$x = 2$$ vÃ  $$x = 3$$
- Äiá»ƒm gáº§n nháº¥t: $$x_2 = 4$$ vÃ  $$x_4 = 2$$

**Äiá»u kiá»‡n margin cháº·t:**
$$
\begin{cases}
4\beta + \beta_0 = 1 \\
2\beta + \beta_0 = -1
\end{cases}
\Rightarrow \beta = 1, \quad \beta_0 = -3
$$

**Nghiá»‡m:**
- SiÃªu pháº³ng: $$x - 3 = 0$$ hay $$x = 3$$ (sai! pháº£i lÃ  $$x=2.5$$)
- HÃ£y kiá»ƒm tra láº¡i...

**Sá»­a láº¡i:** Äiá»ƒm gáº§n nháº¥t pháº£i lÃ  $$x = 3$$ (lá»›p +1) vÃ  $$x = 2$$ (lá»›p -1):
$$
\begin{cases}
3\beta + \beta_0 = 1 \\
2\beta + \beta_0 = -1
\end{cases}
\Rightarrow \beta = 2, \quad \beta_0 = -5
$$

- SiÃªu pháº³ng: $$2x - 5 = 0$$ hay $$x = 2.5$$ âœ“
- Margin: $$\frac{2}{\lvert\beta\rvert} = \frac{2}{2} = 1$$
- Support vectors: $$x = 3$$ vÃ  $$x = 2$$

## 9. BÃ i toÃ¡n Äá»‘i ngáº«u

### Dual Problem

Tháº¿ cÃ¡c Ä‘iá»u kiá»‡n stationarity vÃ o Lagrangian:

$$
\begin{align}
\max_{w} \quad &\sum_{i=1}^n w_i - \frac{1}{2} \sum_{i,j} w_i w_j y_i y_j \langle x_i, x_j \rangle \\
\text{s.t.} \quad &\sum_{i=1}^n w_i y_i = 0 \\
&0 \leq w_i \leq C, \quad i = 1, \ldots, n
\end{align}
$$

### Æ¯u Ä‘iá»ƒm

1. **Kernel trick**: Chá»‰ phá»¥ thuá»™c vÃ o $$\langle x_i, x_j \rangle$$ â†’ cÃ³ thá»ƒ dÃ¹ng kernel
2. **Ãt rÃ ng buá»™c hÆ¡n**: Chá»‰ 1 rÃ ng buá»™c Ä‘áº³ng thá»©c + box constraints
3. **Solver hiá»‡u quáº£**: SMO, LIBSVM

## 10. á»¨ng dá»¥ng KKT trong SVM

### 10.1. Kiá»ƒm tra tÃ­nh tá»‘i Æ°u

DÃ¹ng Ä‘iá»u kiá»‡n KKT Ä‘á»ƒ verify nghiá»‡m:
1. Primal/Dual feasibility
2. Stationarity
3. Complementary slackness

### 10.2. TÃ­nh $$\beta_0$$

Tá»« support vectors trÃªn margin ($$0 < w_i < C$$):
$$
\beta_0 = y_i - \beta^T x_i = y_i - \sum_{j} w_j y_j \langle x_j, x_i \rangle
$$

**Thá»±c táº¿:** Láº¥y trung bÃ¬nh trÃªn táº¥t cáº£ SV trÃªn margin:
$$
\beta_0 = \frac{1}{\lvert S\rvert} \sum_{i \in S} \left( y_i - \sum_{j} w_j y_j \langle x_j, x_i \rangle \right)
$$

### 10.3. Lá»c Support Vectors

TrÆ°á»›c khi giáº£i, loáº¡i bá» Ä‘iá»ƒm cháº¯c cháº¯n khÃ´ng pháº£i SV:
$$
y_i(\beta_{\text{init}}^T x_i + \beta_{0,\text{init}}) \gg 1
$$

â†’ TÄƒng hiá»‡u quáº£ cho datasets lá»›n

## 11. BÃ i táº­p Thá»±c hÃ nh

### BÃ i táº­p 1: PhÃ¢n tÃ­ch Support Vectors

Cho nghiá»‡m SVM vá»›i $$C = 1$$:
```
w = (0, 0.5, 0.3, 1, 0, 1, 0.2)
Î¾ = (0, 0, 0.2, 0.8, 0, 1.5, 0)
```

**YÃªu cáº§u:**
a) XÃ¡c Ä‘á»‹nh support vectors  
b) PhÃ¢n loáº¡i theo vá»‹ trÃ­ (trÃªn margin, trong margin, misclassified)  
c) Giáº£i thÃ­ch $$w_1 = 0$$ nhÆ°ng $$\xi_1 = 0$$

<details>
<summary><strong>ğŸ’¡ Lá»i giáº£i</strong></summary>

**a) Support vectors:** $$i \in \{2, 3, 4, 6, 7\}$$ (vÃ¬ $$w_i > 0$$)

**b) PhÃ¢n loáº¡i:**
- **TrÃªn margin**: $$i = 2, 7$$ ($$\xi_i = 0$$, $$0 < w_i < C$$)
- **Trong margin**: $$i = 3, 4$$ ($$0 < \xi_i < 1$$, $$w_i = C$$)
- **Misclassified**: $$i = 6$$ ($$\xi_6 = 1.5 > 1$$, $$w_6 = C$$)

**c)** $$w_1 = 0$$ nghÄ©a lÃ  khÃ´ng pháº£i SV. Tá»« CS: $$v_1 = C - 0 = 1 > 0$$ â†’ $$\xi_1 = 0$$ âœ“  
Äiá»ƒm $$x_1$$ náº±m xa margin, phÃ¢n loáº¡i Ä‘Ãºng.

</details>

---

### BÃ i táº­p 2: TÃ­nh toÃ¡n tá»« KKT

Cho $$C = 2$$, $$n = 3$$, $$p = 2$$:
```
xâ‚ = (0, 1), yâ‚ = +1, wâ‚ = 0.5
xâ‚‚ = (1, 0), yâ‚‚ = +1, wâ‚‚ = 0.5  
xâ‚ƒ = (0, 0), yâ‚ƒ = -1, wâ‚ƒ = 1
```
$$\xi_1 = \xi_2 = 0$$, $$\xi_3 = 0.2$$.

**YÃªu cáº§u:**
a) TÃ­nh $$\beta$$ tá»« stationarity  
b) TÃ­nh $$\beta_0$$ tá»« SV trÃªn margin  
c) Kiá»ƒm tra CS cho $$i=3$$

<details>
<summary><strong>ğŸ’¡ Lá»i giáº£i</strong></summary>

**a)** $$\beta = \sum w_i y_i x_i = 0.5(0,1) + 0.5(1,0) + 1 \cdot (-1)(0,0) = (0.5, 0.5)$$

**b)** Tá»« $$i=1$$: $$y_1(\beta^T x_1 + \beta_0) = 1$$  
$$1 \cdot (0.5 + \beta_0) = 1$$ â†’ $$\beta_0 = 0.5$$

**c)** CS: $$w_3(1 - \xi_3 - y_3(\beta^T x_3 + \beta_0)) = 0$$  
$$y_3(\beta^T x_3 + \beta_0) = -1(0.5) = -0.5$$  
$$1(1 - 0.2 - (-0.5)) = 1.3 \neq 0$$ âœ—  

**Káº¿t luáº­n:** CS vi pháº¡m! CÃ³ lá»—i trong dá»¯ liá»‡u.

</details>

---

## 12. TÃ³m táº¯t

### CÃ¡c Ä‘iá»ƒm chÃ­nh

1. **SVM giáº£i quyáº¿t váº¥n Ä‘á» cá»§a PLA**: Trong vÃ´ sá»‘ máº·t phÃ¢n cÃ¡ch, SVM tÃ¬m máº·t cÃ³ margin lá»›n nháº¥t
2. **Maximum Margin Classifier**: SVM tá»‘i Ä‘a hÃ³a khoáº£ng cÃ¡ch tá»« máº·t phÃ¢n cÃ¡ch Ä‘áº¿n Ä‘iá»ƒm gáº§n nháº¥t
3. **BÃ i toÃ¡n tá»‘i Æ°u lá»“i**: Hard-margin SVM lÃ  Quadratic Programming vá»›i nghiá»‡m duy nháº¥t
4. **Soft-margin** cho phÃ©p vi pháº¡m qua $$\xi_i$$, Ä‘iá»u khiá»ƒn bá»Ÿi $$C$$
5. **Äiá»u kiá»‡n KKT** cho:
   - $$\beta = \sum w_i y_i x_i$$ (chá»‰ phá»¥ thuá»™c support vectors)
   - PhÃ¢n loáº¡i Ä‘iá»ƒm thÃ nh SV vÃ  non-SV
6. **Support vectors** quyáº¿t Ä‘á»‹nh siÃªu pháº³ng, thÆ°á»ng $$s \ll n$$
7. **Complementary slackness** giáº£i thÃ­ch khi nÃ o $$w_i = 0$$ hay $$w_i > 0$$

### Ã nghÄ©a thá»±c tiá»…n

Äiá»u kiá»‡n KKT khÃ´ng dÃ¹ng trá»±c tiáº¿p Ä‘á»ƒ giáº£i SVM (dÃ¹ng SMO, LIBSVM), nhÆ°ng giÃºp:
- Kiá»ƒm chá»©ng tÃ­nh tá»‘i Æ°u
- Hiá»ƒu cáº¥u trÃºc nghiá»‡m (sparsity, support vectors)
- PhÃ¡t triá»ƒn thuáº­t toÃ¡n hiá»‡u quáº£
- PhÃ¢n tÃ­ch Ä‘á»™ nháº¡y cá»§a mÃ´ hÃ¬nh

### Lá»£i tháº¿ cá»§a SVM

1. **Hiá»‡u quáº£ vá»›i dá»¯ liá»‡u chiá»u cao**: Hoáº¡t Ä‘á»™ng tá»‘t khi sá»‘ chiá»u > sá»‘ máº«u
2. **Tiáº¿t kiá»‡m bá»™ nhá»›**: Chá»‰ lÆ°u trá»¯ support vectors
3. **Linh hoáº¡t**: CÃ³ thá»ƒ dÃ¹ng kernel cho dá»¯ liá»‡u phi tuyáº¿n
4. **Robust**: Ãt bá»‹ overfitting nhá» margin maximization

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

### SÃ¡ch vÃ  giÃ¡o trÃ¬nh

1. **Vapnik, V. N.** (1995). *The Nature of Statistical Learning Theory*. Springer.
2. **Boyd, S., & Vandenberghe, L.** (2004). *Convex Optimization*. Cambridge University Press. Chapter 12.
3. **Hastie, T., et al.** (2009). *The Elements of Statistical Learning* (2nd ed.). Springer. Chapter 12.
4. **Cristianini, N., & Shawe-Taylor, J.** (2000). *An Introduction to Support Vector Machines*. Cambridge University Press.
5. **Bishop, C. M.** (2006). *Pattern Recognition and Machine Learning*. Springer. Chapter 7.

### BÃ i viáº¿t vÃ  tutorial

6. **Machine Learning CÆ¡ Báº£n** - [BÃ i 19: Support Vector Machine](https://machinelearningcoban.com/2017/04/09/smv/) - VÅ© Há»¯u Tiá»‡p
7. **scikit-learn Documentation** - [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html)
8. **LIBSVM** - [A Library for Support Vector Machines](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)
