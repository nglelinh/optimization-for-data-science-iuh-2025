---
layout: post
title: 04-08 Relaxation
chapter: '04'
order: 9
owner: YoungJae Choung
categories:
- chapter04
lang: vi
---
This section discusses relaxation techniques, which are used to simplify or approximate convex optimization problems by relaxing constraints.

Consider a problem of the form:
>$$\text{min}_{x} \text{ } f(x) \text{  subject to  } x \in C$$

The process of changing the domain set $$C$$ to a superset $$\tilde{C} \supseteq C$$ is known as *Relaxation*.
>$$\text{min}_{x} \text{ } f(x) \text{  subject to  } x \in \tilde{C}$$

Since we are optimizing over a larger domain set than $$C$$, the optimal value of the relaxed problem is always less than or equal to that of the original problem.

#### Important special case: relaxing non-affine equality constraints
>$$h_{j}(x) = 0, j = 1, \dotsc, r,$$ where $$h_{j}, j = 1, \dotsc, r$$ are convex but non-affine,
>are replaced with $$h_{j(x)} \le 0, j = 1, \dotsc, r.$$

By transforming equality constraints into inequality constraints, the relaxation technique loosens the constraints and effectively enlarges the domain. When the given equality constraints are convex and non-affine, this method can be used to reformulate the problem as a convex optimization problem. (However, this is under the condition that the same solution is still valid even after the relaxation.)
