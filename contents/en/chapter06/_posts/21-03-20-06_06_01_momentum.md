---
layout: post
title: 06-06-01 Momentum
chapter: '06'
order: 17
owner: Kyeongmin Woo
categories:
- chapter06
lang: en
lesson_type: required
---

Gradient descent cơ bản có thể gặp phải một số vấn đề trong thực tế, đặc biệt là tốc độ hội tụ chậm và dao động quanh điểm tối ưu. **Momentum** là một trong những cải tiến quan trọng nhất để khắc phục những hạn chế này.

## Động lực và ý tưởng

Gradient descent cơ bản có thể gặp khó khăn khi:
- Hàm mục tiêu có độ cong khác nhau theo các hướng khác nhau
- Gradient dao động mạnh, gây ra hiện tượng "zigzag"
- Tốc độ hội tụ chậm trong các thung lũng hẹp

**Momentum** được lấy cảm hứng từ vật lý: một quả bóng lăn xuống đồi không chỉ phụ thuộc vào độ dốc tại điểm hiện tại mà còn duy trì một phần vận tốc từ các bước trước đó.

<figure class="image" style="align: center;">
<p align="center">
  <img src="https://miro.medium.com/max/1400/1*f2OaVsd3T85WiSK-caJdEA.gif" alt="momentum_visualization" width="60%" height="60%">
  <figcaption style="text-align: center;">Momentum giúp quả bóng vượt qua các điểm cực tiểu địa phương</figcaption>
</p>
</figure>

## Công thức Momentum

Thuật toán Momentum duy trì một vector vận tốc $$v$$ được cập nhật như sau:

> $$v^{(k)} = \beta v^{(k-1)} + (1-\beta) \nabla f(x^{(k-1)})$$
> $$x^{(k)} = x^{(k-1)} - \alpha v^{(k)}$$

Trong đó:
- $$\beta \in [0,1)$$ là **hệ số momentum** (thường $$\beta = 0.9$$)
- $$\alpha > 0$$ là **learning rate**
- $$v^{(0)} = 0$$ (khởi tạo vận tốc bằng 0)

### Pseudocode

> **Given** starting point $$x^{(0)}$$, learning rate $$\alpha$$, momentum $$\beta$$ <br>
> **Initialize** $$v^{(0)} = 0$$ <br>
> **For** $$k = 1, 2, 3, ...$$ **do** <br>
> &nbsp;&nbsp;&nbsp;&nbsp; Compute gradient: $$g^{(k)} = \nabla f(x^{(k-1)})$$ <br>
> &nbsp;&nbsp;&nbsp;&nbsp; Update velocity: $$v^{(k)} = \beta v^{(k-1)} + (1-\beta) g^{(k)}$$ <br>
> &nbsp;&nbsp;&nbsp;&nbsp; Update position: $$x^{(k)} = x^{(k-1)} - \alpha v^{(k)}$$ <br>
> **Until** convergence criterion is met

## Phân tích toán học

Momentum có thể được viết dưới dạng tổng trọng số của các gradient trước đó:

> $$v^{(k)} = (1-\beta) \sum_{i=0}^{k-1} \beta^i \nabla f(x^{(k-1-i)})$$

Điều này cho thấy:
- Gradient gần đây có trọng số cao hơn: $$(1-\beta)$$
- Các gradient cũ vẫn có ảnh hưởng nhưng giảm dần theo hàm mũ: $$(1-\beta)\beta^i$$
- Khi $$\beta \to 1$$, thuật toán "nhớ" lâu hơn các gradient trước đó

### Exponentially Weighted Moving Average

Momentum thực chất là một **Exponentially Weighted Moving Average (EWMA)** của các gradient:

> $$v^{(k)} = (1-\beta) \nabla f(x^{(k-1)}) + \beta v^{(k-1)}$$

Điều này tương đương với:
> $$v^{(k)} = (1-\beta) \sum_{i=0}^{k-1} \beta^i \nabla f(x^{(k-1-i)})$$

## Ưu điểm của Momentum

### 1. Tăng tốc hội tụ
Trong các hướng có gradient nhất quán, momentum tích lũy vận tốc, giúp thuật toán di chuyển nhanh hơn về phía điểm tối ưu.

### 2. Giảm dao động
Trong các hướng có gradient dao động, momentum làm mượt chuyển động bằng cách trung bình hóa các gradient trái chiều.

### 3. Vượt qua local minima
Quán tính giúp thuật toán có thể vượt qua các điểm cực tiểu địa phương nông, đặc biệt hữu ích trong tối ưu hóa non-convex.

## Ví dụ minh họa

### Hàm Quadratic với Condition Number cao

Xét hàm $$f(x,y) = \frac{1}{2}(10x^2 + y^2)$$ - một ellipse với tỷ lệ khung hình 10:1.

**Gradient**: $$\nabla f(x,y) = [10x, y]$$

**Gradient descent thông thường**:
- Dao động mạnh theo hướng x (gradient lớn: 10x)
- Tiến chậm theo hướng y (gradient nhỏ: y)
- Tạo ra quỹ đạo "zigzag"

**Momentum**:
- Tích lũy vận tốc theo hướng y (hướng đúng đến minimum)
- Làm mượt dao động theo hướng x
- Quỹ đạo mượt mà hơn và hội tụ nhanh hơn

### Phân tích số học

Với $$\beta = 0.9$$, $$\alpha = 0.01$$, starting point $$(2, 2)$$:

**Iteration 1**:
- $$g^{(1)} = [20, 2]$$
- $$v^{(1)} = 0.9 \cdot [0,0] + 0.1 \cdot [20,2] = [2, 0.2]$$
- $$x^{(1)} = [2,2] - 0.01 \cdot [2,0.2] = [1.98, 1.998]$$

**Iteration 2**:
- $$g^{(2)} = [19.8, 1.998]$$
- $$v^{(2)} = 0.9 \cdot [2,0.2] + 0.1 \cdot [19.8,1.998] = [3.78, 0.38]$$
- $$x^{(2)} = [1.98,1.998] - 0.01 \cdot [3.78,0.38] = [1.942, 1.994]$$

Ta thấy vận tốc tích lũy theo cả hai hướng, giúp tăng tốc hội tụ.

## Interactive Visualization

<div id="momentum-demo" style="margin: 20px 0;">
    <div style="margin-bottom: 15px;">
        <label for="momentum-beta-demo">Momentum β: <span id="momentum-beta-demo-value">0.9</span></label><br>
        <input type="range" id="momentum-beta-demo" min="0" max="0.99" step="0.01" value="0.9" style="width: 300px;">
    </div>
    
    <div style="margin-bottom: 15px;">
        <label for="learning-rate-demo">Learning Rate α: <span id="learning-rate-demo-value">0.01</span></label><br>
        <input type="range" id="learning-rate-demo" min="0.001" max="0.1" step="0.001" value="0.01" style="width: 300px;">
    </div>
    
    <div style="margin-bottom: 15px;">
        <button id="start-momentum-demo">Start Comparison</button>
        <button id="reset-momentum-demo">Reset</button>
        <button id="step-momentum-demo">Single Step</button>
    </div>
    
    <canvas id="momentum-demo-canvas" width="600" height="400" style="border: 1px solid #ccc; display: block; margin: 0 auto;"></canvas>
    
    <div id="momentum-demo-info" style="text-align: center; margin-top: 10px; font-family: monospace;">
        <div>Standard GD - Iteration: 0, Loss: 12.500</div>
        <div>Momentum - Iteration: 0, Loss: 12.500</div>
    </div>
</div>

## Hyperparameter Tuning

### Momentum Coefficient (β)

- **$$\beta = 0.0$$**: Không có momentum, tương đương gradient descent thông thường
- **$$\beta = 0.5$$**: Momentum nhẹ, phù hợp khi gradient tương đối ổn định
- **$$\beta = 0.9$$**: Giá trị phổ biến, cân bằng tốt giữa tốc độ và ổn định
- **$$\beta = 0.99$$**: Momentum mạnh, phù hợp với bài toán khó hoặc gradient noise cao
- **$$\beta \to 1$$**: Có thể gây overshooting và không ổn định

### Learning Rate (α)

Khi sử dụng momentum, learning rate thường cần điều chỉnh:
- **Giảm α**: Do momentum tăng tốc, cần α nhỏ hơn để tránh divergence
- **Rule of thumb**: $$\alpha_{momentum} \approx \frac{\alpha_{GD}}{1 + \beta}$$

### Adaptive Scheduling

Một số chiến lược điều chỉnh β theo thời gian:
- **Warm-up**: Bắt đầu với β nhỏ, tăng dần
- **Decay**: Giảm β khi gần convergence để tăng độ chính xác

## Biến thể của Momentum

### 1. Classical Momentum (Polyak, 1964)
Công thức gốc như đã trình bày ở trên.

### 2. Nesterov Momentum
Sẽ được trình bày chi tiết trong phần tiếp theo.

### 3. Momentum với Weight Decay
> $$v^{(k)} = \beta v^{(k-1)} + (1-\beta)(\nabla f(x^{(k-1)}) + \lambda x^{(k-1)})$$

## Ứng dụng thực tế

### 1. Deep Learning
- **Neural Networks**: Momentum là standard trong training deep networks
- **Batch normalization**: Kết hợp tốt với momentum
- **Transfer learning**: Giúp fine-tuning nhanh hơn

### 2. Computer Vision
- **Image classification**: ResNet, VGG đều sử dụng momentum
- **Object detection**: YOLO, R-CNN với momentum optimizer

### 3. Natural Language Processing
- **Language models**: BERT, GPT training với momentum
- **Machine translation**: Transformer architectures

## So sánh với các phương pháp khác

| Phương pháp | Tốc độ hội tụ | Memory | Stability | Use case |
|-------------|---------------|---------|-----------|----------|
| **Standard GD** | Chậm | Thấp | Cao | Simple problems |
| **Momentum** | Nhanh | Thấp | Trung bình | Most problems |
| **AdaGrad** | Adaptive | Cao | Thấp | Sparse features |
| **Adam** | Rất nhanh | Cao | Trung bình | Deep learning |

<script>
class MomentumDemo {
    constructor() {
        this.canvas = document.getElementById('momentum-demo-canvas');
        this.ctx = this.canvas.getContext('2d');
        
        // Controls
        this.betaSlider = document.getElementById('momentum-beta-demo');
        this.lrSlider = document.getElementById('learning-rate-demo');
        this.betaValue = document.getElementById('momentum-beta-demo-value');
        this.lrValue = document.getElementById('learning-rate-demo-value');
        this.demoInfo = document.getElementById('momentum-demo-info');
        
        // State
        this.isAnimating = false;
        this.iteration = 0;
        
        // Initialize
        this.reset();
        this.setupEventListeners();
    }
    
    setupEventListeners() {
        this.betaSlider.addEventListener('input', (e) => {
            this.betaValue.textContent = e.target.value;
        });
        
        this.lrSlider.addEventListener('input', (e) => {
            this.lrValue.textContent = e.target.value;
        });
        
        document.getElementById('start-momentum-demo').addEventListener('click', () => {
            this.startAnimation();
        });
        
        document.getElementById('reset-momentum-demo').addEventListener('click', () => {
            this.reset();
        });
        
        document.getElementById('step-momentum-demo').addEventListener('click', () => {
            this.singleStep();
        });
    }
    
    // Objective function: f(x,y) = 0.5 * (10*x^2 + y^2)
    objectiveFunction(x, y) {
        return 0.5 * (10 * x * x + y * y);
    }
    
    // Gradient: [10*x, y]
    gradient(x, y) {
        return [10 * x, y];
    }
    
    // Coordinate transformations
    toCanvas(x, y) {
        const centerX = this.canvas.width / 2;
        const centerY = this.canvas.height / 2;
        const scale = 50;
        return [centerX + x * scale, centerY - y * scale];
    }
    
    drawContours() {
        this.ctx.strokeStyle = '#E0E0E0';
        this.ctx.lineWidth = 1;
        
        // Draw elliptical contours
        const levels = [0.5, 2, 8, 18, 32, 50];
        
        for (let level of levels) {
            this.ctx.beginPath();
            for (let angle = 0; angle <= 2 * Math.PI; angle += 0.1) {
                // For f(x,y) = 0.5*(10*x^2 + y^2) = level
                const a = Math.sqrt(2 * level / 10); // x semi-axis
                const b = Math.sqrt(2 * level);      // y semi-axis
                
                const x = a * Math.cos(angle);
                const y = b * Math.sin(angle);
                const [canvasX, canvasY] = this.toCanvas(x, y);
                
                if (angle === 0) {
                    this.ctx.moveTo(canvasX, canvasY);
                } else {
                    this.ctx.lineTo(canvasX, canvasY);
                }
            }
            this.ctx.stroke();
        }
        
        // Draw axes
        this.ctx.strokeStyle = '#CCCCCC';
        this.ctx.lineWidth = 1;
        
        // X-axis
        this.ctx.beginPath();
        this.ctx.moveTo(0, this.canvas.height / 2);
        this.ctx.lineTo(this.canvas.width, this.canvas.height / 2);
        this.ctx.stroke();
        
        // Y-axis
        this.ctx.beginPath();
        this.ctx.moveTo(this.canvas.width / 2, 0);
        this.ctx.lineTo(this.canvas.width / 2, this.canvas.height);
        this.ctx.stroke();
    }
    
    drawPath(path, color, lineWidth = 2) {
        if (path.length < 2) return;
        
        this.ctx.strokeStyle = color;
        this.ctx.lineWidth = lineWidth;
        this.ctx.beginPath();
        
        for (let i = 0; i < path.length; i++) {
            const [canvasX, canvasY] = this.toCanvas(path[i][0], path[i][1]);
            if (i === 0) {
                this.ctx.moveTo(canvasX, canvasY);
            } else {
                this.ctx.lineTo(canvasX, canvasY);
            }
        }
        this.ctx.stroke();
        
        // Draw current position
        if (path.length > 0) {
            const [lastX, lastY] = path[path.length - 1];
            const [canvasX, canvasY] = this.toCanvas(lastX, lastY);
            this.ctx.fillStyle = color;
            this.ctx.beginPath();
            this.ctx.arc(canvasX, canvasY, 5, 0, 2 * Math.PI);
            this.ctx.fill();
        }
    }
    
    reset() {
        this.isAnimating = false;
        this.iteration = 0;
        
        // Starting position
        this.gdPos = [2, 2];
        this.momentumPos = [2, 2];
        this.momentumVel = [0, 0];
        
        this.gdPath = [[2, 2]];
        this.momentumPath = [[2, 2]];
        
        this.draw();
    }
    
    singleStep() {
        const lr = parseFloat(this.lrSlider.value);
        const beta = parseFloat(this.betaSlider.value);
        
        // Standard Gradient Descent
        const gdGrad = this.gradient(this.gdPos[0], this.gdPos[1]);
        this.gdPos[0] -= lr * gdGrad[0];
        this.gdPos[1] -= lr * gdGrad[1];
        this.gdPath.push([this.gdPos[0], this.gdPos[1]]);
        
        // Momentum
        const momentumGrad = this.gradient(this.momentumPos[0], this.momentumPos[1]);
        this.momentumVel[0] = beta * this.momentumVel[0] + (1 - beta) * momentumGrad[0];
        this.momentumVel[1] = beta * this.momentumVel[1] + (1 - beta) * momentumGrad[1];
        this.momentumPos[0] -= lr * this.momentumVel[0];
        this.momentumPos[1] -= lr * this.momentumVel[1];
        this.momentumPath.push([this.momentumPos[0], this.momentumPos[1]]);
        
        this.iteration++;
        this.draw();
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
        
        this.drawContours();
        this.drawPath(this.gdPath, '#FF5722', 2);
        this.drawPath(this.momentumPath, '#2196F3', 2);
        
        // Legend
        this.ctx.fillStyle = '#FF5722';
        this.ctx.fillRect(10, 10, 20, 10);
        this.ctx.fillStyle = '#000';
        this.ctx.font = '12px Arial';
        this.ctx.fillText('Standard GD', 35, 20);
        
        this.ctx.fillStyle = '#2196F3';
        this.ctx.fillRect(10, 30, 20, 10);
        this.ctx.fillStyle = '#000';
        this.ctx.fillText('Momentum', 35, 40);
        
        // Update info
        const gdLoss = this.objectiveFunction(this.gdPos[0], this.gdPos[1]);
        const momentumLoss = this.objectiveFunction(this.momentumPos[0], this.momentumPos[1]);
        
        this.demoInfo.innerHTML = 
            `<div>Standard GD - Iteration: ${this.iteration}, Loss: ${gdLoss.toFixed(3)}</div>` +
            `<div>Momentum - Iteration: ${this.iteration}, Loss: ${momentumLoss.toFixed(3)}</div>`;
    }
    
    startAnimation() {
        if (this.isAnimating) {
            this.isAnimating = false;
            document.getElementById('start-momentum-demo').textContent = 'Start Comparison';
            return;
        }
        
        this.isAnimating = true;
        document.getElementById('start-momentum-demo').textContent = 'Stop Comparison';
        
        const animate = () => {
            if (!this.isAnimating) return;
            
            const currentLoss = Math.min(
                this.objectiveFunction(this.gdPos[0], this.gdPos[1]),
                this.objectiveFunction(this.momentumPos[0], this.momentumPos[1])
            );
            
            if (currentLoss > 1e-4 && this.iteration < 200) {
                this.singleStep();
                setTimeout(animate, 100);
            } else {
                this.isAnimating = false;
                document.getElementById('start-momentum-demo').textContent = 'Start Comparison';
            }
        };
        
        animate();
    }
}

// Initialize when DOM is loaded
document.addEventListener('DOMContentLoaded', function() {
    if (document.getElementById('momentum-demo-canvas')) {
        new MomentumDemo();
    }
});
</script>

## Tài liệu tham khảo

1. Polyak, B. T. (1964). Some methods of speeding up the convergence of iteration methods. USSR Computational Mathematics and Mathematical Physics, 4(5), 1-17.

2. Sutskever, I., Martens, J., Dahl, G., & Hinton, G. (2013). On the importance of initialization and momentum in deep learning. International Conference on Machine Learning, 1139-1147.

3. Ruder, S. (2016). An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.
